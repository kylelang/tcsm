[["index.html", "Theory Construction and Statistical Modeling Course Information", " Theory Construction and Statistical Modeling Kyle M. Lang Last updated: 2023-10-06 Course Information In order to test a theory, we must express the theory as a statistical model and then test this model on quantitative (numeric) data. In this course we will use datasets from different disciplines within the social sciences (educational sciences, psychology, and sociology) to explain and illustrate theories and practices that are used in all social science disciplines to statistically model social science theories. This course uses existing tutorial datasets to practice the process of translating verbal theories into testable statistical models. If you are interested in the methods of acquiring high quality data to test your own theory, we recommend following the course Conducting a Survey which is taught from November to January. Most information about the course is available in this GitBook. Course-related communication will be through https://uu.blackboard.com (Log in with your student ID and password). "],["acknowledgement.html", "Acknowledgement", " Acknowledgement This course was originally developed by dr. Caspar van Lissa. I (dr. Kyle M. Lang) have modified Caspar’s original materials and take full responsibility for any errors or inaccuracies introduced through these modifications. Credit for any particularly effective piece of pedagogy should probably go to Caspar. You can view the original version of this course here on Caspar’s GitHub page. "],["instructors.html", "Instructors", " Instructors Coordinator: dr. Kyle M. Lang Lectures: dr. Kyle M. Lang Practicals: Rianne Kraakman Daniëlle Remmerswaal Danielle McCool "],["course-overview.html", "Course overview", " Course overview This course comprises three parts: Path analysis: You will learn how to estimate complex path models of observed variables (e.g., linked linear regressions) as structural equation models. Factor analysis: You will learn different ways of defining and estimating latent (unobserved) constructs. Full structural equation modeling: You will combine the first two topics to estimate path models describing the associations among latent constructs. Each of these three themes will be evaluated with a separate assignment. The first two assignments will be graded on a pass/fail basis. Your course grade will be based on your third assignment grade. "],["schedule.html", "Schedule", " Schedule Course Week Calendar Week Lecture/Practical Topic Workgroup Activity Assignment Deadline 0 36 Pre-course preparation 1 37 Introduction to R 2 38 Statistical modeling, Path analysis 3 39 Mediation, Moderation 4 40 Exploratory factor analysis (EFA) A1 Peer-Review A1: 2023-10-04 @ 23:59 5 41 Confirmatory factor analysis (CFA) 6 42 Structural equation modeling (SEM) A2 Peer-Review A2: 2023-10-18 @ 23:59 7 43 Multiple group models 8 44 Wrap-up A3 Peer-Review 9 45 Exam week: No class meetings A3: 2023-11-10 @ 23:59 NOTE: The schedule (including topics covered and assignment deadlines) is subject to change at the instructors’ discretion. "],["learning-goals.html", "Learning goals", " Learning goals In this course you will learn how to translate a social scientific theory into a statistical model, how to analyze your data with these models, and how to interpret and report your results following APA standards. After completing the course, you will be able to: Translate a verbal theory into a conceptual model, and translate a conceptual model into a statistical model. Independently analyze data using the free, open-source statistical software R. Apply a latent variable model to a real-life problem wherein the observed variables are only indirect indicators of an unobserved construct. Use a path model to represent the hypothesized causal relations among several variables, including relationships such as mediation and moderation. Explain to a fellow student how structural equation modeling combines latent variable models with path models and the benefits of doing so. Reflect critically on the decisions involved in defining and estimating structural equation models. "],["resources.html", "Resources", " Resources Literature You do not need a separate book for this course! Most of the information is contained within this GitBook and the course readings (which you will be able to access via links in this GitBook). All literature is freely available online, as long as you are logging in from within the UU-domain (i.e., from the UU campus or through an appropriate VPN). All readings are linked in this GitBook via either direct download links or DOIs. If you run into any trouble accessing a given article, searching for the title using Google Scholar or the University Library will probably due the trick. Software You will do all of your statistical analyses with the statistical programming language/environment R and the add-on package lavaan. If you want to expand your learning, you can follow this optional lavaan tutorial. "],["reading-questions.html", "Reading questions", " Reading questions Along with every article, we will provide reading questions. You will not be graded on the reading questions, but it is important to prepare the reading questions before every lecture. The reading questions serve several important purposes: Provide relevant background knowledge for the lecture Help you recognize and understand the key terms and concepts Make you aware of important publications that shaped the field Help you extract the relevant insights from the literature "],["weekly-preparation.html", "Weekly preparation", " Weekly preparation Before every class meeting (both lectures and practicals) you need to do the assigned homework (delineated in the GitBook chapter for that week). This course follows a flipped classroom procedure, so you must complete the weekly homework to meaningfully participate in, and benefit from, the class meetings. Background knowledge We assume you have basic knowledge about multivariate statistics before entering this course. You do not need any prior experience working with R. If you wish to refresh your knowledge, we recommend the chapters on ANOVA, multiple regression, and exploratory factor analysis from Field’s Discovering Statistics using R. If you cannot access the Field book, many other introductory statistics textbooks cover these topics equally well. So, use whatever you have lying around from past statistics courses. You could also try one of the following open-access options: Applied Statistics with R Introduction to Modern Statistics Introduction to Statistical Learning "],["grading.html", "Grading", " Grading Your grade for the course is based on a “portfolio” composed of the three take-home assignments: Path modeling Deadline: Wednesday 2023-10-04 at 23:59 Group assignment Pass/Fail Confirmatory factor analysis Deadline: Wednesday 2023-10-18 at 23:59 Group assignment Pass/Fail Full structural equation modeling Deadline: Friday 2023-11-10 at 23:59 Individual assignment Comprises your entire numeric course grade The specifics of the assignments will be explicated in the Assignments chapter of this GitBook "],["attendance.html", "Attendance", " Attendance Attendance is not mandatory, but we strongly encourage you to attend all lectures and practicals. In our experience, students who actively participate tend to pass the course, whereas those who do not participate tend to drop out or fail. The lectures and practicals build on each other, so, in the unfortunate event that you have to miss a class meeting, please make sure you have caught up with the material before the next session. "],["assignments.html", "Assignments", " Assignments This chapter contains the details and binding information about the three assignments that comprise the portfolio upon which your course grade is based. Below, you can find a brief idea of what each assignment will cover. For each assignment, you will use R to analyze some real-world data, and you will write up your results in a concise report (not a full research paper). Guidelines for these analyses/reports are delineated in the following three sections. You will submit your reports via Blackboard. You will complete the first two assignments in your Assignment Groups. You will complete the third assignment individually. The first two assignments are graded as pass/fail. You must pass both of these assignments to pass the course. The third assignment constitutes your course grade. "],["assignment-1-path-analysis.html", "Assignment 1: Path Analysis", " Assignment 1: Path Analysis For the first assignment, you will work in groups to apply a path model that describes how several variables could be causally related. The components of the first assignment are described below. Choose a suitable dataset, and describe the data. You can use any of the 8 datasets linked below. State the research question; define and explicate the theoretical path model. This model must include, at least, three variables. Use a path diagram to show your theoretical model. Translate your theoretical path model into lavaan syntax, and estimate the model. Include the code used to define and estimate your model as an appendix. Explain your rationale for important modeling decisions. Discuss the conceptual fit between your theory and your model. Evaluate the model assumptions. Discuss other important decisions that could have influence your results. Report the results in APA style. Provide relevant output in a suitable format. Include measures of explained variance for the dependent variables. Discuss the results. Use your results to answer the research question. Consider the strengths and limitations of your analysis. Evaluation See the Grading section below for more information on how Assignment 1 will be evaluated. You can access an evaluation matrix for Assignment 1 here. This matrix gives an indication of what level of work constitutes insufficient, sufficient, and excellent responses to the six components described above. Submission Assignment 1 is due at 23:59 on Wednesday 4 October 2023. Submit your report via the Assignment 1 portal on Blackboard. "],["assignment-2-confirmatory-factor-analysis.html", "Assignment 2: Confirmatory Factor Analysis", " Assignment 2: Confirmatory Factor Analysis In the second assignment, you will work in groups to run a CFA wherein the observed variables are indirect indicators of the unobserved constructs you want to analyze. The components of the second assignment are described below. Choose a suitable dataset, and describe the data. Ideally, you will work with the same data that you analyzed in Assignment 1. If you want to switch, you can use any of the 8 datasets linked below. State the research question; define and explicate the theoretical CFA model. This model must include, at least, two latent constructs. Use a path diagram to represent your model. Translate your theoretical model into lavaan syntax, and estimate the model. Include the code used to define and estimate your model as an appendix. Explain your rationale for important modeling decisions. Discuss the conceptual fit between your theory and your model. Evaluate the model assumptions. Discuss other important decisions that could have influence your results. Report the results in APA style. Provide relevant output in a suitable format. Include measures of model fit. Discuss the results. Use your results to answer the research question. Consider the strengths and limitations of your analysis. Evaluation See the Grading section below for more information on how Assignment 2 will be evaluated. You can access an evaluation matrix for Assignment 2 here. This matrix gives an indication of what level of work constitutes insufficient, sufficient, and excellent responses to the six components described above. Submission Assignment 2 is due at 23:59 on Wednesday 18 October 2023. Submit your report via the Assignment 2 portal on Blackboard. "],["a3_components.html", "Assignment 3: Full Structural Equation Model", " Assignment 3: Full Structural Equation Model In the third assignment, you will work individually to apply a full SEM that describes how several (latent) variables could be causally related. The components of the third assignment are described below. Choose a suitable dataset, and describe the data. Ideally, you will work with the same data that you analyzed in Assignments 1 &amp; 2. If you want to switch, you can use any of the 8 datasets linked below. State the research question; define and explicate the theoretical SEM. The structural component of this model must include, at least, three variables. The model must include, at least, two latent variables. Use a path diagram to represent your model. Translate your theoretical SEM into lavaan syntax, and estimate the model. Include the code used to define and estimate your model as an appendix. Explain your rationale for important modeling decisions. Discuss the conceptual fit between your theory and your model. Evaluate the model assumptions. Discuss other important decisions that could have influence your results. Report the results in APA style. Provide relevant output in a suitable format. Include measures of model fit. Include measures of explained variance for the dependent variables. Discuss the results. Use your results to answer the research question. Consider the strengths and limitations of your analysis. Evaluation See the Grading section below for more information on how the component scores represented in the rubric are combined into an overall assignment grade. You can access an evaluation matrix for Assignment 3 here. This matrix gives an indication of what level of work constitutes insufficient, sufficient, and excellent responses to the six components described above. Submission Assignment 3 is due at 23:59 on Friday 10 November 2023. Submit your report via the Assignment 3 portal on Blackboard. "],["elaboration-tips.html", "Elaboration &amp; Tips", " Elaboration &amp; Tips Theoretical Model &amp; Research Question You need to provide some justification for your model and research question, but only enough to demonstrate that you’ve actually conceptualized and estimated a theoretically plausible statistical model (as opposed to randomly combining variables until lavaan returns a pretty picture). You have several ways to show that your model is plausible. Use common-sense arguments. Reference (a small number of) published papers. Replicate an existing model/research question. Don’t provide a rigorous literature-supported theoretical motivation. You don’t have the time to conduct a thorough literature review, and we don’t have the time to read such reviews when grading. Literature review is not one of the learning goals for this course, so you cannot get “bonus points” for an extensive literature review. You are free to test any plausible model that meets the size requirements. You can derive your own model/research question or you can replicate a published analysis. Model Specifications We will not cover methods for modeling categorical outcome variables. So, use only continuous variables as outcomes. DVs in path models and the structural parts of SEMs Observed indicators of latent factors in CFA/SEM NOTE: You may treat ordinal items as continuous, for the purposes of these assignments. We will not cover methods for latent variable interactions. Don’t specify a theoretical model that requires an interaction involving a latent construct. There is one exception to the above prohibition. If the moderator is an observed grouping variable, you can estimate the model as a multiple-group model. We’ll cover these methods in Week 7. Assumptions You need to show that you’re thinking about the assumptions and their impact on your results, but you don’t need to run thorough model diagnostics. Indeed, the task of checking assumptions isn’t nearly as straight forward in path analysis, CFA, and SEM as it is in linear regression modeling. You won’t be able to directly apply the methods you have learned for regression diagnostics, for example. Since all of our models are estimated with normal-theory maximum likelihood, the fundamental assumption of all the models we’ll consider in this course boils down to the following. All random variables in my model are i.i.d. multivariate normally distributed. So, you can get by with basic data screening and checking the observed random variables in your model (i.e., all variables other than fixed predictors) for normality. Since checking for multivariate normality is a bit tricky, we’ll only ask you to evaluate univariate normality. You should do these evaluations via graphical means. To summarize, we’re looking for the following. Data Consider whether the measurement level of your data matches the assumptions of your model. Check your variables for univariate outliers. If you find any outliers, either treat them in some way or explain why you are retaining them for the analysis. Check for missing data. For the purposes of the assignment, you can use complete case analysis to work around the missing data. If you’re up for more of a challenge, feel free to try multiple imputation or full information maximum likelihood. Model Evaluate the univariate normality of any random, observed variables in your model. E.g., DVs in path models, observed IVs modeled as random variables, indicators of latent factors If you fit a multiple-group model for Assignment 3, do this evaluation within groups. Use graphical tools to evaluate the normality assumption. Normal QQ-Plots Histograms Results What do we mean by reporting your results “in a suitable format”? Basically, put some effort into making your results readable, and don’t include a bunch of superfluous information. Part of demonstrating that you understand the analysis is showing that you know which pieces of output convey the important information. Tabulate your results; don’t directly copy the R output. Don’t include everything lavaan gives you. Include only the output needed to understand your results and support your conclusions. "],["data_options.html", "Data", " Data Below, you can find links to a few suitable datasets that you can use for the assignments. You must use one of the following datasets. You may not choose your own data from the wild. Coping with Covid Dataset Codebook Pre-Registration Feminist Perspectives Scale Dataset Article Hypersensitive Narcissism Scale &amp; Dirty Dozen Dataset HSNS Article DD Article Kentucky Inventory of Mindfulness Skills Dataset Article Depression Anxiety Stress Scale Dataset DASS Information Nomophobia Dataset Recylced Water Acceptance Dataset Article "],["procedures.html", "Procedures", " Procedures Formatting You must submit your assignment reports in PDF format. Each report should include a title page. The title page should include the following information: The name of the assignment. The names of all assignment authors (i.e., all group members for Assignments 1 &amp; 2, your name for Assignment 3). The Assignment Group number (only for Assignments 1 &amp; 2). You must include the code used to define and run your model(s) as an appendix. Try to format the text in this appendix clearly. Use a monospace font. Length You may use as many words as necessary to adequately explain yourself; though, concision and parsimony are encouraged. Note that the assignments are not intended to be full-blown papers! The focus should be on the definition of your model, how this model relates to theory (introduction), and what you have learned from your estimated model (discussion). For each of the assignments, you should be able to get the job done in fewer than 10 pages of text (excluding title page, figures, appendices, and references). Submission You will submit your reports through Blackboard. Each assignment has a corresponding item in the “Assignments” section of the BB page through which you will submit your reports. For Assignments 1 &amp; 2, you may only submit one report per group. Designate one group member to submit the report. The grade for this submission will apply to all group members. If something goes wrong with the submission, or you notice a mistake (before the deadline) that you want to correct, you may upload a new version of your report. We will grade the final submitted version. The submissions will be screened with Ouriginal. "],["grading-1.html", "Grading", " Grading Group Assignments Assignments 1 &amp; 2 are simply graded as pass/fail. To pass, your submission must: Do a reasonable job of addressing the relevant components listed above Be submitted before the deadline Otherwise, you will fail the assignment. Individual Assignment Assignment 3 will be fully graded on the usual 10-point scale. Points will be allocated according to the extent to which your submission addresses the six components listed above. The evaluation matrix gives an indication of how these points will be apportioned. Further details over the grading procedures for Assignment 3 (e.g., exactly how your 10-point grade will be defined) will be provided at a later date. Assuming your group passes the first two assignments, your final course grade will simply be your Assignment 3 grade. Resits You must get a “pass” for Assignments 1 &amp; 2 and score at least 5.5 on Assignment 3 to pass the course. If you fail any of the assignments, you will have the opportunity to resit the failed assignment(s). If you resit Assignment 3, your revised graded cannot be higher than 6. Further details on the resit procedure will be provided at a later date. Example Assignment You can find an example of a good submission (for an older version of Assignment 2) here. This example is not perfect (no paper ever is), and several points could be improved. That being said, this submission exemplifies what we’re looking for in your project reports. So, following the spirit of this example would earn you a high grade. "],["rules.html", "Rules", " Rules Resources For all three assignments, you may use any reference materials you like, including: All course materials The course GitBook Additional books and papers The internet Collaboration You will complete the first two assignments in groups. Although you will work in groups, your group may not work together with other groups. You will complete the final assignment individually. For this assignment, you may not work with anyone else. For all three assignments, you are obligated to submit original work (i.e., work conducted for this course by you or your group). Submitting an assignment that violates this condition constitutes fraud. Such cases of fraud will be addressed according to the University’s standard policy. Academic integrity Hopefully, you also feel a moral obligation to obey the rules. For this course, we have implemented an examination that allows you to showcase what you have learned in a more realistic way than a written exam would allow. This assessment format spares you the stress of long exams (the two exams for this course used to be 4 hours each) and the attendant studying/cramming. The assignments will also help you assess your ability to independently analyse data, which is important to know for your future courses and/or career. However, this format also assumes that you complete the assignments in good faith. So, I simply ask that you hold up your end of the bargain, and submit your original work to show us what you’ve learned. Strict stuff By submitting your assignments (both group and individual), you confirm the following: You have completed the assignment yourself (or with your group) You are submitting work that you have written yourself (or with your group) You are using your own UU credentials to submit the assignment You have not had outside help that violates the conditions delineated above while completing the assignment All assignments will be submitted via Ouriginal in Blackboard and, thereby, checked for plagiarism. If fraud or plagiarism is detected or suspected, we will inform the Board of Examiners in the usual manner. In the event of demonstrable fraud, the sanctions delineated in Article 5.15 of the Education and Examination Regulations (EER) will apply. "],["software-setup.html", "Software Setup", " Software Setup This chapter will help you prepare for the course by showing how to install R and RStudio on your computer. If you’re already using R, there may be nothing new for you here. That being said, you should look over this chapter to ensure that your current setup will be compatible with the course requirements. If you have never used R before, this chapter is essential! The information is this chapter will be crucial for getting your computer ready for the course. "],["typographic-conventions.html", "Typographic Conventions", " Typographic Conventions Throughout this GitBook, we (try to) use a consistent set of typographic conventions: Functions are typeset in a code font, and the name of the function is always followed by parentheses E.g., sum(), mean() Other R objects (e.g., data objects, function arguments) are in also typeset in a code font but without parentheses E.g., seTE, method.tau Sometimes, we’ll use the package name followed by two colons (::, the so-called *scope-resolution operator), like lavaan::sem(). This command is valid R code and will run if you copy it into your R console. The lavaan:: part of the command tells R that we want to use the sem() from the lavaan package. "],["installing-software.html", "Installing software", " Installing software Before we start the course, we have to install three things: R: A free program for statistical programming RStudio: An integrated development environment (IDE) which makes it easier to work with R. Several packages: Separate pieces of ‘add-on’ software for R with functions to do specific analyses. Packages also include documentation describing how to use their functions and sample data. Installing R The latest version of R is available here. Click the appropriate link for your operating system and follow the instructions for installing the latest stable release. Depending on which OS you select, you may be given an option to install different components (e.g., base, contrib, Rtools). For this course, you will only need the base package. Installing RStudio Download the Free Desktop version of RStudio from the download page of the RStudio website. Installing packages To participate in this course, you will need a few essential R packages. Here’s an overview of the packages and why we need them: Package Description lavaan A sophisticated and user-friendly package for structural equation modeling dplyr A powerful suite of data-processing tools ggplot2 A flexible and user-friendly package for making graphs tidySEM Plotting and tabulating the output of SEM-models semTools Comparing models, establishing measurement invariance across groups psych Descriptive statistics and EFA rockchalk Probing interactions foreign Loading data from SPSS ‘.sav’ files readxl Loading data from Excel ‘.xslx’ files To install these packages, we use the install.packages() function in R. Open RStudio Inside RStudio, find the window named Console on left side of the screen. Copy the following code into the console and hit Enter/Return to run the command. install.packages(c(&quot;lavaan&quot;, &quot;dplyr&quot;, &quot;ggplot2&quot;, &quot;tidySEM&quot;, &quot;semTools&quot;, &quot;psych&quot;, &quot;rockchalk&quot;, &quot;foreign&quot;, &quot;readxl&quot;), dependencies = TRUE) "],["course-data.html", "Course Data", " Course Data All of the data files you will need for the course are available in this SurfDrive directory. Follow the link to download a ZIP archive containing the data you will need to complete the practical exercises and assignments. Extract these data files to a convenient location on your computer. "],["note-on-data-updates.html", "Note on Data Updates", " Note on Data Updates During the course, we may need to update some of these datasets and/or add some new datasets to the SurfDrive directory. If so, you will need to download the updated data. We will let you know if and when any datasets are modified. In such situations, you are responsible for updating your data. Working with outdated data will probably produce incorrect results. Your answer won’t match the solutions we expect. Your answer will be marked as incorrect, even if the code used to produce the answer is correct. Points lost on an assignment due to using outdated datasets will not be returned. "],["introduction-to-r.html", "1 Introduction to R", " 1 Introduction to R This week is all about getting up-and-running with R and RStudio. Homework before the lecture Complete the preparatory material: Read over the Course Information chapter Work through the Software Setup chapter Watch the Lecture Recording for this week. Homework before the practical Complete the At-Home Exercises. Practical content During the practical you will work on the In-Class Exercises. "],["lecture.html", "1.1 Lecture", " 1.1 Lecture This week, you will learn the basics of R and RStudio. Rather than re-inventing the proverbial wheel, we’re linked to existing resources developed by R-Ladies Sydney. 1.1.1 Recordings Tour of RStudio \\[\\\\[6pt]\\] R Packages \\[\\\\[6pt]\\] Data I/0 1.1.2 Slides You can access the accompanying resources on the R-Ladies Sydney website here. "],["reading.html", "1.2 Reading", " 1.2 Reading There is no official reading this week. If you’d like to deepen your dive into R, feel free to check out Hadley Wickham’s excellent book R for Data Science. Otherwise, you may want to get a jump-start on the At-Home Exercises for this week. \\[\\\\[12pt]\\] "],["at-home-exercises.html", "1.3 At-Home Exercises", " 1.3 At-Home Exercises This week is all about gaining familiarity with R and RStudio. We’ll be using the primers available on Posit Cloud to work through some basic elements of data visualization and statistical programming in R. Although you should already have R working, this week’s at-home and in-class exercises don’t require that you have R installed on your system. If following along within this GitBook doesn’t work for you, you can also find the tutorials online on the Posit Primers page. 1.3.1 Visualizations with R 1.3.2 Programming with R End of At-Home Exercises "],["in-class-exercises.html", "1.4 In-Class Exercises", " 1.4 In-Class Exercises In the practical this week, we’ll go a little further into what it’s possible with R. Don’t worry if you cannot remember everything in these primers—they’re only meant to familiarize you with what is possible and to get you some experience interacting with R and RStudio. The following primers come from Posit Cloud and were created with the learnr package. 1.4.1 Viewing Data This first primer introduces a special data format called a tibble, as well as some functions for viewing your data. 1.4.2 Dissecting Data In the next primer, we’ll explore tools to subset and rearrange you data: select(), filter(), and arrange(). 1.4.3 Grouping and Manipulating Data Advanced If you made it through the previous two sections with ease and want to challenge yourself, go ahead with this next section. If you’re running short on time, you can skip ahead to Exploratory Data Analysis. \\[\\\\[3pt]\\] 1.4.4 Exploratory Data Analysis 1.4.5 Visualizing Data Visualizing data is a great way to start understanding a data set. In this section, we’ll highlight a few examples of how you can use the ggplot2 libarary to visualize your data. Primers on many other visualizations are available on Posit Cloud. Bar Charts for Categorical Variables Scatterplots for Continuous Variables 1.4.6 Tidying Data This primer will provide an overview of what’s meant by “tidy data”. You only need to complete the Tidy Data section—the sections on Gathering and Spreading columns are useful, but we won’t ask you to apply those techniques in this course. Recap Hopefully, you now feel more comfortable using some of R’s basic functionality and packages to work with data. Here’s a brief description of the functions covered above: install.packages() for installing packages Remember to put the package names in quotes library() for loading packages View() for viewing your dataset select() for picking only certain columns filter() for picking only certain rows arrange() for changing the rows order %&gt;% aka “the pipe” for chaining commands together In RStudio, you can hit ctrl+shift+m as a handy key combination ? for help files Logical tests and Boolean operators == equal to != not equal to &lt; less than &lt;= less than or equal to &gt; greater than &gt;= greater than or equal to is.na() is the value NA (not available) !is.na is the value not NA &amp; and (true only if the left and right are both true) | or (true if either the left or right are true) ! not (invert true/false) %in% in (is left in the larger set of right values) any() any (true if any in the set are true) all() all (true if all in the set are true) xor() xor (true if one and only one of the set are true) ggplot2 ggplot() create the basic object from which to building a plot aes() contains the aesthetic mappings (like x and y) geom_bar() bar plots for distributions of categorical variables geom_point() scatterplots for plotting two continuous variables geom_label_repel() for plotting text facet_wrap() for creating sets of conditional plots End of In-Class Exercises "],["statistical-modeling-path-analysis.html", "2 Statistical Modeling &amp; Path Analysis", " 2 Statistical Modeling &amp; Path Analysis This week, we will cover statistical modeling and path analysis. Homework before the lecture Watch the Lecture Recording for this week. Complete the Reading for this week, and answer the associated reading questions. Homework before the practical Complete the At-Home Exercises. Practical content During the practical you will work on the In-Class Exercises. "],["lecture-1.html", "2.1 Lecture", " 2.1 Lecture In this lecture, we will begin by discussing the paradigm and contextualizing statistical modeling relative to other ways that we can conduct statistical analyses. We will conclude with an introduction to . 2.1.1 Recordings Statistical Reasoning Statistical Modeling Path Analysis 2.1.2 Slides You can download the lectures slides here "],["reading-1.html", "2.2 Reading", " 2.2 Reading Reference Smaldino, P. E. (2017). Models are stupid, and we need more of them. In R.R. Vallacher, S.J. Read, &amp; A. Nowakt (Eds.), Computational Social Psychology (pp. 311–331). New York: Routledge. SKIP PAGES 322 - 327 Questions What are the differences between a “verbal model” and a “formal model”? As explained in the paragraph “A Brief Note on Statistical Models”, formal models are not the same as statistical models. Still, we can learn a lot from Smaldino’s approach. Write down three insights from this paper that you would like to apply to your statistical modeling during this course. Suggested Reading (Optional) The following paper is not required, but it’s definitely worth a read. Breiman provides a very interesting perspective on different ways to approach a modeling-based analysis. Breiman, L. (2001). Statistical Modeling: The Two Cultures (with comments and a rejoinder by the author). Statistical Science, 16(3) 199–231. https://doi.org/10.1214/ss/1009213726 "],["at-home-exercises-1.html", "2.3 At-Home Exercises", " 2.3 At-Home Exercises Load the LifeSat.sav data. library(dplyr) library(haven) LifeSat &lt;- read_spss(&quot;LifeSat.sav&quot;) 2.3.1 Make a table of descriptive statistics for the variables: LifSat, educ, ChildSup, SpouSup, and age. What is the average age in the sample? What is the range (youngest and oldest child)? Hint: Use the tidySEM::descriptives() function.` Click for explanation The package tidySEM contains the descriptives() function for computing descriptive statistics. The describe() function in the psych package is a good alternative. library(tidySEM) descriptives(LifeSat[ , c(&quot;LifSat&quot;, &quot;educ&quot;, &quot;ChildSup&quot;, &quot;SpouSup&quot;, &quot;age&quot;)]) 2.3.2 Run a simple linear regression with LifSat as the dependent variable and educ as the independent variable. Hints: The lm() function (short for linear model) does linear regression. The summary() function provides relevant summary statistics for the model. It can be helpful to store the results of your analysis in an object. Click for explanation results &lt;- lm(LifSat ~ educ, data = LifeSat) summary(results) ## ## Call: ## lm(formula = LifSat ~ educ, data = LifeSat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -43.781 -11.866 2.018 12.418 43.018 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 35.184 7.874 4.469 2.15e-05 *** ## educ 3.466 1.173 2.956 0.00392 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 17.64 on 96 degrees of freedom ## Multiple R-squared: 0.08344, Adjusted R-squared: 0.0739 ## F-statistic: 8.74 on 1 and 96 DF, p-value: 0.003918 2.3.3 Repeat the analysis from 2.3.2 with age as the independent variable. Click for explanation results &lt;- lm(LifSat ~ age, data = LifeSat) summary(results) ## ## Call: ## lm(formula = LifSat ~ age, data = LifeSat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -35.321 -14.184 3.192 13.593 40.626 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 200.2302 52.1385 3.840 0.00022 *** ## age -2.0265 0.7417 -2.732 0.00749 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 17.75 on 96 degrees of freedom ## Multiple R-squared: 0.07215, Adjusted R-squared: 0.06249 ## F-statistic: 7.465 on 1 and 96 DF, p-value: 0.007487 2.3.4 Repeat the analysis from 2.3.2 and 2.3.3 with ChildSup as the independent variable. Click for explanation results &lt;- lm(LifSat ~ ChildSup, data = LifeSat) summary(results) ## ## Call: ## lm(formula = LifSat ~ ChildSup, data = LifeSat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -37.32 -12.14 0.66 12.41 44.68 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 37.559 8.342 4.502 1.89e-05 *** ## ChildSup 2.960 1.188 2.492 0.0144 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 17.86 on 96 degrees of freedom ## Multiple R-squared: 0.06076, Adjusted R-squared: 0.05098 ## F-statistic: 6.211 on 1 and 96 DF, p-value: 0.01441 2.3.5 Run a multiple linear regression with LifSat as the dependent variable and educ, age, and ChildSup as the independent variables. Hint: You can use the + sign to add multiple variables to the RHS of your model formula. Click for explanation results &lt;- lm(LifSat ~ educ + age + ChildSup, data = LifeSat) summary(results) ## ## Call: ## lm(formula = LifSat ~ educ + age + ChildSup, data = LifeSat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -32.98 -12.56 2.68 11.03 41.91 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 134.9801 53.2798 2.533 0.0130 * ## educ 2.8171 1.1436 2.463 0.0156 * ## age -1.5952 0.7188 -2.219 0.0289 * ## ChildSup 2.4092 1.1361 2.121 0.0366 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 16.92 on 94 degrees of freedom ## Multiple R-squared: 0.1741, Adjusted R-squared: 0.1477 ## F-statistic: 6.603 on 3 and 94 DF, p-value: 0.0004254 2.3.6 Compare the results from 2.3.5 with those from 2.3.2, 2.3.3, and 2.3.4. What do you notice when you compare the estimated slopes for each of the three predictors in the multiple regression model with the corresponding estimates from the simple regression models? "],["in-class-exercises-1.html", "2.4 In-Class Exercises", " 2.4 In-Class Exercises During this practical, you will work through some exercises meant to expand your statistical reasoning skills and improve your understanding of linear models. For this exercise, having some familiarity with regression will be helpful. If you feel like you need to refresh your knowledge in this area, consider the resources listed in the Background knowledge section. Data: You will use the following dataset for these exercises. Sesam.sav 2.4.1 Data Exploration Open the file “Sesam.sav” # Load `dplyr` for data processing: library(dplyr) # Load the `haven` library for reading in SPSS files: library(haven) ## Load the &#39;Sesam.sav&#39; data ## Use haven::zap_formats() to remove SPSS attributes sesam &lt;- read_sav(file = &quot;Sesam.sav&quot;) %&gt;% zap_formats() This file is part of a larger dataset that evaluates the impact of the first year of the Sesame Street television series. Sesame Street is mainly concerned with teaching preschool related skills to children in the 3–5 year age range. The following variables will be used in this exercise: age: measured in months prelet: knowledge of letters before watching Sesame Street (range 0–58) prenumb: knowledge of numbers before watching Sesame Street (range 0–54) prerelat: knowledge of size/amount/position relationships before watching Sesame Street (range 0–17) peabody: vocabulary maturity before watching Sesame Street (range 20–120) postnumb: knowledge of numbers after a year of Sesame Street (range 0–54) Note: Unless stated otherwise, the following questions refer to the sesam data and the above variables. 2.4.1.1 What is the type of each variable? Hint: The output of the str() function should be helpful here. Click to show code ## Examine the data structure: str(sesam) ## tibble [240 × 8] (S3: tbl_df/tbl/data.frame) ## $ id : num [1:240] 1 2 3 4 5 6 7 8 9 10 ... ## $ age : num [1:240] 66 67 56 49 69 54 47 51 69 53 ... ## $ prelet : num [1:240] 23 26 14 11 47 26 12 48 44 38 ... ## $ prenumb : num [1:240] 40 39 9 14 51 33 13 52 42 31 ... ## $ prerelat: num [1:240] 14 16 9 9 17 14 11 15 15 10 ... ## $ peabody : num [1:240] 62 80 32 27 71 32 28 38 49 32 ... ## $ postnumb: num [1:240] 44 39 40 19 54 39 44 51 48 52 ... ## $ gain : num [1:240] 4 0 31 5 3 6 31 -1 6 21 ... ## ..- attr(*, &quot;display_width&quot;)= int 10 Click for explanation All variables are numeric. str() uses the abbreviation “num” to indicate a numeric vector. 2.4.1.2 What is the average age in the sample? What is the age range (youngest and oldest child)? Hint: Use tidySEM::descriptives() Click to show code As in the take home exercises, you can use the descriptives() function from the tidySEM package to describe the data: library(tidySEM) descriptives(sesam) Click for explanation We can get the average age from the “mean” column in the table ( 51.5), and the age range from the columns “min” and “max”, (34 and 69 respectively.) 2.4.1.3 What is the average gain in knowledge of numbers? What is the standard deviation of this gain? Hints: You will need to compute the gain and save the change score as a new object. You can then use the base-R functions mean() and sd() to do the calculations. Click to show code Create a new variable that represents the difference between pre- and post-test scores on knowledge of numbers: sesam &lt;- mutate(sesam, ndif = postnumb - prenumb) Compute the mean and SD of the change score: sesam %&gt;% summarise(mean(ndif), sd(ndif)) 2.4.1.4 Create an appropriate visualization of the gain scores you computed in 2.4.1.3. Justify your choice of visualization. Hint: Some applicable visualizations are explained in the Visualizations with R section. Click to show code library(ggplot2) ## Create an empty baseline plot object: p &lt;- ggplot(sesam, aes(x = ndif)) ## Add some appropriate geoms: p + geom_histogram() p + geom_density() p + geom_boxplot() Click for explanation Because the gain score is numeric, we should use something appropriate for showing the distribution of a continuous variable. In this case, we can use either a density plot, or a histogram (remember from the lecture, this is like a density plot, but binned). We can also use a box plot, which can be a concise way to display a lot of information about a variable in a little less space. 2.4.1.5 Create a visualization that provides information about the bivariate relationship between the pre- and post-test number knowledge. Justify your choice of visualization. Describe the relationship based on what you see in your visualization. Hint: Again, the Visualizations with R section may provide some useful insights. Click to show code ## Create a scatterplot of the pre- and post-test number knowledge ggplot(sesam, aes(x = prenumb, y = postnumb)) + geom_point() Click for explanation A scatterplot is a good tool for showing patterns in the way that two continuous variables relate to each other. From it, we can quickly gather information about whether a relationship exists, its direction, its strength, how much variation there is, and whether or not a relationship might be non-linear. Based on this scatterplot, we see a positive relationship between the prior knowledge of numbers and the knowledge of numbers at the end of the study. Children who started with a higher level of numeracy also ended with a higher level of numeracy. There is a considerable amount of variance in the relationship. Not every child increases their numeracy between pre-test and post-test. Children show differing amounts of increase. 2.4.2 Linear Modeling 2.4.2.1 Are there significant, bivariate associations between postnumb and the following variables? age prelet prenumb prerelat peabody Use Pearson correlations to answer this question. You do not need to check the assumptions here (though you would in real life). Hint: The base-R cor.test() function and the corr.test() function from the psych package will both conduct hypothesis tests for a correlation coefficients (the base-R cor() function only computes the coefficients). Click to show code library(psych) ## Test the correlations using psych::corr.test(): sesam %&gt;% select(postnumb, age, prelet, prenumb, prerelat, peabody) %&gt;% corr.test() ## Call:corr.test(x = .) ## Correlation matrix ## postnumb age prelet prenumb prerelat peabody ## postnumb 1.00 0.34 0.50 0.68 0.54 0.52 ## age 0.34 1.00 0.33 0.43 0.44 0.29 ## prelet 0.50 0.33 1.00 0.72 0.47 0.40 ## prenumb 0.68 0.43 0.72 1.00 0.72 0.61 ## prerelat 0.54 0.44 0.47 0.72 1.00 0.56 ## peabody 0.52 0.29 0.40 0.61 0.56 1.00 ## Sample Size ## [1] 240 ## Probability values (Entries above the diagonal are adjusted for multiple tests.) ## postnumb age prelet prenumb prerelat peabody ## postnumb 0 0 0 0 0 0 ## age 0 0 0 0 0 0 ## prelet 0 0 0 0 0 0 ## prenumb 0 0 0 0 0 0 ## prerelat 0 0 0 0 0 0 ## peabody 0 0 0 0 0 0 ## ## To see confidence intervals of the correlations, print with the short=FALSE option ## OR ## library(magrittr) ## Test the correlations using multiple cor.test() calls: sesam %$% cor.test(postnumb, age) ## ## Pearson&#39;s product-moment correlation ## ## data: postnumb and age ## t = 5.5972, df = 238, p-value = 5.979e-08 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.2241066 0.4483253 ## sample estimates: ## cor ## 0.3410578 sesam %$% cor.test(postnumb, prelet) ## ## Pearson&#39;s product-moment correlation ## ## data: postnumb and prelet ## t = 8.9986, df = 238, p-value &lt; 2.2e-16 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.4029239 0.5926632 ## sample estimates: ## cor ## 0.5038464 sesam %$% cor.test(postnumb, prenumb) ## ## Pearson&#39;s product-moment correlation ## ## data: postnumb and prenumb ## t = 14.133, df = 238, p-value &lt; 2.2e-16 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.6002172 0.7389277 ## sample estimates: ## cor ## 0.6755051 sesam %$% cor.test(postnumb, prerelat) ## ## Pearson&#39;s product-moment correlation ## ## data: postnumb and prerelat ## t = 9.9857, df = 238, p-value &lt; 2.2e-16 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.4475469 0.6268773 ## sample estimates: ## cor ## 0.5433818 sesam %$% cor.test(postnumb, peabody) ## ## Pearson&#39;s product-moment correlation ## ## data: postnumb and peabody ## t = 9.395, df = 238, p-value &lt; 2.2e-16 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.4212427 0.6067923 ## sample estimates: ## cor ## 0.520128 Click for explanation Yes, based on the p-values (remember that 0 here really means very small, making it less than .05), we would say that there are significant correlations between postnumb and all other variables in the data. (In fact, all variables in the data are significantly correlated with one another.) 2.4.2.2 Do age and prenumb explain a significant proportion of the variance in postnumb? What statistic did you use to justify your conclusion? Interpret the model fit. Use the lm() function to fit your model. Click to show code lmOut &lt;- lm(postnumb ~ age + prenumb, data = sesam) summary(lmOut) ## ## Call: ## lm(formula = postnumb ~ age + prenumb, data = sesam) ## ## Residuals: ## Min 1Q Median 3Q Max ## -38.130 -6.456 -0.456 5.435 22.568 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 7.4242 5.1854 1.432 0.154 ## age 0.1225 0.1084 1.131 0.259 ## prenumb 0.7809 0.0637 12.259 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 9.486 on 237 degrees of freedom ## Multiple R-squared: 0.4592, Adjusted R-squared: 0.4547 ## F-statistic: 100.6 on 2 and 237 DF, p-value: &lt; 2.2e-16 Click for explanation Yes, age and prenumb explain a significant amount of variability in postnumb (\\(R^2 = 0.459\\), \\(F[2, 237] = 100.629\\), \\(p &lt; 0.001\\)). We use the F statistic for the overall test of model fit to support this conclusion. The variables age and prenumb together explain 45.9% of the variability in postnumb. 2.4.2.3 Write the null and alternative hypotheses tested for in 2.4.2.2. Click for explanation Since we are testing for explained variance, our hypotheses concern the \\(R^2\\). \\[ \\begin{align*} H_0: R^2 = 0\\\\ H_1: R^2 &gt; 0 \\end{align*} \\] Note that this is a directional hypotheses because the \\(R^2\\) cannot be negative. 2.4.2.4 Define the model syntax to estimate the model from 2.4.2.2 as a path analysis using lavaan. Click to show code mod &lt;- &#39;postnumb ~ 1 + age + prenumb&#39; 2.4.2.5 Estimate the path analytic model you defined above. Use the lavaan::sem() function to estimate the model. Click to show code library(lavaan) lavOut1 &lt;- sem(mod, data = sesam) 2.4.2.6 Summarize the fitted model you estimated above. Use the summary() function to summarize the model. Click to show code summary(lavOut1) ## lavaan 0.6.16 ended normally after 1 iteration ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 4 ## ## Number of observations 240 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## postnumb ~ ## age 0.123 0.108 1.138 0.255 ## prenumb 0.781 0.063 12.336 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .postnumb 7.424 5.153 1.441 0.150 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .postnumb 88.864 8.112 10.954 0.000 In OLS regression, the predictor variables are usually treated as fixed and do not covary. We can easily relax this assumption in path analysis. 2.4.2.7 Re-estimate the path analytic model you defined in 2.4.2.4. Specify the predictors as random, correlated variables. Hint: You can make the predictors random in, at least, two ways: Modify the model syntax to specify the correlation between age and prenumb. Add fixed.x = FALSE to your sem() call. Click to show code lavOut2 &lt;- sem(mod, data = sesam, fixed.x = FALSE) ## OR ## mod &lt;- &#39; postnumb ~ 1 + age + prenumb age ~~ prenumb &#39; lavOut2 &lt;- sem(mod, data = sesam) 2.4.2.8 Summarize the fitted model you estimated above. Compare the results to those from the OLS regression in 2.4.2.2 and the path model in 2.4.2.5. Click to show code summary(lavOut2) ## lavaan 0.6.16 ended normally after 26 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 9 ## ## Number of observations 240 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## postnumb ~ ## age 0.123 0.108 1.138 0.255 ## prenumb 0.781 0.063 12.336 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## age ~~ ## prenumb 28.930 4.701 6.154 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .postnumb 7.424 5.153 1.441 0.150 ## age 51.525 0.405 127.344 0.000 ## prenumb 20.896 0.688 30.359 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .postnumb 88.864 8.112 10.954 0.000 ## age 39.291 3.587 10.954 0.000 ## prenumb 113.702 10.379 10.954 0.000 summary(lavOut1) ## lavaan 0.6.16 ended normally after 1 iteration ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 4 ## ## Number of observations 240 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## postnumb ~ ## age 0.123 0.108 1.138 0.255 ## prenumb 0.781 0.063 12.336 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .postnumb 7.424 5.153 1.441 0.150 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .postnumb 88.864 8.112 10.954 0.000 summary(lmOut) ## ## Call: ## lm(formula = postnumb ~ age + prenumb, data = sesam) ## ## Residuals: ## Min 1Q Median 3Q Max ## -38.130 -6.456 -0.456 5.435 22.568 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 7.4242 5.1854 1.432 0.154 ## age 0.1225 0.1084 1.131 0.259 ## prenumb 0.7809 0.0637 12.259 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 9.486 on 237 degrees of freedom ## Multiple R-squared: 0.4592, Adjusted R-squared: 0.4547 ## F-statistic: 100.6 on 2 and 237 DF, p-value: &lt; 2.2e-16 2.4.2.9 Consider the path model below. How many regression coefficients are estimated in this model? How many variances are estimated? How many covariances are estimated? Click for explanation Six regression coefficients (red) Four (residual) variances (blue) No covariances 2.4.2.10 Consider a multiple regression analysis with three continuous independent variables: scores on tests of language, history, and logic, and one continuous dependent variable: score on a math test. We want to know if scores on the language, history, and logic tests can predict the math test score. Sketch a path model that you could use to answer this question How many regression parameters are there? How many variances could you estimate? How many covariances could you estimate? 2.4.3 Categorical IVs Load the Drivers.sav data. # Read the data into a data frame named &#39;drivers&#39;: drivers &lt;- read_sav(&quot;Drivers.sav&quot;) %&gt;% as_factor() # This preserves the SPSS labels for nominal variables In this section, we will evaluate the following research question: Does talking on the phone interfere with people&#39;s driving skills? These data come from an experiment. The condition variable represents the three experimental conditions: Hand-held phone Hands-free phone Control (no phone) We will use condition as the IV in our models. The DV, RT, represents the participant’s reaction time (in milliseconds) during a driving simulation. 2.4.3.1 Use the package ggplot2 to create a density plot for the variable RT. What concept are we representing with this plot? Hint: Consider the lap times example from the statistical modeling section of Lecture 2. Click to show code ggplot(drivers, aes(x = RT)) + geom_density() Click for explanation This shows the distribution of all the combined reaction times from drivers in all three categories. 2.4.3.2 Modify this density plot by mapping the variable condition from your data to the fill aesthetic in ggplot. What is the difference between this plot and the previous plot? Do you think there is evidence for differences between the groups? How might we test this by fitting a model to our sample? Click to show code Hint: To modify the transparency of the densities, use the aesthetic alpha. ggplot(drivers, aes(x = RT, fill = condition)) + geom_density(alpha = .5) Click for explanation This figure models the conditional distribution of reaction time, where the type of cell phone usage is the grouping factor. Things you can look at to visually assess whether the three groups differ are the amount of overlap of the distributions, how much distance there is between the individual means, and whether the combined distribution is much different than the conditional distributions. If we are willing to assume that these conditional distributions are normally distributed and have equivalent variances, we could use a linear model with dummy-coded predictors. Aside: ANOVA vs. Linear Regression As you may know, the mathematical model underlying ANOVA is just a linear regression model with nominal IVs. So, in terms of the underlying statistical models, there is no difference between ANOVA and regression; the differences lie in the focus of the analysis. ANOVA is really a type of statistical test wherein we are testing hypotheses about the effects of some set of nominal grouping factors on some continuous outcome. When doing an ANOVA, we usually don’t interact directly with the parameter estimates from the underlying model. Regression is a type of statistical model (i.e., a way to represent a univariate distribution with a conditional mean and fixed variance). When we do a regression analysis, we primarily focus on the estimated parameters of the underling linear model. When doing ANOVA in R, we estimate the model exactly as we would for linear regression; we simply summarize the results differently. If you want to summarize your model in terms of the sums of squares table you usually see when running an ANOVA, you can supply your fitted lm object to the anova() function. This is a statistical modeling course, not a statistical testing course, so we will not consider ANOVA any further. 2.4.3.3 Estimate a linear model that will answer the research question stated in the beginning of this section. Use lm() to estimate the model. Summarize the fitted model and use the results to answer the research question. Click to show code library(magrittr) lmOut &lt;- drivers %&gt;% mutate(condition = relevel(condition, ref = &quot;control&quot;)) %$% lm(RT ~ condition) summary(lmOut) ## ## Call: ## lm(formula = RT ~ condition) ## ## Residuals: ## Min 1Q Median 3Q Max ## -317.50 -71.25 2.98 89.55 243.45 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 553.75 29.08 19.042 &lt;2e-16 *** ## conditionhand-held 100.75 41.13 2.450 0.0174 * ## conditionhands-free 63.80 41.13 1.551 0.1264 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 130.1 on 57 degrees of freedom ## Multiple R-squared: 0.09729, Adjusted R-squared: 0.06562 ## F-statistic: 3.072 on 2 and 57 DF, p-value: 0.05408 anova(lmOut) Click for explanation The effect of condition on RT is nonsignificant (\\(F[2, 57] = 3.07\\), \\(p = 0.054\\)). Therefore, based on these results, we do not have evidence for an effect of mobile phone usage on driving performance. 2.4.3.4 Use lavaan to estimate the model from 2.4.3.3 as a path model. Hint: lavaan won’t let us use factors for our categorical predictors. So, you will need to create your own dummy codes. Click to show code mod &lt;- &#39;RT ~ 1 + HH + HF&#39; lavOut &lt;- drivers %&gt;% mutate(HH = ifelse(condition == &quot;hand-held&quot;, 1, 0), # Create dummy code for &quot;hand-held&quot; condition HF = ifelse(condition == &quot;hands-free&quot;, 1, 0) # Create dummy code for &quot;hands-free&quot; condition ) %&gt;% sem(mod, data = .) # Estimate the model summary(lavOut) ## lavaan 0.6.16 ended normally after 1 iteration ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 4 ## ## Number of observations 60 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## RT ~ ## HH 100.750 40.085 2.513 0.012 ## HF 63.800 40.085 1.592 0.111 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .RT 553.750 28.344 19.537 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .RT 16068.028 2933.607 5.477 0.000 At this point, we haven’t covered the tools you need to conduct the ANOVA-style tests with path models. So, you can’t yet answer the research question with the above model. When we discuss model comparisons, you’ll get the missing tools. End of In-Class Exercises 2 "],["mediation-moderation.html", "3 Mediation &amp; Moderation", " 3 Mediation &amp; Moderation In this lecture, we will discuss two particular types of processes that we can model using path analysis: mediation and moderation. Homework before the lecture Watch the Lecture Recording for this week. Complete the Reading for this week, and answer the associated reading questions. Homework before the practical Complete the At-Home Exercises. Practical content During the practical you will work on the In-Class Exercises. "],["lecture-2.html", "3.1 Lecture", " 3.1 Lecture Researchers often have theories about possible causal processes linking multiple variables. Mediation is a particularly important example of such a process in which in an input variable, X, influences the outcome, Y, through an intermediary variable, M (the mediator). For instance, psychotherapy (X), may affect thoughts (M), which in turn affects mood (Y). We can investigate mediation via a specific sequence of linear regression equations, but path modeling will make our lives much easier. We can use path models to simultaneously estimate multiple related regression equations. So, mediation analysis is an ideal application of path modeling. In this lecture, we consider both approaches and discuss their relative strengths and weaknesses. As with mediation, researchers often posit theories involving moderation. Moderation implies that the effect of X on Y depends on another variable, Z. For instance, the effect of feedback (X) on performance (Y) may depend on age (Z). Older children might process feedback more effectively than younger children. Hence, the feedback is more effective for older children than for younger children, and the effect of feedback on performance is stronger for older children than for younger children. In such a case, we would say that age moderates the effect of feedback on performance. 3.1.1 Recordings Note: In the following recordings, the slide numbers are a bit of a mess, because I made these videos by cutting together recordings that used different slide decks. My apologies to those who are particularly distracted by continuity errors. Mediation Basics Mediation Testing Bootstrapping Moderation Basics Moderation Probing 3.1.2 Slides You can download the lecture slides here "],["reading-2.html", "3.2 Reading", " 3.2 Reading Reference Baron, R. M. &amp; Kenny, D. A. (1986). The moderator-mediator variable distinction in social psychological research: Conceptual, strategic, and statistical Considerations. Journal of Personality and Individual Differences, 51(6), 1173–1182 Questions What is mediation? Give an example of mediation. According to the authors, we must satisfy four criteria to infer mediation. What are these criteria? What is “moderation”, and how is it different from “mediation”? Give an example of moderation. What are the four methods given by Baron and Kenny as suitable ways to to study interaction effects? The authors suggest that one of the most common ways to address unreliability is to use multiple indicators. Thinking back to what you’ve learned about factor analysis, briefly explain why multiple indicators can improve reliability. How can you determine whether a variable is a mediator or moderator? Reference Hayes, A. F. (2009). Beyond Baron and Kenny: Statistical mediation analysis in the new millennium. Communication Monographs, 76(4), 408–420. Questions What is an indirect or mediated effect? What is the difference between the total and direct effect? What is the main problem with the Barron &amp; Kenny “Causal Steps Approach”? What is bootstrapping, and why is it a better way to test mediation than Sobel’s test? Explain how it is possible that “effects that don’t exist can be mediated”. "],["at-home-exercises-2.html", "3.3 At-Home Exercises", " 3.3 At-Home Exercises 3.3.1 Mediation In the first part of this practical, we will analyze the data contained in SelfEsteem.sav. These data comprise 143 observations of the following variables.1 case: Participant ID number ParAtt: Parental Attachment PeerAtt: Peer Attachment Emp: Empathy ProSoc: Prosocial behavior Aggr: Aggression SelfEst: Self-esteem 3.3.1.1 Load the SelfEsteem.sav data. Note: Unless otherwise specified, all analyses in Section 3.3.1 apply to these data. Click to show code library(haven) seData &lt;- read_sav(&quot;SelfEsteem.sav&quot;) Suppose we are interested in the (indirect) effect of peer attachment on self-esteem, and whether empathy has a mediating effect on this relationship. We might generate the following hypotheses: Better peer relationships promote higher self esteem This effect is mediated by a student’s empathy levels, where better peer relationships increase empathy, and higher levels of empathy lead to higher self-esteem. To evaluate these hypotheses, we will use lavaan to estimate a path model. 3.3.1.2 Draw a path model (on paper) that can be used to test the above hypotheses. Label the input (X), outcome (Y), and mediator/intermediary (M). Label the paths a, b, and c’. Hint: Refer back to the Mediation Basics lecture if you need help here. Click for explanation 3.3.1.3 Specify the lavaan model syntax implied by the path diagram shown above. Save the resulting character string as an object in your environment. Hint: Refer back to the example in which opinions of systematic racism mediate the relationship between political affiliation and support for affirmative action policies from the Mediation Testing lecture this week. Click to show code mod &lt;- &#39; ## Equation for outcome: SelfEst ~ Emp + PeerAtt ## Equation for the mediator: Emp ~ PeerAtt &#39; 3.3.1.4 Use the lavaan::sem() function to estimate the model defined in 3.3.1.3. Use the default settings in sem(). Click to show code library(lavaan) out &lt;- sem(mod, data = seData) 3.3.1.5 Explore the summary of the fitted model. Which numbers correspond to the a, b, and c’ paths? Interpret these paths. Do the direction of the effects seem to align with our hypothesis? Click to show code summary(out) ## lavaan 0.6.16 ended normally after 1 iteration ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 5 ## ## Number of observations 143 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## SelfEst ~ ## Emp 0.234 0.091 2.568 0.010 ## PeerAtt 0.174 0.088 1.968 0.049 ## Emp ~ ## PeerAtt 0.349 0.076 4.628 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .SelfEst 0.934 0.110 8.456 0.000 ## .Emp 0.785 0.093 8.456 0.000 Click for explanation The results show estimates of the a path (Emp ~ PeerAtt), the b path (SelfEst ~ Emp), and the c’ path (SelfEst ~ PeerAtt). All three of these effects are positive and significant, including the direct effect of PeerAtt on SelfEst (\\(\\beta = 0.174\\), \\(Z = 1.97\\), \\(p = 0.025\\)), and the parts of the indirect effect made up by the effect of PeerAtt on Emp (\\(\\beta = 0.349\\), \\(Z = 4.63\\), \\(p = 0\\)), and Emp on SelfEst (\\(\\beta = 0.234\\), \\(Z = 2.57\\), \\(p = 0.005\\)). We can see that the direction of the effects seems to support of our hypotheses, but without taking the next steps to investigate the indirect effect, we should be hesitant to say more. Remember that an indirect effect (IE) is the product of multiple regression slopes. Therefore, to estimate an IE, we must define this product in our model syntax. In lavaan, we define the new IE parameter in two steps. Label the relevant regression paths. Use the labels to define a new parameter that represent the desired IE. We can define new parameters in lavaan model syntax via the := operator. The lavaan website contains a tutorial on this procedure: http://lavaan.ugent.be/tutorial/mediation.html 3.3.1.6 Use the procedure described above to modify the model syntax from 3.3.1.3 by adding the definition of the hypothesized IE from PeerAtt to SelfEst. Click to show code mod &lt;- &#39; ## Equation for outcome: SelfEst ~ b * Emp + PeerAtt ## Equation for mediator: Emp ~ a * PeerAtt ## Indirect effect: ie := a * b &#39; Click for explanation Notice that I only label the parameters that I will use to define the IE. You are free to label any parameter that you like, but I choose the to label only the minimally sufficient set to avoid cluttering the code/output. 3.3.1.7 Use lavaan::sem() to estimate the model with the IEs defined. Use the default settings for sem(). Is the hypothesized IE significant according to the default tests? Hint: Refer to the Mediation Testing lecture Click to show code out &lt;- sem(mod, data = seData) summary(out) ## lavaan 0.6.16 ended normally after 1 iteration ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 5 ## ## Number of observations 143 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## SelfEst ~ ## Emp (b) 0.234 0.091 2.568 0.010 ## PeerAtt 0.174 0.088 1.968 0.049 ## Emp ~ ## PeerAtt (a) 0.349 0.076 4.628 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .SelfEst 0.934 0.110 8.456 0.000 ## .Emp 0.785 0.093 8.456 0.000 ## ## Defined Parameters: ## Estimate Std.Err z-value P(&gt;|z|) ## ie 0.082 0.036 2.245 0.025 Click for explanation The IE of Peer Attachment on Self Esteem through Empathy is statistically significant (\\(\\hat{\\textit{IE}} = 0.082\\), \\(Z = 2.25\\), \\(p = 0.012\\)). Note: The p-value above doesn’t match the output because we’re testing a directional hypothesis, but lavaan conducts two-tailed tests for the model parameters. As we learned in the lecture, the above test of the indirect effect is equivalent to Sobel’s Z test (which we don’t really want). An appropriate, robust test of the indirect effect requires bootstrapping, which we will do later this week as part of the in-class exercises. For now, we’ll add another input variable to our model: parental attachment. We will use this model to evaluate the following research questions: Is there a direct effect of parental attachment on self-esteem, after controlling for peer attachment and empathy? Is there a direct effect of peer attachment on self-esteem, after controlling for parental attachment and empathy? Is the effect of parental attachment on self-esteem mediated by empathy, after controlling for peer attachment? Is the effect of peer attachment on self-esteem mediated by empathy, after controlling for parental attachment? 3.3.1.8 Run the path model needed to test the research questions listed above. Specify the lavaan model syntax implied by the research questions. Allow peer attachment and parental attachment to covary. Define two new parameters to represent the hypothesized indirect effects. Estimate the model using lavaan::sem(). Use the default settings in sem(). Investigate the model summary. Click to show code mod &lt;- &#39; ## Equation for outcome: SelfEst ~ b * Emp + ParAtt + PeerAtt ## Equation for mediator: Emp ~ a1 * ParAtt + a2 * PeerAtt ## Covariance: ParAtt ~~ PeerAtt ie_ParAtt := a1 * b ie_PeerAtt := a2 * b &#39; out &lt;- sem(mod, data = seData) summary(out) ## lavaan 0.6.16 ended normally after 16 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 10 ## ## Number of observations 143 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## SelfEst ~ ## Emp (b) 0.206 0.088 2.357 0.018 ## ParAtt 0.287 0.078 3.650 0.000 ## PeerAtt 0.024 0.094 0.252 0.801 ## Emp ~ ## ParAtt (a1) 0.078 0.075 1.045 0.296 ## PeerAtt (a2) 0.306 0.086 3.557 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## ParAtt ~~ ## PeerAtt 0.537 0.103 5.215 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .SelfEst 0.854 0.101 8.456 0.000 ## .Emp 0.779 0.092 8.456 0.000 ## ParAtt 1.277 0.151 8.456 0.000 ## PeerAtt 0.963 0.114 8.456 0.000 ## ## Defined Parameters: ## Estimate Std.Err z-value P(&gt;|z|) ## ie_ParAtt 0.016 0.017 0.956 0.339 ## ie_PeerAtt 0.063 0.032 1.965 0.049 3.3.1.9 What can we say about the two indirect effects? Can we say that empathy mediates both paths? Click to show explanation According to the Sobel-style test, after controlling for parental attachment, the indirect effect of peer attachment on self-esteem was statistically significant (\\(\\hat{IE} = 0.063\\), \\(Z = 1.96\\), \\(p = 0.049\\)), as was the analogous direct effect (\\(\\hat{\\beta} = 0.306\\), \\(Z = 3.56\\), \\(p &lt; 0.001\\)). After controlling for peer attachment, neither the indirect effect (\\(\\hat{IE} = 0.016\\), \\(Z = 0.96\\), \\(p = 0.339\\)) nor the direct effect (\\(\\hat{\\beta} = 0.078\\), \\(Z = 1.05\\), \\(p = 0.296\\)) of parental attachment on self-esteem was significant, though. 3.3.2 Moderation Remember that moderation attempts to describe when one variable influences another. For the home exercise, we’ll go back to the Sesame Street data we worked with for the in-class exercises last week. 3.3.2.1 Load the Sesam2.sav data.2 NOTE: Unless otherwise specified, all analyses in Section 3.3.2 use these data. Click to show code # Read the data into an object called &#39;sesam2&#39;: sesam2 &lt;- read_sav(&quot;Sesam2.sav&quot;) VIEWCAT is a nominal grouping variable, but it is represented as a numeric variable in the sesam2 data. The levels represent the following frequencies of Sesame Street viewership of the children in the data: VIEWCAT = 1: Rarely/Never VIEWCAT = 2: 2–3 times a week VIEWCAT = 3: 4–5 times a week VIEWCAT = 4: &gt; 5 times a week 3.3.2.2 Convert VIEWCAT into a factor. Make sure that VIEWCAT = 1 is the reference group. Hints: You can identify the reference group with the levels() or contrasts() functions. The reference group is the group labelled with the first level printed by levels(). When you run contrasts(), you will see a pattern matrix that defines a certain dummy coding scheme. The reference group is the group that has zeros in each column of this matrix. If you need to change the reference group, you can use the relevel() function. Click to show code library(forcats) ## Convert &#39;VIEWCAT&#39; to a factor: sesam2 &lt;- sesam2 %&gt;% mutate(VIEWCAT = factor(VIEWCAT)) ## Optionally specify the labels # sesam2 &lt;- # sesam2 %&gt;% # mutate(VIEWCAT = factor(VIEWCAT, # levels = c(1, 2, 3, 4), # labels = c(&quot;Rarely/never&quot;, # &quot;2-3 times per week&quot;, # &quot;4-5 times per week&quot;, # &quot;&gt; 5 times per week&quot;))) ## Check the reference group: levels(sesam2$VIEWCAT) ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; contrasts(sesam2$VIEWCAT) ## 2 3 4 ## 1 0 0 0 ## 2 1 0 0 ## 3 0 1 0 ## 4 0 0 1 ## If necessary, relevel # sesam &lt;- # sesam2 %&gt;% # mutate(VIEWCAT = relevel(VIEWCAT, 1)) 3.3.2.3 Use lm() to estimate a multiple regression model wherein VIEWCAT predicts POSTNUMB. Summarize the model. Interpret the estimates. Click to show code lmOut &lt;- lm(POSTNUMB ~ VIEWCAT, data = sesam2) summary(lmOut) ## ## Call: ## lm(formula = POSTNUMB ~ VIEWCAT, data = sesam2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -25.474 -7.942 0.240 8.526 25.240 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 18.760 2.316 8.102 8.95e-14 *** ## VIEWCAT2 9.331 2.900 3.218 0.00154 ** ## VIEWCAT3 14.714 2.777 5.298 3.49e-07 *** ## VIEWCAT4 18.032 2.809 6.419 1.24e-09 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 11.58 on 175 degrees of freedom ## Multiple R-squared: 0.2102, Adjusted R-squared: 0.1967 ## F-statistic: 15.53 on 3 and 175 DF, p-value: 5.337e-09 Click for explanation Viewing category explains a statistically significant proportion of the variance in the post-test score of numbers learned (\\(R^2 = 0.21\\), \\(F(3, 175) = 15.53\\), \\(p &lt; 0.001\\)). Kids who never or rarely watched Sesame Street had an average score of 18.76 on the post-test. Kids with weekly viewing habits of 2–3, 4–5, or 5+ times per week all had significantly higher scores on the post-test than kids who never or rarely watched Sesame Street (2–3: \\(\\hat{\\beta} = 9.33\\), \\(t = 3.22\\), \\(p = 0.002\\); 4–5: \\(\\hat{\\beta} = 14.71\\), \\(t = 5.3\\), \\(p &lt; 0.001\\); 5+: \\(\\hat{\\beta} = 18.03\\), \\(t = 6.42\\), \\(p &lt; 0.001\\)). If we compare the box plot, kernel density plot, and model output below, the relationships between the regression coefficient estimates for the viewing categories and the group means should be evident. 3.3.2.4 Use ggplot() to make a scatterplot with AGE on the x-axis and POSTNUMB on the y-axis. Color the points according to the their VIEWCAT level. Save the plot object to a variable in your environment. Hint: You can map color to the levels of a variable on your dataset by assigning the variable names to the color argument of the aes() function in ggplot(). Click to show code library(ggplot2) ## Add aes(..., color = VIEWCAT) to get different colors for each group: p &lt;- ggplot(sesam2, aes(x = AGE, y = POSTNUMB, color = VIEWCAT)) + geom_point() # Add points for scatterplot ## Print the plot stored as &#39;p&#39;: p We assigned the global color aesthetic to the VIEWCAT variable, so the points are colored based on their group. 3.3.2.5 Add linear regression lines for each group to the above scatterplot. Hints: You can add regression lines with ggplot2::geom_smooth() To get linear regression lines, set the argument method = \"lm\" To omit error envelopes, set the argument se = FALSE Click to show code ## Add OLS best-fit lines: p + geom_smooth(method = &quot;lm&quot;, se = FALSE) The global color aesthetic assignment from above carries through to any additional plot elements that we add, including the regression lines. So, we also get a separate regression line for each VIEWCAT group. 3.3.2.6 How would you interpret the pattern of regression lines above? Click for explanation All the lines show a positive slope, so post-test number recognition appears to increase along with increasing age. The lines are not parallel, though. So VIEWCAT may be moderating the effect of AGE on POSTNUMB. Based on the figure we just created, we may want to test for moderation in our regression model. To do so, we need to add an interaction between AGE and VIEWCAT. The VIEWCAT factor is represented by 3 dummy codes in our model, though. So when we interact AGE and VIEWCAT, we will create 3 interaction terms. To test the overall moderating influence of VIEWCAT, we need to conduct a multiparameter hypothesis test of all 3 interaction terms. One way that we can go about implementing such a test is through a hierarchical regression analysis entailing three steps: Estimate the additive model wherein we regress POSTNUMB onto AGE and VIEWCAT without any interaction. Estimate the moderated model by adding the interaction between AGE and VIEWCAT into the additive model. Conduct a \\(\\Delta R^2\\) test to compare the fit of the two models. 3.3.2.7 Conduct the hierarchical regression analysis described above. Does VIEWCAT significantly moderate the effect of AGE on POSTNUMB? Provide statistical justification for your conclusion. Click to show code ## Estimate the additive model a view the results: results_add &lt;- lm(POSTNUMB ~ VIEWCAT + AGE, data = sesam2) summary(results_add) ## ## Call: ## lm(formula = POSTNUMB ~ VIEWCAT + AGE, data = sesam2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -23.680 -8.003 -0.070 8.464 22.635 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -10.1056 6.5091 -1.553 0.12235 ## VIEWCAT2 9.1453 2.7390 3.339 0.00103 ** ## VIEWCAT3 13.8602 2.6294 5.271 3.98e-07 *** ## VIEWCAT4 16.9215 2.6636 6.353 1.79e-09 *** ## AGE 0.5750 0.1221 4.708 5.08e-06 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 10.94 on 174 degrees of freedom ## Multiple R-squared: 0.2995, Adjusted R-squared: 0.2834 ## F-statistic: 18.6 on 4 and 174 DF, p-value: 9.642e-13 ## Estimate the moderated model and view the results: results_mod &lt;- lm(POSTNUMB ~ VIEWCAT * AGE, data = sesam2) summary(results_mod) ## ## Call: ## lm(formula = POSTNUMB ~ VIEWCAT * AGE, data = sesam2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -23.8371 -8.2387 0.6158 8.7988 22.5611 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -18.7211 15.5883 -1.201 0.2314 ## VIEWCAT2 9.9741 20.6227 0.484 0.6293 ## VIEWCAT3 23.5825 19.3591 1.218 0.2248 ## VIEWCAT4 34.3969 19.3600 1.777 0.0774 . ## AGE 0.7466 0.3074 2.429 0.0162 * ## VIEWCAT2:AGE -0.0175 0.4060 -0.043 0.9657 ## VIEWCAT3:AGE -0.1930 0.3782 -0.510 0.6104 ## VIEWCAT4:AGE -0.3416 0.3770 -0.906 0.3663 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 10.99 on 171 degrees of freedom ## Multiple R-squared: 0.3046, Adjusted R-squared: 0.2762 ## F-statistic: 10.7 on 7 and 171 DF, p-value: 3.79e-11 ## Test for moderation: anova(results_add, results_mod) Click for explanation VIEWCAT does not significantly moderate the effect of AGE on POSTNUMB (\\(F[3, 171] = 0.422\\), \\(p = 0.738\\)). 3.3.2.8 Sketch the analytic path diagrams for the additive and moderated models you estimated in 3.3.2.7 (on paper). Click for explanation Additive Model Moderated Model End of At-Home Exercises 3 These data were simulated from the covariance matrix provided in Laible, D. J., Carlo, G., &amp; Roesch, S. C. (2004). Pathways to self-esteem in late adolescence: The role of parent and peer attachment, empathy, and social behaviours. Journal of adolescence, 27(6), 703-716.↩︎ These data are from the very interesting study: Ball, S., &amp; Bogatz, G. A. (1970). A Summary of the Major Findings in” The First Year of Sesame Street: An Evaluation”.↩︎ "],["in-class-exercises-2.html", "3.4 In-Class Exercises", " 3.4 In-Class Exercises 3.4.1 Mediation In this practical, we’ll go back to the data from the at-home exercises, SelfEsteem.sav. Recall that these data comprise 143 observations of the following variables. case: Participant ID number ParAtt: Parental Attachment PeerAtt: Peer Attachment Emp: Empathy ProSoc: Prosocial behavior Aggr: Aggression SelfEst: Self-esteem When we last worked with the data, we built a model with one mediator (Emp), creating indirect effects between our predictors ParAtt and PeerAtt, and our outcome variable SelfEst. Below, you will estimate a more complex, multiple-mediator model. 3.4.1.1 Load the data into the object seData using haven::read_sav() Click to show code library(haven) seData &lt;- read_sav(&quot;SelfEsteem.sav&quot;) For this analysis, we are interested in the (indirect) effects of parental and peer attachment on self-esteem. Furthermore, we want to evaluate the mediating roles of empathy and social behavior (i.e., prosocial behavior and aggression). Specifically, we have the following hypotheses. Better peer relationships will promote higher self-esteem via a three-step indirect process. Better peer relationships will increase empathy levels. Higher empathy will increase prosocial behavior and decrease aggressive behavior. More prosocial behaviors and less aggressive behavior will both produce higher self-esteem. Better relationships with parents directly increase self-esteem. To evaluate these hypotheses, we will use lavaan to estimate the following multiple mediator model as a path model. 3.4.1.2 Specify the lavaan model syntax implied by the path diagram shown above. Save the resulting character string as an object in your environment. Click to show code mod0 &lt;- &#39; ## Equation for outcome: SelfEst ~ ProSoc + Aggr + Emp + ParAtt + PeerAtt ## Equations for stage 2 mediators: ProSoc ~ PeerAtt + ParAtt + Emp Aggr ~ PeerAtt + ParAtt + Emp ## Equation for stage 1 mediator: Emp ~ ParAtt + PeerAtt ## Covariances: ProSoc ~~ Aggr ParAtt ~~ PeerAtt &#39; 3.4.1.3 Use the lavaan::sem() function to estimate the model defined in 3.4.1.2. Use the default settings in sem(). Summarize the fitted model. Click to show code library(lavaan) out &lt;- sem(mod0, data = seData) summary(out) ## lavaan 0.6.16 ended normally after 16 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 21 ## ## Number of observations 143 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## SelfEst ~ ## ProSoc 0.252 0.096 2.634 0.008 ## Aggr 0.185 0.085 2.172 0.030 ## Emp 0.143 0.098 1.460 0.144 ## ParAtt 0.244 0.078 3.133 0.002 ## PeerAtt 0.051 0.091 0.555 0.579 ## ProSoc ~ ## PeerAtt -0.037 0.080 -0.469 0.639 ## ParAtt 0.193 0.067 2.886 0.004 ## Emp 0.477 0.074 6.411 0.000 ## Aggr ~ ## PeerAtt -0.095 0.090 -1.055 0.291 ## ParAtt -0.034 0.075 -0.454 0.650 ## Emp -0.309 0.084 -3.697 0.000 ## Emp ~ ## ParAtt 0.078 0.075 1.045 0.296 ## PeerAtt 0.306 0.086 3.557 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## .ProSoc ~~ ## .Aggr -0.086 0.058 -1.476 0.140 ## ParAtt ~~ ## PeerAtt 0.537 0.103 5.215 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .SelfEst 0.796 0.094 8.456 0.000 ## .ProSoc 0.618 0.073 8.456 0.000 ## .Aggr 0.777 0.092 8.456 0.000 ## .Emp 0.779 0.092 8.456 0.000 ## ParAtt 1.277 0.151 8.456 0.000 ## PeerAtt 0.963 0.114 8.456 0.000 3.4.1.4 Considering the parameter estimates from 3.4.1.3, what can you say about the hypotheses? Click for explanation Notice that all of the hypotheses stated above are explicitly directional. Hence, when evaluating the significance of the structural paths that speak to these hypotheses, we should use one-tailed tests. We cannot ask lavaan to return one-tailed p-values, but we have no need to do so. We can simply divide the two-tailed p-values in half. The significant direct effect of ParAtt on SelfEst (\\(\\beta = 0.244\\), \\(Z = 3.13\\), \\(p = 0.001\\)) and the lack of a significant direct effect of PeerAtt on SelfEst (\\(\\beta = 0.051\\), \\(Z = 0.555\\), \\(p = 0.29\\)) align with our hypotheses. The remaining patterns of individual estimates also seem to conform to the hypotheses (e.g., all of the individual paths comprising the indirect effects of PeerAtt on SelfEst are significant). We cannot make any firm conclusions until we actually estimate and test the indirect effects, though. 3.4.1.5 Modify the model syntax from 3.4.1.2 by adding definitions of the two hypothesized IEs from PeerAtt to SelfEst. Click to show code You can use any labeling scheme that makes sense to you, but I recommend adopting some kind of systematic rule. Here, I will label the individual estimates in terms of the short variable names used in the path diagram above. mod &lt;- &#39; ## Equation for outcome: SelfEst ~ y_m21 * ProSoc + y_m22 * Aggr + Emp + ParAtt + PeerAtt ## Equations for stage 2 mediators: ProSoc ~ m21_x2 * PeerAtt + ParAtt + m21_m1 * Emp Aggr ~ m22_x2 * PeerAtt + ParAtt + m22_m1 * Emp ## Equation for stage 1 mediator: Emp ~ ParAtt + m1_x2 * PeerAtt ## Covariances: ProSoc ~~ Aggr ParAtt ~~ PeerAtt ## Indirect effects: ie_pro := m1_x2 * m21_m1 * y_m21 ie_agg := m1_x2 * m22_m1 * y_m22 &#39; 3.4.1.6 Use lavaan::sem() to estimate the model with the IEs defined. Use the default settings for sem(). Are the hypothesized IEs significant according to the default tests? Click to show code out &lt;- sem(mod, data = seData) summary(out) ## lavaan 0.6.16 ended normally after 16 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 21 ## ## Number of observations 143 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## SelfEst ~ ## ProSoc (y_21) 0.252 0.096 2.634 0.008 ## Aggr (y_22) 0.185 0.085 2.172 0.030 ## Emp 0.143 0.098 1.460 0.144 ## ParAtt 0.244 0.078 3.133 0.002 ## PerAtt 0.051 0.091 0.555 0.579 ## ProSoc ~ ## PerAtt (m21_2) -0.037 0.080 -0.469 0.639 ## ParAtt 0.193 0.067 2.886 0.004 ## Emp (m21_1) 0.477 0.074 6.411 0.000 ## Aggr ~ ## PerAtt (m22_2) -0.095 0.090 -1.055 0.291 ## ParAtt -0.034 0.075 -0.454 0.650 ## Emp (m22_1) -0.309 0.084 -3.697 0.000 ## Emp ~ ## ParAtt 0.078 0.075 1.045 0.296 ## PerAtt (m1_2) 0.306 0.086 3.557 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## .ProSoc ~~ ## .Aggr -0.086 0.058 -1.476 0.140 ## ParAtt ~~ ## PeerAtt 0.537 0.103 5.215 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .SelfEst 0.796 0.094 8.456 0.000 ## .ProSoc 0.618 0.073 8.456 0.000 ## .Aggr 0.777 0.092 8.456 0.000 ## .Emp 0.779 0.092 8.456 0.000 ## ParAtt 1.277 0.151 8.456 0.000 ## PeerAtt 0.963 0.114 8.456 0.000 ## ## Defined Parameters: ## Estimate Std.Err z-value P(&gt;|z|) ## ie_pro 0.037 0.018 2.010 0.044 ## ie_agg -0.017 0.011 -1.657 0.098 Click for explanation The IE of Peer Attachment on Self Esteem through Empathy and Prosocial Behavior is significant (\\(\\hat{\\textit{IE}} = 0.037\\), \\(Z = 2.01\\), \\(p = 0.022\\)), as is the analogous IE through Aggressive Behavior (\\(\\hat{\\textit{IE}} = -0.017\\), \\(Z = -1.66\\), \\(p = 0.049\\)). Though, this latter effect is just barely significant at the \\(\\alpha = 0.05\\) level. The tests we used to evaluate the significance of the IEs in 3.4.1.6 are flawed because they assume normal sampling distributions for the IEs. However the IEs are defined as products of multiple, normally distributed, regression slopes. So the IEs themselves cannot be normally distributed (at least in finite samples), and the results of the normal-theory significance tests may be misleading. To get an accurate test of the IEs, we should use bootstrapping to generate an empirical sampling distribution for each IE. In lavaan, we implement bootstrapping by specifying the se = \"bootstrap\" option in the fitting function (i.e., the cfa() or sem() function) and specifying the number of bootstrap samples via the bootstrap option. Workflow Tip To draw reliable conclusions from bootstrapped results, we need many bootstrap samples (i.e., B &gt; 1000), but we must estimate the full model for each of these samples, so the estimation can take a long time. To avoid too much frustration, you should first estimate the model without bootstrapping to make sure everything is specified correctly. Only after you are certain that your code is correct do you want to run the full bootstrapped version. 3.4.1.7 Re-estimate the model from 3.4.1.6 using 1000 bootstrap samples. Other than the se and bootstrap options, use the defaults. Are the hypothesized IEs significant according to the bootstrap-based test statistics? Click to show code ## Set a seed to get replicable bootstrap samples: set.seed(235711) ## Estimate the model with bootstrapping: out_boot &lt;- sem(mod, data = seData, se = &quot;bootstrap&quot;, bootstrap = 1000) ## Summarize the model: summary(out_boot) ## lavaan 0.6.16 ended normally after 16 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 21 ## ## Number of observations 143 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Bootstrap ## Number of requested bootstrap draws 1000 ## Number of successful bootstrap draws 1000 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## SelfEst ~ ## ProSoc (y_21) 0.252 0.100 2.529 0.011 ## Aggr (y_22) 0.185 0.085 2.174 0.030 ## Emp 0.143 0.095 1.507 0.132 ## ParAtt 0.244 0.079 3.089 0.002 ## PerAtt 0.051 0.095 0.530 0.596 ## ProSoc ~ ## PerAtt (m21_2) -0.037 0.082 -0.456 0.648 ## ParAtt 0.193 0.068 2.831 0.005 ## Emp (m21_1) 0.477 0.078 6.092 0.000 ## Aggr ~ ## PerAtt (m22_2) -0.095 0.087 -1.093 0.275 ## ParAtt -0.034 0.076 -0.448 0.654 ## Emp (m22_1) -0.309 0.092 -3.356 0.001 ## Emp ~ ## ParAtt 0.078 0.072 1.092 0.275 ## PerAtt (m1_2) 0.306 0.079 3.896 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## .ProSoc ~~ ## .Aggr -0.086 0.058 -1.493 0.135 ## ParAtt ~~ ## PeerAtt 0.537 0.128 4.195 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .SelfEst 0.796 0.082 9.698 0.000 ## .ProSoc 0.618 0.068 9.114 0.000 ## .Aggr 0.777 0.104 7.476 0.000 ## .Emp 0.779 0.090 8.651 0.000 ## ParAtt 1.277 0.197 6.473 0.000 ## PeerAtt 0.963 0.105 9.203 0.000 ## ## Defined Parameters: ## Estimate Std.Err z-value P(&gt;|z|) ## ie_pro 0.037 0.019 1.891 0.059 ## ie_agg -0.017 0.011 -1.638 0.101 Click for explanation As with the normal-theory tests, the hypothesized IE of Peer Attachment on Self Esteem was significant (\\(\\hat{\\textit{IE}} = 0.037\\), \\(Z = 1.89\\), \\(p = 0.029\\)), but the IE of Aggressive Behavior has crossed into nonsignificant territory (\\(\\hat{\\textit{IE}} = -0.017\\), \\(Z = -1.64\\), \\(p = 0.051\\)). Note: Bootstrapping is a stochastic method, so each run can provide different results. Since the indirect effect of aggressive behavior is so close to the critical value, you may come to a different conclusions vis-á-vis statistical significance if you run this analysis with a different random number seed or a different number of bootstrap samples. When you use the summary() function to summarize the bootstrapped model from 3.4.1.7, the output will probably look pretty much the same as it did in 3.4.1.6, but it’s not. The standard errors and test statistics in the bootstrapped summary are derived from empirical sampling distributions, whereas these values are based on an assumed normal sampling distribution in 3.4.1.6. The standard method of testing IEs with bootstrapping is to compute confidence intervals (CIs) from the empirical sampling distribution of the IEs. In lavaan, we can compute basic (percentile, 95%) CIs by adding the ci = TRUE option to the summary() function. To evaluate our directional hypotheses at an \\(\\alpha = 0.05\\) level, however, we need to compute 90% CIs. We can get more control over the summary statistics (include the CIs) with the parameterEstimates() function. 3.4.1.8 Check the documentation for lavaan::parameterEstimates(). Click to show code ?parameterEstimates 3.4.1.9 Use the parameterEstimates() function to compute bootstrapped CIs for the hypothesized IEs. Compute percentile CIs. Are the IEs significant according to the bootstrapped CIs? Click to show code parameterEstimates(out_boot, ci = TRUE, level = 0.9) Click for explanation When evaluating a directional hypothesis with a CI, we only consider one of the interval’s boundaries. For a hypothesized positive effect, we check only if the lower boundary is greater than zero. For a hypothesized negative effect, we check if the upper boundary is less than zero. As with the previous tests, the IE of Peer Attachment on Self Esteem through Empathy and Prosocial Behavior is significant (\\(\\hat{\\textit{IE}} = 0.037\\), \\(95\\% ~ CI = [0.009; \\infty]\\)), but the analogous IE through Aggressive Behavior is not quite significant (\\(\\hat{\\textit{IE}} = -0.017\\), \\(95\\% ~ CI = [-\\infty; -0.003]\\)). 3.4.1.10 Based on the analyses you’ve conducted here, what do you conclude vis-à-vis the original hypotheses? Click for explanation When using normal-theory tests, both hypothesized indirect effects between Peer Attachment and Self Esteem were supported in that the IE through Empathy and Prosocial Behavior as well as the IE through Empathy and Aggressive Behavior were both significant. The hypothesized direct effect of Parent Attachment on Self Esteem was also born out via a significant direct effect in the model. When testing the indirect effects with bootstrapping, however, the effect through Aggressive Behavior was nonsignificant. Since bootstrapping gives a more accurate test of the indirect effect, we should probably trust these results more than the normal-theory results. We should not infer a significant indirect effect of Peer Attachment on Self Esteem transmitted through Empathy and Aggressive Behavior. These results may not tell the whole story, though. We have not tested for indirect effects between Parent Attachment and Self Esteem, and we have not evaluated simpler indirect effects between Peer Attachment and Self Esteem (e.g., PeerAtt \\(\\rightarrow\\) Emp \\(\\rightarrow\\) SelfEst). 3.4.2 Moderation We will first analyze a synthetic version of the Outlook on Life Survey data. The original data were collected in the United States in 2012 to measure, among other things, attitudes about racial issues, opinions of the Federal government, and beliefs about the future. We will work with a synthesized subset of the original data. You can access these synthetic data as outlook.rds. This dataset comprises 2288 observations of the following 13 variables. d1:d3: Three observed indicators of a construct measuring disillusionment with the US Federal government. Higher scores indicate more disillusionment s1:s4: Four observed indicators of a construct measuring the perceived achievability of material success. Higher scores indicate greater perceived achievability progress: A single item assessing perceived progress toward achieving the “American Dream” Higher scores indicate greater perceived progress merit: A single item assessing endorsement of the meritocratic ideal that hard work leads to success. Higher scores indicate stronger endorsement of the meritocratic ideal lib2Con: A single item assessing liberal-to-conservative orientation Lower scores are more liberal, higher scores are more conservative party: A four-level factor indicating self-reported political party affiliation disillusion: A scale score representing disillusionment with the US Federal government Created as the mean of d1:d3 success: A scale score representing the perceived achievability of material success Created as the mean of s1:s4 To satisfy the access and licensing conditions under which the original data are distributed, the data contained in outlook.rds were synthesized from the original variables using the methods described by Volker and Vink (2021). You can access the original data here, and you can access the code used to process the data here. 3.4.2.1 Read in the outlook.rds dataset. Hint: An RDS file is an R object that’s been saved to a file. To read in this type of file, we use readRDS() from base R. Click to show code outlook &lt;- readRDS(&quot;outlook.rds&quot;) 3.4.2.2 Summarize the outlook data to get a sense of their characteristics. Click to show code head(outlook) summary(outlook) ## d1 d2 d3 s1 ## Min. :1.000 Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.:3.000 1st Qu.:2.000 1st Qu.:3.000 1st Qu.:2.000 ## Median :4.000 Median :3.000 Median :4.000 Median :2.000 ## Mean :3.642 Mean :3.218 Mean :3.629 Mean :2.288 ## 3rd Qu.:4.000 3rd Qu.:4.000 3rd Qu.:4.000 3rd Qu.:3.000 ## Max. :5.000 Max. :5.000 Max. :5.000 Max. :4.000 ## s2 s3 s4 progress ## Min. :1.000 Min. :1.000 Min. :1.000 Min. : 1.000 ## 1st Qu.:1.000 1st Qu.:1.000 1st Qu.:2.000 1st Qu.: 5.000 ## Median :2.000 Median :2.000 Median :2.000 Median : 7.000 ## Mean :1.922 Mean :2.012 Mean :2.469 Mean : 6.432 ## 3rd Qu.:2.000 3rd Qu.:3.000 3rd Qu.:3.000 3rd Qu.: 8.000 ## Max. :4.000 Max. :4.000 Max. :4.000 Max. :10.000 ## merit lib2Con party disillusion ## Min. :1.000 Min. :1.000 republican : 332 Min. :1.000 ## 1st Qu.:4.000 1st Qu.:3.000 democrat :1264 1st Qu.:3.000 ## Median :5.000 Median :4.000 independent: 576 Median :3.667 ## Mean :4.826 Mean :3.998 other : 116 Mean :3.497 ## 3rd Qu.:6.000 3rd Qu.:5.000 3rd Qu.:4.000 ## Max. :7.000 Max. :7.000 Max. :5.000 ## success ## Min. :1.000 ## 1st Qu.:1.750 ## Median :2.000 ## Mean :2.173 ## 3rd Qu.:2.500 ## Max. :4.000 str(outlook) ## &#39;data.frame&#39;: 2288 obs. of 13 variables: ## $ d1 : num 4 4 4 5 5 4 5 4 4 4 ... ## $ d2 : num 4 2 4 4 3 5 4 2 4 5 ... ## $ d3 : num 4 4 4 5 4 4 4 3 3 4 ... ## $ s1 : num 3 3 4 2 2 2 2 1 3 3 ... ## $ s2 : num 2 2 2 1 1 2 1 1 2 2 ... ## $ s3 : num 3 2 4 1 2 1 1 1 3 2 ... ## $ s4 : num 3 3 3 1 2 3 3 2 2 2 ... ## $ progress : num 8 4 6 1 6 5 7 6 9 7 ... ## $ merit : num 6 5 5 4 3 4 2 5 5 5 ... ## $ lib2Con : num 5 6 4 1 4 4 4 4 4 5 ... ## $ party : Factor w/ 4 levels &quot;republican&quot;,&quot;democrat&quot;,..: 1 3 3 2 2 2 2 2 4 1 ... ## $ disillusion: num 4 3.33 4 4.67 4 ... ## $ success : num 2.75 2.5 3.25 1.25 1.75 2 1.75 1.25 2.5 2.25 ... We will first use OLS regression to estimate a model encoding the following relations: Belief in the achievability of success, success, predicts perceived progress toward the American Dream, progress, as the focal effect. Disillusionment with the US Federal government, disillusion moderates the success \\(\\rightarrow\\) progress effect. Placement on the liberal-to-conservative continuum, lib2Con is partialed out as a covariate. 3.4.2.3 Draw the conceptual path diagram for the model described above. Click for explanation 3.4.2.4 Write out the regression equation necessary to evaluate the moderation hypothesis described above. Click for explanation \\[ Y_{progress} = \\beta_0 + \\beta_1 W_{lib2Con} + \\beta_2 X_{success} + \\beta_3 Z_{disillusion} + \\beta_4 XZ + \\varepsilon \\] 3.4.2.5 Use lm() to estimate the moderated regression model via OLS regression. Click to show code olsFit &lt;- lm(progress ~ lib2Con + success * disillusion, data = outlook) 3.4.2.6 Summarize the fitted model and interpret the results. Is the moderation hypothesis supported? How does disillusionment level affect the focal effect? Click to show code summary(olsFit) ## ## Call: ## lm(formula = progress ~ lib2Con + success * disillusion, data = outlook) ## ## Residuals: ## Min 1Q Median 3Q Max ## -7.4315 -1.2525 0.1307 1.4369 5.6717 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 6.81128 0.62073 10.973 &lt; 2e-16 *** ## lib2Con 0.03052 0.03040 1.004 0.3155 ## success 0.42360 0.25853 1.638 0.1015 ## disillusion -0.78002 0.16864 -4.625 3.95e-06 *** ## success:disillusion 0.17429 0.07273 2.396 0.0166 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.041 on 2283 degrees of freedom ## Multiple R-squared: 0.1385, Adjusted R-squared: 0.137 ## F-statistic: 91.74 on 4 and 2283 DF, p-value: &lt; 2.2e-16 Click for explanation Yes, disillusion significantly moderates the relation between success and progress (\\(\\beta = 0.174\\), \\(t[2283] = 2.396\\), \\(p = 0.017\\)) such that the effect of success on progress increases as levels of disillusion increase, after controlling for lib2Con. The rockchalk package contains some useful routines for probing interactions estimated via lm(). Specifically, the plotslopes() function will estimate and plot simple slopes, and the testSlopes() function tests the simple slopes estimated by plotSlopes(). 3.4.2.7 Probe the interaction. Use the plotSlopes() and testSlopes() functions from the rockchalk package to conduct a simple slopes analysis for the model from 3.4.2.5. Click to show code library(rockchalk) ## Estimate and plot simple slopes: psOut &lt;- plotSlopes(olsFit, plotx = &quot;success&quot;, modx = &quot;disillusion&quot;, modxVals = &quot;std.dev&quot;) ## Test the simple slopes: tsOut &lt;- testSlopes(psOut) ## Values of disillusion OUTSIDE this interval: ## lo hi ## -28.9332857 0.2672244 ## cause the slope of (b1 + b2*disillusion)success to be statistically significant ## View the results: tsOut$hypotests Note: The message printed by testSlopes() gives the boundaries of the Johnson-Neyman Region of Significance (Johnson &amp; Neyman, 1936). Johnson-Neyman analysis is an alternative method of probing interactions that we have not covered in this course. For more information, check out Preacher, et al. (2006). We will now use lavaan to estimate the moderated regression model from above as a path analysis. 3.4.2.8 Define the model syntax for the path analytic version of the model described above. Parameterize the model as in the OLS regression. Use only observed items and scale scores. Click to show code pathMod &lt;- &#39; progress ~ 1 + lib2Con + success + disillusion + success:disillusion &#39; 3.4.2.9 Estimate the path model on the outlook data. Click to show code pathFit &lt;- sem(pathMod, data = outlook) 3.4.2.10 Summarize the fitted path model and interpret the results. Do the results match the OLS regression results? What proportion of the variability in progress is explained by this model? Hint: the function lavInspect() can be used to extract information from models Click to show code summary(pathFit) ## lavaan 0.6.16 ended normally after 1 iteration ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 6 ## ## Number of observations 2288 ## ## Model Test User Model: ## ## Test statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## progress ~ ## lib2Con 0.031 0.030 1.005 0.315 ## success 0.424 0.258 1.640 0.101 ## disillusion -0.780 0.168 -4.630 0.000 ## success:dsllsn 0.174 0.073 2.399 0.016 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .progress 6.811 0.620 10.985 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .progress 4.157 0.123 33.823 0.000 lavInspect(pathFit, &quot;r2&quot;) ## progress ## 0.138 Click for explanation Yes, the estimates and inferential conclusions are all the same as in the OLS regression model. The model explains 13.85% of the variability in progress. The semTools package contains some helpful routines for probing interactions estimated via the lavaan() function (or one of it’s wrappers). Specifically, the probe2WayMC() and plotProbe() functions will estimate/test simple slopes and plot the estimated simple slopes, respectively. 3.4.2.11 Probe the interaction from 3.4.2.9 using semTools utilities. Use probe2WayMC() to estimate and test the simple slopes. Use plotProbe() to visualize the simple slopes. Define the simple slopes with the same conditional values of disillusion that you used in 3.4.2.7. Which simple slopes are significant? Do these results match the results from 3.4.2.7? Click to show code library(semTools) ## Define the conditional values at which to calculate simple slopes: condVals &lt;- summarise(outlook, &quot;m-sd&quot; = mean(disillusion) - sd(disillusion), mean = mean(disillusion), &quot;m+sd&quot; = mean(disillusion) + sd(disillusion) ) %&gt;% unlist() ## Compute simple slopes and intercepts: ssOut &lt;- probe2WayMC(pathFit, nameX = c(&quot;success&quot;, &quot;disillusion&quot;, &quot;success:disillusion&quot;), nameY = &quot;progress&quot;, modVar = &quot;disillusion&quot;, valProbe = condVals) ## Check the results: ssOut ## $SimpleIntcept ## disillusion est se z pvalue ## m-sd 2.719 4.690 0.231 20.271 0 ## mean 3.497 4.084 0.190 21.508 0 ## m+sd 4.274 3.477 0.230 15.122 0 ## ## $SimpleSlope ## disillusion est se z pvalue ## m-sd 2.719 0.897 0.083 10.792 0 ## mean 3.497 1.033 0.065 15.994 0 ## m+sd 4.274 1.169 0.088 13.223 0 ## Visualize the simple slopes: plotProbe(ssOut, xlim = range(outlook$success), xlab = &quot;Ease of Personal Success&quot;, ylab = &quot;Progress toward American Dream&quot;, legendArgs = list(legend = names(condVals)) ) Click for explanation Each of the simple slopes is significant. As level of disillusionment increases, the effect of success on progress also increases, and this effect is significant for all levels of disillusion considered here. These results match the simple slopes from the OLS regression analysis. End of In-Class Exercises 3 "],["efa.html", "4 EFA", " 4 EFA This week will be a general introduction to latent variables and scaling procedures. We will discuss several different aspects of exploratory factor analysis (EFA). Most notably: The differences between Principal Component Analyses (PCA) and Factor Analysis Model estimation and factor extraction methods Factor rotations You will have to make decisions regarding each of these aspects when conducting a factor analysis. We will also discuss reliability and factor scores as means of evaluating the properties of a scale. Homework before the lecture Watch the Lecture Recording for this week. Complete the Reading for this week, and answer the associated reading questions. Homework before the practical Complete the At-Home Exercises. Practical content During the practical you will work on the In-Class Exercises. "],["lecture-3.html", "4.1 Lecture", " 4.1 Lecture How do you know if you have measured the putative hypothetical construct that you intend to measure? The methods introduced in this lecture (namely, latent variables, factor analysis, and reliability analysis) can shed empirical light on this issue. In the social and behavioral sciences we’re often forced to measure key concepts indirectly. For example, we have no way of directly quantifying a person’s current level of depression, or their innate motivation, or their risk-aversion, or any of the other myriad psychological features that comprise the human mental state. In truth, we cannot really measure these hypothetical constructs at all, we must estimate latent representations thereof (though, psychometricians still use the language of physical measurement to describe this process). Furthermore, we can rarely estimate an adequate representation with only a single observed variable (e.g., question on a survey, score on a test, reading from a sensor). We generally need several observed variables to reliably represent a single hypothetical construct. For example, we cannot accurately determine someone’s IQ or socio-economic status based on their response to a single question; we need several questions that each tap into slightly different aspects of IQ or SES. Given multiple items measuring the same construct, we can use the methods discussed in this lecture (i.e., factor analysis and reliability analysis) to evaluate the quality of our measurement (i.e., how well we have estimated the underlying hypothetical construct). If we do well enough in this estimation task, we will be able to combine these estimated latent variables with the path analysis methods discussed in previous two weeks to produce the full structural equation models that we will cover at the end of this course. 4.1.1 Recording Notes: This week (and next), we’ll be re-using Caspar van Lissa’s old slides and lecture recording. So, you’ll see Caspar in the following video, and the slides will have a notably different flavor than our usual materials. Don’t be confused by any mention of “model fit” in the lecture. We haven’t covered model fit yet, but we will do so next week. 4.1.2 Slides You can download the lecture slides here. "],["reading-3.html", "4.2 Reading", " 4.2 Reading This week, you will read two papers. Reference 1 Preacher, K. J., &amp; MacCullum, R. C. (2003). Repairing Tom Swift’s electric factor analysis machine, Understanding Statistics 2(1) 13–43. Questions 1 What is a latent variable? Give an example of a latent variable. What is factor analysis, and what can you investigate using this method? In the introduction, Preacher and Maccallum describe a “little jiffy” method of doing factor analysis. Briefly describe this little jiffy—or bad practice—method. Briefly explain the key differences between Principal Component Analyses (PCA) and Exploratory Factor Analyses (EFA). What is the purpose of factor rotation? Reference 2 Kestilä, E. (2006). Is there demand for radical right populism in the Finnish electorate? Scandinavian Political Studies 29(3), 169–191. Questions 2 What is the research question that the author tries to answer? Briefly describe the characteristics of the Radical Right Parties (RRP) in Europe. What are the two main explanations of support for RRP upon which this paper focuses? Does the empirical part of the paper reflect the theoretical framework well? Why or why not? According to the author, is Finland very different from other European countries on the main dependent variables? What is the author’s conclusion (i.e., how does the author answer the research question)? "],["at-home-exercises-3.html", "4.3 At-Home Exercises", " 4.3 At-Home Exercises In these exercises, you will attempt to replicate some of the analyses from the second reading for this week: Kestilä, E. (2006). Is there demand for radical right populism in the Finnish electorate? Scandinavian Political Studies 29(3), 169–191. The data for this practical were collected during the first round of the European Social Survey (ESS). The ESS is a repeated cross-sectional survey administered in 32 European countries. The first wave was collected in 2002, and two new waves have been collected each year since. You can find more info and access the data at https://www.europeansocialsurvey.org. The data we will analyze for this practical are contained in the file named ESSround1-a.sav. This file contains data for all respondents, but only includes those variables that you will need to complete the following exercises. 4.3.1 Load the ESSround1-a.sav dataset into R. Inspect the data after loading to make sure everything went well. ## Load the &#39;haven&#39; package: library(haven) ## Read the &#39;ESSround1-a.sav&#39; ess into a data frame called &#39;ess&#39;: ess &lt;- read_spss(&quot;ESSround1-a.sav&quot;) ## Inspect the result: dim(ess) summary(ess) head(ess) str(ess) When you inspect the data, you may notice that almost all variables are represented as factors. If so, good eyes! We’ll come back to this issue a little later. Click here for a description of the variables. Variable Description name Title of dataset essround ESS round edition Edition proddate Production date cntry Country idno Respondent’s identification number trstlgl Trust in the legal system trstplc Trust in the police trstun Trust in the United Nations trstep Trust in the European Parliament trstprl Trust in country’s parliament stfhlth State of health services in country nowadays stfedu State of education in country nowadays stfeco How satisfied with present state of economy in country stfgov How satisfied with the national government stfdem How satisfied with the way democracy works in country pltinvt Politicians interested in votes rather than peoples opinions pltcare Politicians in general care what people like respondent think trstplt Trust in politicians imsmetn Allow many/few immigrants of same race/ethnic group as majority imdfetn Allow many/few immigrants of different race/ethnic group from majority eimrcnt Allow many/few immigrants from richer countries in Europe eimpcnt Allow many/few immigrants from poorer countries in Europe imrcntr Allow many/few immigrants from richer countries outside Europe impcntr Allow many/few immigrants from poorer countries outside Europe qfimchr Qualification for immigration: christian background qfimwht Qualification for immigration: be white imwgdwn Average wages/salaries generally brought down by immigrants imhecop Immigrants harm economic prospects of the poor more than the rich imtcjob Immigrants take jobs away in country or create new jobs imbleco Taxes and services: immigrants take out more than they put in or less imbgeco Immigration bad or good for country’s economy imueclt Country’s cultural life undermined or enriched by immigrants imwbcnt Immigrants make country worse or better place to live imwbcrm Immigrants make country’s crime problems worse or better imrsprc Richer countries should be responsible for accepting people from poorer countries pplstrd Better for a country if almost everyone share customs and traditions vrtrlg Better for a country if a variety of different religions shrrfg Country has more than its fair share of people applying refugee status rfgawrk People applying refugee status allowed to work while cases considered gvrfgap Government should be generous judging applications for refugee status rfgfrpc Most refugee applicants not in real fear of persecution own countries rfggvfn Financial support to refugee applicants while cases considered rfgbfml Granted refugees should be entitled to bring close family members gndr Gender yrbrn Year of birth edulvl Highest level of education eduyrs Years of full-time education completed polintr How interested in politics lrscale Placement on left right scale The ess dataset contains much more information than Kestilä (2006) used. Kestilä only analyzed data from the following ten countries: Austria Belgium Denmark Finland France Germany Italy Netherlands Norway Sweden So, our first task is to subset the data to only the relevant population. When we apply logical subsetting, we can select rows from a dataset based on logical conditions. In this case, we want to select only rows from the 10 countries listed above. 4.3.2 Subset the data to include only the 10 countries analyzed by Kestilä (2006). Inspect the subsetted data to check that everything went well. Hints: Use the %in% operator to create a logical vector that indicates which elements of the cntry variable are in the set of target counties. You may find it helpful to convert cntry to a factor using as_factor(). You can clean up empty factor levels using droplevels(). Click to show code library(dplyr) ## Create a character vector naming the target countries: targets &lt;- c(&quot;Austria&quot;, &quot;Belgium&quot;, &quot;Denmark&quot;, &quot;Finland&quot;, &quot;France&quot;, &quot;Germany&quot;, &quot;Italy&quot;, &quot;Netherlands&quot;, &quot;Norway&quot;, &quot;Sweden&quot;) ## Select only those rows that come from a target country: ess &lt;- ess %&gt;% mutate(cntry = as_factor(cntry)) %&gt;% # Convert cntry to a factor filter(cntry %in% targets) %&gt;% # Subset rows mutate(cntry = droplevels(cntry)) # Drop empty factor levels ## Inspect the result: dim(ess) ## [1] 19690 50 table(ess$cntry) ## ## Austria Belgium Germany Denmark Finland France ## 2257 1899 2919 1506 2000 1503 ## Italy Netherlands Norway Sweden ## 1207 2364 2036 1999 Before we can analyze the data, we need to screen them for problems. At this point, we won’t get into the nitty-gritty of outlier analysis and data cleaning. We must, however, ensure that the variables we want to analyze are formatted correctly (e.g., interval and ratio variables should be numeric, nominal variables should be factors). 4.3.3 Screen the data to see if the variables are formatted correctly. Click to show code library(tidySEM) ## Check the data structure: str(ess) ## tibble [19,690 × 50] (S3: tbl_df/tbl/data.frame) ## $ name : chr [1:19690] &quot;ESS1e06_1&quot; &quot;ESS1e06_1&quot; &quot;ESS1e06_1&quot; &quot;ESS1e06_1&quot; ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Title of dataset&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;A9&quot; ## ..- attr(*, &quot;display_width&quot;)= int 14 ## $ essround: num [1:19690] 1 1 1 1 1 1 1 1 1 1 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;ESS round&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F2.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 10 ## $ edition : chr [1:19690] &quot;6.1&quot; &quot;6.1&quot; &quot;6.1&quot; &quot;6.1&quot; ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Edition&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;A3&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ proddate: chr [1:19690] &quot;03.10.2008&quot; &quot;03.10.2008&quot; &quot;03.10.2008&quot; &quot;03.10.2008&quot; ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Production date&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;A10&quot; ## ..- attr(*, &quot;display_width&quot;)= int 12 ## $ cntry : Factor w/ 10 levels &quot;Austria&quot;,&quot;Belgium&quot;,..: 1 9 1 1 9 1 2 9 1 9 ... ## $ idno : num [1:19690] 1 1 2 3 3 4 4 4 6 6 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Respondent&#39;s identification number&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F9.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 11 ## $ trstlgl : dbl+lbl [1:19690] 10, 6, 8, 4, 8, 10, 9, 7, 7, 7, 5, 6, 5, ... ## ..@ label : chr &quot;Trust in the legal system&quot; ## ..@ format.spss : chr &quot;F2.0&quot; ## ..@ display_width: int 9 ## ..@ labels : Named num [1:14] 0 1 2 3 4 5 6 7 8 9 ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:14] &quot;No trust at all&quot; &quot;1&quot; &quot;2&quot; &quot;3&quot; ... ## $ trstplc : dbl+lbl [1:19690] 10, 8, 5, 8, 8, 9, 8, 9, 4, 9, 6, 6, 8, ... ## ..@ label : chr &quot;Trust in the police&quot; ## ..@ format.spss : chr &quot;F2.0&quot; ## ..@ display_width: int 9 ## ..@ labels : Named num [1:14] 0 1 2 3 4 5 6 7 8 9 ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:14] &quot;No trust at all&quot; &quot;1&quot; &quot;2&quot; &quot;3&quot; ... ## $ trstun : dbl+lbl [1:19690] 9, 8, 6, NA, 5, 8, NA, 7, 5, 7, NA, NA, 8, ... ## ..@ label : chr &quot;Trust in the United Nations&quot; ## ..@ format.spss: chr &quot;F2.0&quot; ## ..@ labels : Named num [1:14] 0 1 2 3 4 5 6 7 8 9 ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:14] &quot;No trust at all&quot; &quot;1&quot; &quot;2&quot; &quot;3&quot; ... ## $ trstep : dbl+lbl [1:19690] NA, 3, 0, 7, 3, 7, 0, 3, 4, 6, 2, 5, 3, ... ## ..@ label : chr &quot;Trust in the European Parliament&quot; ## ..@ format.spss: chr &quot;F2.0&quot; ## ..@ labels : Named num [1:14] 0 1 2 3 4 5 6 7 8 9 ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:14] &quot;No trust at all&quot; &quot;1&quot; &quot;2&quot; &quot;3&quot; ... ## $ trstprl : dbl+lbl [1:19690] 9, 7, 0, 6, 8, 8, 10, 2, 6, 8, 0, 6, 0, ... ## ..@ label : chr &quot;Trust in country&#39;s parliament&quot; ## ..@ format.spss : chr &quot;F2.0&quot; ## ..@ display_width: int 9 ## ..@ labels : Named num [1:14] 0 1 2 3 4 5 6 7 8 9 ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:14] &quot;No trust at all&quot; &quot;1&quot; &quot;2&quot; &quot;3&quot; ... ## $ stfhlth : dbl+lbl [1:19690] 10, 4, 0, 7, 6, 8, NA, 6, 3, 5, 6, 9, 2, ... ## ..@ label : chr &quot;State of health services in country nowadays&quot; ## ..@ format.spss : chr &quot;F2.0&quot; ## ..@ display_width: int 9 ## ..@ labels : Named num [1:14] 0 1 2 3 4 5 6 7 8 9 ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:14] &quot;Extremely bad&quot; &quot;1&quot; &quot;2&quot; &quot;3&quot; ... ## $ stfedu : dbl+lbl [1:19690] 8, 7, 7, 5, 8, 7, NA, 7, 6, 7, 3, 8, 7, ... ## ..@ label : chr &quot;State of education in country nowadays&quot; ## ..@ format.spss: chr &quot;F2.0&quot; ## ..@ labels : Named num [1:14] 0 1 2 3 4 5 6 7 8 9 ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:14] &quot;Extremely bad&quot; &quot;1&quot; &quot;2&quot; &quot;3&quot; ... ## $ stfeco : dbl+lbl [1:19690] 7, 6, 0, 7, 8, 6, NA, 9, 8, 9, 0, 8, 2, ... ## ..@ label : chr &quot;How satisfied with present state of economy in country&quot; ## ..@ format.spss: chr &quot;F2.0&quot; ## ..@ labels : Named num [1:14] 0 1 2 3 4 5 6 7 8 9 ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:14] &quot;Extremely dissatisfied&quot; &quot;1&quot; &quot;2&quot; &quot;3&quot; ... ## $ stfgov : dbl+lbl [1:19690] 7, 7, 0, 7, 6, 3, NA, 5, 5, 7, 0, 5, 0, ... ## ..@ label : chr &quot;How satisfied with the national government&quot; ## ..@ format.spss: chr &quot;F2.0&quot; ## ..@ labels : Named num [1:14] 0 1 2 3 4 5 6 7 8 9 ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:14] &quot;Extremely dissatisfied&quot; &quot;1&quot; &quot;2&quot; &quot;3&quot; ... ## $ stfdem : dbl+lbl [1:19690] 8, 5, 5, 5, 7, 7, NA, 7, 7, 9, 0, 8, 7, ... ## ..@ label : chr &quot;How satisfied with the way democracy works in country&quot; ## ..@ format.spss: chr &quot;F2.0&quot; ## ..@ labels : Named num [1:14] 0 1 2 3 4 5 6 7 8 9 ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:14] &quot;Extremely dissatisfied&quot; &quot;1&quot; &quot;2&quot; &quot;3&quot; ... ## $ pltinvt : dbl+lbl [1:19690] 1, 3, 1, 1, 4, 1, 1, 3, 2, 3, 1, 2, 1, 3, 4, 2, 3, 4... ## ..@ label : chr &quot;Politicians interested in votes rather than peoples opinions&quot; ## ..@ format.spss : chr &quot;F1.0&quot; ## ..@ display_width: int 9 ## ..@ labels : Named num [1:8] 1 2 3 4 5 7 8 9 ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Nearly all just interested in votes&quot; &quot;Most just interested in votes&quot; &quot;Some just interested in votes&quot; &quot;Most interested in opinions&quot; ... ## $ pltcare : dbl+lbl [1:19690] 1, 4, 1, 1, 4, 3, 2, 5, 2, 3, 1, 2, 2, 3, 5, 3, 2, 3... ## ..@ label : chr &quot;Politicians in general care what people like respondent think&quot; ## ..@ format.spss : chr &quot;F1.0&quot; ## ..@ display_width: int 9 ## ..@ labels : Named num [1:8] 1 2 3 4 5 7 8 9 ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Hardly any politicians care&quot; &quot;Very few care&quot; &quot;Some care&quot; &quot;Many care&quot; ... ## $ trstplt : dbl+lbl [1:19690] 0, 5, 0, 2, 5, 4, 8, 2, 4, 6, 0, 5, 0, ... ## ..@ label : chr &quot;Trust in politicians&quot; ## ..@ format.spss : chr &quot;F2.0&quot; ## ..@ display_width: int 9 ## ..@ labels : Named num [1:14] 0 1 2 3 4 5 6 7 8 9 ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:14] &quot;No trust at all&quot; &quot;1&quot; &quot;2&quot; &quot;3&quot; ... ## $ imsmetn : dbl+lbl [1:19690] 4, 3, 2, 3, 2, 1, NA, 2, NA, 1, 1, NA, 3, ... ## ..@ label : chr &quot;Allow many/few immigrants of same race/ethnic group as majority&quot; ## ..@ format.spss : chr &quot;F1.0&quot; ## ..@ display_width: int 9 ## ..@ labels : Named num [1:7] 1 2 3 4 7 8 9 ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Allow many to come and live here&quot; &quot;Allow some&quot; &quot;Allow a few&quot; &quot;Allow none&quot; ... ## $ imdfetn : dbl+lbl [1:19690] 3, 3, 2, 3, 2, 2, NA, 2, NA, 1, 1, NA, 3, ... ## ..@ label : chr &quot;Allow many/few immigrants of different race/ethnic group from majority&quot; ## ..@ format.spss : chr &quot;F1.0&quot; ## ..@ display_width: int 9 ## ..@ labels : Named num [1:7] 1 2 3 4 7 8 9 ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Allow many to come and live here&quot; &quot;Allow some&quot; &quot;Allow a few&quot; &quot;Allow none&quot; ... ## $ eimrcnt : dbl+lbl [1:19690] 4, 2, 2, 2, 3, 1, NA, 2, NA, 1, 1, 3, 3, ... ## ..@ label : chr &quot;Allow many/few immigrants from richer countries in Europe&quot; ## ..@ format.spss : chr &quot;F1.0&quot; ## ..@ display_width: int 9 ## ..@ labels : Named num [1:7] 1 2 3 4 7 8 9 ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Allow many to come and live here&quot; &quot;Allow some&quot; &quot;Allow a few&quot; &quot;Allow none&quot; ... ## $ eimpcnt : dbl+lbl [1:19690] 3, 2, 2, 2, 2, 2, NA, 2, NA, 1, 1, 3, 3, ... ## ..@ label : chr &quot;Allow many/few immigrants from poorer countries in Europe&quot; ## ..@ format.spss : chr &quot;F1.0&quot; ## ..@ display_width: int 9 ## ..@ labels : Named num [1:7] 1 2 3 4 7 8 9 ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Allow many to come and live here&quot; &quot;Allow some&quot; &quot;Allow a few&quot; &quot;Allow none&quot; ... ## $ imrcntr : dbl+lbl [1:19690] 3, 3, 2, 2, 2, 1, NA, 2, NA, 2, 1, NA, 3, ... ## ..@ label : chr &quot;Allow many/few immigrants from richer countries outside Europe&quot; ## ..@ format.spss : chr &quot;F1.0&quot; ## ..@ display_width: int 9 ## ..@ labels : Named num [1:7] 1 2 3 4 7 8 9 ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Allow many to come and live here&quot; &quot;Allow some&quot; &quot;Allow a few&quot; &quot;Allow none&quot; ... ## $ impcntr : dbl+lbl [1:19690] 3, 2, 2, 3, 2, 1, NA, 2, NA, 2, 1, NA, 3, ... ## ..@ label : chr &quot;Allow many/few immigrants from poorer countries outside Europe&quot; ## ..@ format.spss : chr &quot;F1.0&quot; ## ..@ display_width: int 9 ## ..@ labels : Named num [1:7] 1 2 3 4 7 8 9 ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Allow many to come and live here&quot; &quot;Allow some&quot; &quot;Allow a few&quot; &quot;Allow none&quot; ... ## $ qfimchr : dbl+lbl [1:19690] 4, 2, 0, 6, 2, 0, 99, 0, 1, 2, 0, 8, 6, ... ## ..@ label : chr &quot;Qualification for immigration: christian background&quot; ## ..@ format.spss : chr &quot;F2.0&quot; ## ..@ display_width: int 9 ## ..@ labels : Named num [1:14] 0 1 2 3 4 5 6 7 8 9 ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:14] &quot;Extremely unimportant&quot; &quot;1&quot; &quot;2&quot; &quot;3&quot; ... ## $ qfimwht : dbl+lbl [1:19690] 1, 0, 0, 0, 0, 0, 99, 0, 0, 1, 0, 5, 0, ... ## ..@ label : chr &quot;Qualification for immigration: be white&quot; ## ..@ format.spss : chr &quot;F2.0&quot; ## ..@ display_width: int 9 ## ..@ labels : Named num [1:14] 0 1 2 3 4 5 6 7 8 9 ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:14] &quot;Extremely unimportant&quot; &quot;1&quot; &quot;2&quot; &quot;3&quot; ... ## $ imwgdwn : dbl+lbl [1:19690] 3, 4, 2, 2, 3, 3, NA, 4, NA, 4, 5, NA, 3, ... ## ..@ label : chr &quot;Average wages/salaries generally brought down by immigrants&quot; ## ..@ format.spss : chr &quot;F1.0&quot; ## ..@ display_width: int 9 ## ..@ labels : Named num [1:8] 1 2 3 4 5 7 8 9 ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Agree strongly&quot; &quot;Agree&quot; &quot;Neither agree nor disagree&quot; &quot;Disagree&quot; ... ## $ imhecop : dbl+lbl [1:19690] 2, 2, 1, 4, 3, 2, NA, 3, NA, 2, 5, 3, 3, ... ## ..@ label : chr &quot;Immigrants harm economic prospects of the poor more than the rich&quot; ## ..@ format.spss : chr &quot;F1.0&quot; ## ..@ display_width: int 9 ## ..@ labels : Named num [1:8] 1 2 3 4 5 7 8 9 ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Agree strongly&quot; &quot;Agree&quot; &quot;Neither agree nor disagree&quot; &quot;Disagree&quot; ... ## $ imtcjob : dbl+lbl [1:19690] 7, 5, 6, 5, 7, 10, NA, 8, NA, 4, 5, 5, 5, ... ## ..@ label : chr &quot;Immigrants take jobs away in country or create new jobs&quot; ## ..@ format.spss : chr &quot;F2.0&quot; ## ..@ display_width: int 9 ## ..@ labels : Named num [1:14] 0 1 2 3 4 5 6 7 8 9 ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:14] &quot;Take jobs away&quot; &quot;1&quot; &quot;2&quot; &quot;3&quot; ... ## $ imbleco : dbl+lbl [1:19690] 9, 4, 2, NA, 3, 10, NA, 9, NA, 6, 5, NA, 2, ... ## ..@ label : chr &quot;Taxes and services: immigrants take out more than they put in or less&quot; ## ..@ format.spss : chr &quot;F2.0&quot; ## ..@ display_width: int 9 ## ..@ labels : Named num [1:14] 0 1 2 3 4 5 6 7 8 9 ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:14] &quot;Generally take out more&quot; &quot;1&quot; &quot;2&quot; &quot;3&quot; ... ## $ imbgeco : dbl+lbl [1:19690] 4, 3, 10, 7, 5, 10, NA, 8, NA, 5, 5, 5, 3, ... ## ..@ label : chr &quot;Immigration bad or good for country&#39;s economy&quot; ## ..@ format.spss : chr &quot;F2.0&quot; ## ..@ display_width: int 9 ## ..@ labels : Named num [1:14] 0 1 2 3 4 5 6 7 8 9 ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:14] &quot;Bad for the economy&quot; &quot;1&quot; &quot;2&quot; &quot;3&quot; ... ## $ imueclt : dbl+lbl [1:19690] 9, 4, 10, 5, 4, 10, NA, 9, NA, 3, 7, 5, 2, ... ## ..@ label : chr &quot;Country&#39;s cultural life undermined or enriched by immigrants&quot; ## ..@ format.spss : chr &quot;F2.0&quot; ## ..@ display_width: int 9 ## ..@ labels : Named num [1:14] 0 1 2 3 4 5 6 7 8 9 ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:14] &quot;Cultural life undermined&quot; &quot;1&quot; &quot;2&quot; &quot;3&quot; ... ## $ imwbcnt : dbl+lbl [1:19690] 7, 3, 5, 5, 5, 10, NA, 8, NA, 5, 5, 5, 2, ... ## ..@ label : chr &quot;Immigrants make country worse or better place to live&quot; ## ..@ format.spss : chr &quot;F2.0&quot; ## ..@ display_width: int 9 ## ..@ labels : Named num [1:14] 0 1 2 3 4 5 6 7 8 9 ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:14] &quot;Worse place to live&quot; &quot;1&quot; &quot;2&quot; &quot;3&quot; ... ## $ imwbcrm : dbl+lbl [1:19690] 3, 3, 5, 2, 3, 5, NA, 5, NA, 3, 4, 2, 0, ... ## ..@ label : chr &quot;Immigrants make country&#39;s crime problems worse or better&quot; ## ..@ format.spss : chr &quot;F2.0&quot; ## ..@ display_width: int 9 ## ..@ labels : Named num [1:14] 0 1 2 3 4 5 6 7 8 9 ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:14] &quot;Crime problems made worse&quot; &quot;1&quot; &quot;2&quot; &quot;3&quot; ... ## $ imrsprc : dbl+lbl [1:19690] 2, 2, 1, 4, 1, 2, NA, 1, 1, 3, 1, NA, 4, ... ## ..@ label : chr &quot;Richer countries should be responsible for accepting people from poorer countries&quot; ## ..@ format.spss : chr &quot;F1.0&quot; ## ..@ display_width: int 9 ## ..@ labels : Named num [1:8] 1 2 3 4 5 7 8 9 ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Agree strongly&quot; &quot;Agree&quot; &quot;Neither agree nor disagree&quot; &quot;Disagree&quot; ... ## $ pplstrd : dbl+lbl [1:19690] 2, 4, 2, 2, 3, 4, NA, 4, 4, 2, 4, 1, 2, ... ## ..@ label : chr &quot;Better for a country if almost everyone share customs and traditions&quot; ## ..@ format.spss : chr &quot;F1.0&quot; ## ..@ display_width: int 9 ## ..@ labels : Named num [1:8] 1 2 3 4 5 7 8 9 ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Agree strongly&quot; &quot;Agree&quot; &quot;Neither agree nor disagree&quot; &quot;Disagree&quot; ... ## $ vrtrlg : dbl+lbl [1:19690] 3, 5, 3, 2, 4, 1, NA, 4, 2, 3, 2, 2, 4, ... ## ..@ label : chr &quot;Better for a country if a variety of different religions&quot; ## ..@ format.spss: chr &quot;F1.0&quot; ## ..@ labels : Named num [1:8] 1 2 3 4 5 7 8 9 ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Agree strongly&quot; &quot;Agree&quot; &quot;Neither agree nor disagree&quot; &quot;Disagree&quot; ... ## $ shrrfg : dbl+lbl [1:19690] 3, 2, 1, 1, 3, 3, NA, 3, 4, 3, 3, NA, 2, ... ## ..@ label : chr &quot;Country has more than its fair share of people applying refugee status&quot; ## ..@ format.spss: chr &quot;F1.0&quot; ## ..@ labels : Named num [1:8] 1 2 3 4 5 7 8 9 ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Agree strongly&quot; &quot;Agree&quot; &quot;Neither agree nor disagree&quot; &quot;Disagree&quot; ... ## $ rfgawrk : dbl+lbl [1:19690] 2, 2, 1, 2, 2, 2, NA, 2, 1, 2, 2, NA, 3, ... ## ..@ label : chr &quot;People applying refugee status allowed to work while cases considered&quot; ## ..@ format.spss : chr &quot;F1.0&quot; ## ..@ display_width: int 9 ## ..@ labels : Named num [1:8] 1 2 3 4 5 7 8 9 ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Agree strongly&quot; &quot;Agree&quot; &quot;Neither agree nor disagree&quot; &quot;Disagree&quot; ... ## $ gvrfgap : dbl+lbl [1:19690] 4, 3, 2, 4, 2, 2, NA, 3, 2, 4, 3, 4, 4, ... ## ..@ label : chr &quot;Government should be generous judging applications for refugee status&quot; ## ..@ format.spss : chr &quot;F1.0&quot; ## ..@ display_width: int 9 ## ..@ labels : Named num [1:8] 1 2 3 4 5 7 8 9 ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Agree strongly&quot; &quot;Agree&quot; &quot;Neither agree nor disagree&quot; &quot;Disagree&quot; ... ## $ rfgfrpc : dbl+lbl [1:19690] 4, 3, 2, 4, 4, 4, NA, 4, 3, 4, 4, 3, 3, ... ## ..@ label : chr &quot;Most refugee applicants not in real fear of persecution own countries&quot; ## ..@ format.spss : chr &quot;F1.0&quot; ## ..@ display_width: int 9 ## ..@ labels : Named num [1:8] 1 2 3 4 5 7 8 9 ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Agree strongly&quot; &quot;Agree&quot; &quot;Neither agree nor disagree&quot; &quot;Disagree&quot; ... ## $ rfggvfn : dbl+lbl [1:19690] 2, 3, 2, 4, 3, 2, NA, 2, 2, 2, 2, NA, 2, ... ## ..@ label : chr &quot;Financial support to refugee applicants while cases considered&quot; ## ..@ format.spss : chr &quot;F1.0&quot; ## ..@ display_width: int 9 ## ..@ labels : Named num [1:8] 1 2 3 4 5 7 8 9 ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Agree strongly&quot; &quot;Agree&quot; &quot;Neither agree nor disagree&quot; &quot;Disagree&quot; ... ## $ rfgbfml : dbl+lbl [1:19690] 2, 3, 1, 2, 2, 1, NA, 4, 2, 3, 2, NA, 4, ... ## ..@ label : chr &quot;Granted refugees should be entitled to bring close family members&quot; ## ..@ format.spss : chr &quot;F1.0&quot; ## ..@ display_width: int 9 ## ..@ labels : Named num [1:8] 1 2 3 4 5 7 8 9 ## .. ..- attr(*, &quot;names&quot;)= chr [1:8] &quot;Agree strongly&quot; &quot;Agree&quot; &quot;Neither agree nor disagree&quot; &quot;Disagree&quot; ... ## $ gndr : dbl+lbl [1:19690] 1, 2, 1, 2, 2, 1, NA, 2, 2, 1, 2, 2, 2, ... ## ..@ label : chr &quot;Gender&quot; ## ..@ format.spss : chr &quot;F1.0&quot; ## ..@ display_width: int 6 ## ..@ labels : Named num [1:3] 1 2 9 ## .. ..- attr(*, &quot;names&quot;)= chr [1:3] &quot;Male&quot; &quot;Female&quot; &quot;No answer&quot; ## $ yrbrn : dbl+lbl [1:19690] 1949, 1978, 1953, 1940, 1964, 1959, NA, 1973, 1962... ## ..@ label : chr &quot;Year of birth&quot; ## ..@ format.spss : chr &quot;F4.0&quot; ## ..@ display_width: int 7 ## ..@ labels : Named num [1:3] 7777 8888 9999 ## .. ..- attr(*, &quot;names&quot;)= chr [1:3] &quot;Refusal&quot; &quot;Don&#39;t know&quot; &quot;No answer&quot; ## $ edulvl : dbl+lbl [1:19690] NA, 3, NA, NA, 3, NA, NA, 6, NA, 5, NA, NA, 3, ... ## ..@ label : chr &quot;Highest level of education&quot; ## ..@ format.spss: chr &quot;F1.0&quot; ## ..@ labels : Named num [1:10] 0 1 2 3 4 5 6 7 8 9 ## .. ..- attr(*, &quot;names&quot;)= chr [1:10] &quot;Not completed primary education&quot; &quot;Primary or first stage of basic&quot; &quot;Lower secondary or second stage of basic&quot; &quot;Upper secondary&quot; ... ## $ eduyrs : dbl+lbl [1:19690] 11, 16, 14, 9, 12, 18, NA, 17, 15, 17, 11, 10, 19, ... ## ..@ label : chr &quot;Years of full-time education completed&quot; ## ..@ format.spss: chr &quot;F2.0&quot; ## ..@ labels : Named num [1:3] 77 88 99 ## .. ..- attr(*, &quot;names&quot;)= chr [1:3] &quot;Refusal&quot; &quot;Don&#39;t know&quot; &quot;No answer&quot; ## $ polintr : dbl+lbl [1:19690] 3, 3, 1, 2, 3, 2, 1, 4, 3, 3, 1, 3, 3, 3, 1, 2, 3, 3... ## ..@ label : chr &quot;How interested in politics&quot; ## ..@ format.spss : chr &quot;F1.0&quot; ## ..@ display_width: int 9 ## ..@ labels : Named num [1:7] 1 2 3 4 7 8 9 ## .. ..- attr(*, &quot;names&quot;)= chr [1:7] &quot;Very interested&quot; &quot;Quite interested&quot; &quot;Hardly interested&quot; &quot;Not at all interested&quot; ... ## $ lrscale : dbl+lbl [1:19690] 6, 7, 6, 5, 8, 5, NA, 8, 5, 7, NA, NA, 4, ... ## ..@ label : chr &quot;Placement on left right scale&quot; ## ..@ format.spss : chr &quot;F2.0&quot; ## ..@ display_width: int 9 ## ..@ labels : Named num [1:14] 0 1 2 3 4 5 6 7 8 9 ... ## .. ..- attr(*, &quot;names&quot;)= chr [1:14] &quot;Left&quot; &quot;1&quot; &quot;2&quot; &quot;3&quot; ... ## Compute descriptive statistics: descriptives(ess) Click for explanation One thing you might notice when inspecting the ess data is that all the scale variables are stored as labelled vectors. When loading SPSS data, haven will use these labelled vectors to preserve the metadata associated with SPSS scale variables (i.e., variable labels and value labels). While it’s good to have this metadata available, we want to analyze these items as numeric variables, so the value labels are only going to make our lives harder. Thankfully, the labelled package contains many routines for manipulating labelled vectors. We can use the labelled::remove_val_labels() function to strip the value labels and convert all of the labelled vectors to numeric vectors. 4.3.4 Correct any formatting issues that you discovered above. Click for explanation In keeping with common practice, we will treat ordinal Likert-type rating scales with five or more levels as continuous. Since some R routines will treat labelled vectors as discrete variables, we can make things easier for ourselves by converting all the labelled vectors in our data to numeric vectors. As noted above, we can easily accomplish this goal with the remove_val_labels() function from the labelled package. ## If necessary, install the labelled package: # install.packages(&quot;labelled&quot;, repos = &quot;https://cloud.r-project.org&quot;) ## Load the labelled package: library(labelled) ## Strip the value labels: ess &lt;- remove_val_labels(ess) ## Check the effects: str(ess) ## tibble [19,690 × 50] (S3: tbl_df/tbl/data.frame) ## $ name : chr [1:19690] &quot;ESS1e06_1&quot; &quot;ESS1e06_1&quot; &quot;ESS1e06_1&quot; &quot;ESS1e06_1&quot; ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Title of dataset&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;A9&quot; ## ..- attr(*, &quot;display_width&quot;)= int 14 ## $ essround: num [1:19690] 1 1 1 1 1 1 1 1 1 1 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;ESS round&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F2.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 10 ## $ edition : chr [1:19690] &quot;6.1&quot; &quot;6.1&quot; &quot;6.1&quot; &quot;6.1&quot; ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Edition&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;A3&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ proddate: chr [1:19690] &quot;03.10.2008&quot; &quot;03.10.2008&quot; &quot;03.10.2008&quot; &quot;03.10.2008&quot; ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Production date&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;A10&quot; ## ..- attr(*, &quot;display_width&quot;)= int 12 ## $ cntry : Factor w/ 10 levels &quot;Austria&quot;,&quot;Belgium&quot;,..: 1 9 1 1 9 1 2 9 1 9 ... ## $ idno : num [1:19690] 1 1 2 3 3 4 4 4 6 6 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Respondent&#39;s identification number&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F9.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 11 ## $ trstlgl : num [1:19690] 10 6 8 4 8 10 9 7 7 7 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Trust in the legal system&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F2.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ trstplc : num [1:19690] 10 8 5 8 8 9 8 9 4 9 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Trust in the police&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F2.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ trstun : num [1:19690] 9 8 6 NA 5 8 NA 7 5 7 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Trust in the United Nations&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F2.0&quot; ## $ trstep : num [1:19690] NA 3 0 7 3 7 0 3 4 6 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Trust in the European Parliament&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F2.0&quot; ## $ trstprl : num [1:19690] 9 7 0 6 8 8 10 2 6 8 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Trust in country&#39;s parliament&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F2.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ stfhlth : num [1:19690] 10 4 0 7 6 8 NA 6 3 5 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;State of health services in country nowadays&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F2.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ stfedu : num [1:19690] 8 7 7 5 8 7 NA 7 6 7 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;State of education in country nowadays&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F2.0&quot; ## $ stfeco : num [1:19690] 7 6 0 7 8 6 NA 9 8 9 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;How satisfied with present state of economy in country&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F2.0&quot; ## $ stfgov : num [1:19690] 7 7 0 7 6 3 NA 5 5 7 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;How satisfied with the national government&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F2.0&quot; ## $ stfdem : num [1:19690] 8 5 5 5 7 7 NA 7 7 9 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;How satisfied with the way democracy works in country&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F2.0&quot; ## $ pltinvt : num [1:19690] 1 3 1 1 4 1 1 3 2 3 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Politicians interested in votes rather than peoples opinions&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F1.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ pltcare : num [1:19690] 1 4 1 1 4 3 2 5 2 3 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Politicians in general care what people like respondent think&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F1.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ trstplt : num [1:19690] 0 5 0 2 5 4 8 2 4 6 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Trust in politicians&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F2.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ imsmetn : num [1:19690] 4 3 2 3 2 1 NA 2 NA 1 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Allow many/few immigrants of same race/ethnic group as majority&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F1.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ imdfetn : num [1:19690] 3 3 2 3 2 2 NA 2 NA 1 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Allow many/few immigrants of different race/ethnic group from majority&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F1.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ eimrcnt : num [1:19690] 4 2 2 2 3 1 NA 2 NA 1 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Allow many/few immigrants from richer countries in Europe&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F1.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ eimpcnt : num [1:19690] 3 2 2 2 2 2 NA 2 NA 1 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Allow many/few immigrants from poorer countries in Europe&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F1.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ imrcntr : num [1:19690] 3 3 2 2 2 1 NA 2 NA 2 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Allow many/few immigrants from richer countries outside Europe&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F1.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ impcntr : num [1:19690] 3 2 2 3 2 1 NA 2 NA 2 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Allow many/few immigrants from poorer countries outside Europe&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F1.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ qfimchr : num [1:19690] 4 2 0 6 2 0 99 0 1 2 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Qualification for immigration: christian background&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F2.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ qfimwht : num [1:19690] 1 0 0 0 0 0 99 0 0 1 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Qualification for immigration: be white&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F2.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ imwgdwn : num [1:19690] 3 4 2 2 3 3 NA 4 NA 4 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Average wages/salaries generally brought down by immigrants&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F1.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ imhecop : num [1:19690] 2 2 1 4 3 2 NA 3 NA 2 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Immigrants harm economic prospects of the poor more than the rich&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F1.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ imtcjob : num [1:19690] 7 5 6 5 7 10 NA 8 NA 4 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Immigrants take jobs away in country or create new jobs&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F2.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ imbleco : num [1:19690] 9 4 2 NA 3 10 NA 9 NA 6 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Taxes and services: immigrants take out more than they put in or less&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F2.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ imbgeco : num [1:19690] 4 3 10 7 5 10 NA 8 NA 5 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Immigration bad or good for country&#39;s economy&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F2.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ imueclt : num [1:19690] 9 4 10 5 4 10 NA 9 NA 3 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Country&#39;s cultural life undermined or enriched by immigrants&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F2.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ imwbcnt : num [1:19690] 7 3 5 5 5 10 NA 8 NA 5 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Immigrants make country worse or better place to live&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F2.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ imwbcrm : num [1:19690] 3 3 5 2 3 5 NA 5 NA 3 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Immigrants make country&#39;s crime problems worse or better&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F2.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ imrsprc : num [1:19690] 2 2 1 4 1 2 NA 1 1 3 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Richer countries should be responsible for accepting people from poorer countries&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F1.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ pplstrd : num [1:19690] 2 4 2 2 3 4 NA 4 4 2 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Better for a country if almost everyone share customs and traditions&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F1.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ vrtrlg : num [1:19690] 3 5 3 2 4 1 NA 4 2 3 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Better for a country if a variety of different religions&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F1.0&quot; ## $ shrrfg : num [1:19690] 3 2 1 1 3 3 NA 3 4 3 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Country has more than its fair share of people applying refugee status&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F1.0&quot; ## $ rfgawrk : num [1:19690] 2 2 1 2 2 2 NA 2 1 2 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;People applying refugee status allowed to work while cases considered&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F1.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ gvrfgap : num [1:19690] 4 3 2 4 2 2 NA 3 2 4 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Government should be generous judging applications for refugee status&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F1.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ rfgfrpc : num [1:19690] 4 3 2 4 4 4 NA 4 3 4 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Most refugee applicants not in real fear of persecution own countries&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F1.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ rfggvfn : num [1:19690] 2 3 2 4 3 2 NA 2 2 2 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Financial support to refugee applicants while cases considered&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F1.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ rfgbfml : num [1:19690] 2 3 1 2 2 1 NA 4 2 3 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Granted refugees should be entitled to bring close family members&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F1.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ gndr : num [1:19690] 1 2 1 2 2 1 NA 2 2 1 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Gender&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F1.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 6 ## $ yrbrn : num [1:19690] 1949 1978 1953 1940 1964 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Year of birth&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F4.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 7 ## $ edulvl : num [1:19690] NA 3 NA NA 3 NA NA 6 NA 5 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Highest level of education&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F1.0&quot; ## $ eduyrs : num [1:19690] 11 16 14 9 12 18 NA 17 15 17 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Years of full-time education completed&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F2.0&quot; ## $ polintr : num [1:19690] 3 3 1 2 3 2 1 4 3 3 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;How interested in politics&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F1.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 ## $ lrscale : num [1:19690] 6 7 6 5 8 5 NA 8 5 7 ... ## ..- attr(*, &quot;label&quot;)= chr &quot;Placement on left right scale&quot; ## ..- attr(*, &quot;format.spss&quot;)= chr &quot;F2.0&quot; ## ..- attr(*, &quot;display_width&quot;)= int 9 descriptives(ess) Note that the variables are now simple numeric vectors, but the variable labels have been retained as column attributes (which is probably useful). If we want to completely nuke the labelling information, we can use the labelled::remove_labels() function to do so. In addition to screening with summary statistics, we can also visualize the variables’ distributions. You have already created a few such visualizations for single variables. Now, we will use a few tricks to efficiently plot each of our target variables. The first step in this process will be to convert the interesting part of our data from “wide format” (one column per variable) into “long format” (one column of variable names, one column of data values). The pivot_longer() function from the tidyr package provides a convenient way to execute this conversion. 4.3.5 Use tidyr::pivot_longer() to create a long-formatted data frame from the target variables in ess. The target variables are all columns from trstlgl to rfgbfml. Click to show code ## Load the tidyr package: library(tidyr) ## Convert the target variables into a long-formatted data frame: ess_plot &lt;- pivot_longer(ess, cols = trstlgl:rfgbfml, # Which columns to convert names_to = &quot;variable&quot;, # Name for the new grouping variable values_to = &quot;value&quot;) # Name for the column of stacked values The next step in the process will be to plot the variables using ggplot(). In the above code, I’ve named the new grouping variable variable and the new stacked data variable value. So, to create one plot for each (original, wide-format) variable, we will use the facet_wrap() function to facet the plots of value on the variable column (i.e., create a separate conditional plot of value for each unique value in variable). 4.3.6 Use ggplot() with an appropriate geom (e.g., geom_histogram(), geom_density(), geom_boxplot()) and facet_wrap() to visualize each of the target variables. Hint: To implement the faceting, simply add facet_wrap(~ variable, scales = \"free_x\") to the end of your ggplot() call (obviously, replacing “variable” with whatever you named the grouping variable in your pivot_longer() call). Click to show code library(ggplot2) ggplot(ess_plot, aes(x = value)) + geom_histogram() + # Create a histogram facet_wrap(~ variable, scales = &quot;free_x&quot;) # Facet on &#39;variable&#39; Click for explanation Notice that the variables are actually discrete (i.e., each variable takes only a few integer values). However, most variables look relatively normal despite being categorical. So, we’ll bend the rules a bit and analyze these variables as continuous. 4.3.7 Check the descriptives for the target variables again. Do you see any remaining issues? Click to show code select(ess, trstlgl:rfgbfml) %&gt;% descriptives() Click for explanation No. Everything looks pretty much fine. Now, we’re ready to run the analyses and see if we can replicate the Kestilä (2006) results. 4.3.8 Run two principal component analyses (PCA): one for trust in politics, one for attitudes towards immigration. Use the principal() function from the psych package. Use exactly the same specifications as Kestilä (2006) concerning the estimation method, rotation, number of components extracted, etc. Hints: Remember that you can view the help file for psych::principal() by running ?psych::principal or, if the psych package already loaded, simply running ?principal. When you print the output from psych::principal(), you can use the cut option to hide any factor loadings smaller than a given threshold. You could consider hiding any loadings smaller than those reported by Kestilä (2006) to make the output easier to interpret. Click to show code Trust in politics Kestilä extracted three components with VARIMAX rotation. ## Load the psych package: library(psych) ## Run the PCA: pca_trust &lt;- select(ess, trstlgl:impcntr) %&gt;% principal(nfactors = 3, rotate = &quot;varimax&quot;) ## Print the results: print(pca_trust, cut = 0.3, digits = 3) ## Principal Components Analysis ## Call: principal(r = ., nfactors = 3, rotate = &quot;varimax&quot;) ## Standardized loadings (pattern matrix) based upon correlation matrix ## RC2 RC1 RC3 h2 u2 com ## trstlgl 0.599 0.324 0.471 0.529 1.59 ## trstplc 0.491 0.339 0.356 0.644 1.78 ## trstun 0.669 0.483 0.517 1.16 ## trstep 0.681 0.498 0.502 1.15 ## trstprl 0.735 0.311 0.648 0.352 1.40 ## stfhlth 0.751 0.567 0.433 1.01 ## stfedu 0.759 0.598 0.402 1.08 ## stfeco 0.317 0.676 0.559 0.441 1.43 ## stfgov 0.425 0.595 0.535 0.465 1.81 ## stfdem 0.475 0.573 0.564 0.436 2.00 ## pltinvt 0.687 0.488 0.512 1.07 ## pltcare 0.681 0.495 0.505 1.13 ## trstplt 0.794 0.711 0.289 1.26 ## imsmetn 0.841 0.724 0.276 1.05 ## imdfetn 0.882 0.796 0.204 1.05 ## eimrcnt 0.808 0.663 0.337 1.03 ## eimpcnt 0.884 0.799 0.201 1.04 ## imrcntr 0.841 0.715 0.285 1.02 ## impcntr 0.880 0.788 0.212 1.04 ## ## RC2 RC1 RC3 ## SS loadings 4.504 4.219 2.736 ## Proportion Var 0.237 0.222 0.144 ## Cumulative Var 0.237 0.459 0.603 ## Proportion Explained 0.393 0.368 0.239 ## Cumulative Proportion 0.393 0.761 1.000 ## ## Mean item complexity = 1.3 ## Test of the hypothesis that 3 components are sufficient. ## ## The root mean square of the residuals (RMSR) is 0.062 ## with the empirical chi square 25718.21 with prob &lt; 0 ## ## Fit based upon off diagonal values = 0.968 Attitudes toward immigration Kestilä extracted five components with VARIMAX rotation. pca_att &lt;- select(ess, imsmetn:rfgbfml) %&gt;% principal(nfactors = 5, rotate = &quot;varimax&quot;) print(pca_att, cut = 0.3, digits = 3) ## Principal Components Analysis ## Call: principal(r = ., nfactors = 5, rotate = &quot;varimax&quot;) ## Standardized loadings (pattern matrix) based upon correlation matrix ## RC2 RC1 RC4 RC5 RC3 h2 u2 com ## imsmetn 0.796 0.722 0.278 1.29 ## imdfetn 0.789 0.791 0.209 1.57 ## eimrcnt 0.821 0.704 0.296 1.09 ## eimpcnt 0.808 0.789 0.211 1.44 ## imrcntr 0.834 0.742 0.258 1.14 ## impcntr 0.788 0.781 0.219 1.54 ## qfimchr 0.887 0.798 0.202 1.03 ## qfimwht 0.881 0.794 0.206 1.05 ## imwgdwn 0.804 0.699 0.301 1.17 ## imhecop 0.752 0.663 0.337 1.36 ## imtcjob 0.495 0.383 0.438 0.562 2.32 ## imbleco 0.634 0.482 0.518 1.42 ## imbgeco 0.674 0.571 0.429 1.55 ## imueclt 0.644 0.539 0.461 1.64 ## imwbcnt 0.691 0.628 0.372 1.67 ## imwbcrm 0.631 0.447 0.553 1.25 ## imrsprc 0.607 0.438 0.562 1.39 ## pplstrd 0.511 0.364 0.636 1.83 ## vrtrlg -0.528 0.375 0.625 1.75 ## shrrfg 0.420 -0.331 0.412 0.588 3.33 ## rfgawrk 0.619 0.400 0.600 1.09 ## gvrfgap 0.689 0.558 0.442 1.36 ## rfgfrpc -0.369 0.318 0.682 3.30 ## rfggvfn 0.592 0.425 0.575 1.45 ## rfgbfml 0.592 0.462 0.538 1.63 ## ## RC2 RC1 RC4 RC5 RC3 ## SS loadings 4.412 3.764 2.691 1.804 1.671 ## Proportion Var 0.176 0.151 0.108 0.072 0.067 ## Cumulative Var 0.176 0.327 0.435 0.507 0.574 ## Proportion Explained 0.308 0.262 0.188 0.126 0.116 ## Cumulative Proportion 0.308 0.570 0.758 0.884 1.000 ## ## Mean item complexity = 1.6 ## Test of the hypothesis that 5 components are sufficient. ## ## The root mean square of the residuals (RMSR) is 0.05 ## with the empirical chi square 29847.2 with prob &lt; 0 ## ## Fit based upon off diagonal values = 0.975 Feature engineering (i.e., creating new variables by combining and/or transforming existing variables) is one of the most common applications of PCA. PCA is a dimension reduction technique that distills the most salient information from a set of variables into a (smaller) set of component scores. Hence, PCA can be a good way of creating aggregate items (analogous to weighted scale scores) when the data are not collected with validated scales. Principal component scores are automatically generated when we run the PCA. If we want to use these scores in subsequent analyses (e.g., as predictors in a regression model), we usually add them to our dataset as additional columns. 4.3.9 Add the component scores produced by the analyses you ran above to the ess data frame. Give each component score an informative name, based on your interpretation of the factor loading matrix I.e., What hypothetical construct do you think each component represents given the items that load onto it? Hints: You can use the data.frame() function to join multiple objects into a single data frame. You can use the colnames() function to assign column names to a matrix or data frame. 1. Extract the component scores Click to show code ## Save the component scores in stand-alone matrices: trust_scores &lt;- pca_trust$scores att_scores &lt;- pca_att$scores ## Inspect the result: head(trust_scores) ## RC2 RC1 RC3 ## [1,] NA NA NA ## [2,] 0.3124145 0.8692374 -0.1684163 ## [3,] -0.7065266 -1.4821553 -1.1328127 ## [4,] NA NA NA ## [5,] -0.2263756 0.7488268 0.5895587 ## [6,] -1.4226982 0.1882465 0.8729685 summary(trust_scores) ## RC2 RC1 RC3 ## Min. :-2.404 Min. :-3.603 Min. :-3.693 ## 1st Qu.:-0.571 1st Qu.:-0.559 1st Qu.:-0.640 ## Median :-0.179 Median : 0.147 Median : 0.072 ## Mean :-0.043 Mean : 0.076 Mean : 0.013 ## 3rd Qu.: 0.747 3rd Qu.: 0.768 3rd Qu.: 0.711 ## Max. : 2.674 Max. : 3.783 Max. : 3.240 ## NA&#39;s :5505 NA&#39;s :5505 NA&#39;s :5505 head(att_scores) ## RC2 RC1 RC4 RC5 RC3 ## [1,] 2.0575643 1.2099251 -0.8992969 0.01524776 -0.081891789 ## [2,] 0.1438873 -1.1749162 -0.5845573 0.57449346 -0.299590997 ## [3,] -0.3071884 0.3995586 -1.7023028 -2.13506852 -0.269858348 ## [4,] NA NA NA NA NA ## [5,] -0.1100894 -0.7831035 -1.5480638 0.33870657 -0.160118606 ## [6,] -0.8641830 2.8746299 -0.3918998 -1.09804421 -0.007004959 summary(att_scores) ## RC2 RC1 RC4 RC5 ## Min. :-3.523 Min. :-3.767 Min. :-3.625 Min. :-3.644 ## 1st Qu.:-0.602 1st Qu.:-0.630 1st Qu.:-0.655 1st Qu.:-0.681 ## Median :-0.081 Median : 0.055 Median :-0.011 Median : 0.040 ## Mean :-0.002 Mean : 0.002 Mean : 0.022 Mean : 0.002 ## 3rd Qu.: 0.699 3rd Qu.: 0.671 3rd Qu.: 0.659 3rd Qu.: 0.714 ## Max. : 3.560 Max. : 3.845 Max. : 4.139 Max. : 3.233 ## NA&#39;s :5400 NA&#39;s :5400 NA&#39;s :5400 NA&#39;s :5400 ## RC3 ## Min. :-1.170 ## 1st Qu.:-0.340 ## Median :-0.150 ## Mean :-0.113 ## 3rd Qu.: 0.070 ## Max. : 8.466 ## NA&#39;s :5400 Click for explanation The object produced by psych::principal() is simply list, and the component scores are already stored therein. So, to extract the component scores, we simply use the $ operator to extract them. 2. Name the component scores Click to show code ## Check names (note the order): colnames(trust_scores) ## [1] &quot;RC2&quot; &quot;RC1&quot; &quot;RC3&quot; colnames(att_scores) ## [1] &quot;RC2&quot; &quot;RC1&quot; &quot;RC4&quot; &quot;RC5&quot; &quot;RC3&quot; ## Give informative names: colnames(trust_scores) &lt;- c(&quot;Trust_Institutions&quot;, &quot;Satisfaction&quot;, &quot; Trust_Politicians&quot;) colnames(att_scores) &lt;- c(&quot;Quantity&quot;, &quot;Effects&quot;, &quot;Refugees&quot;, &quot;Diversity&quot;, &quot;Economic&quot;) 3. Add the component scores to the dataset Click to show code # Add the component scores to the &#39;ess&#39; data: ess &lt;- data.frame(ess, trust_scores, att_scores) 4.3.10 Were you able to replicate the results of Kestilä (2006)? Click for explanation Yes, more-or-less. Although the exact estimates differ somewhat, the general pattern of factor loadings in Kestilä (2006) matches what we found here. End of At-Home Exercises "],["in-class-exercises-3.html", "4.4 In-Class Exercises", " 4.4 In-Class Exercises In these exercises, we will continue with our re-analysis/replication of the Kestilä (2006) results. Rather than attempting a direct replication, we will now redo the analysis using exploratory factor analysis (EFA). 4.4.1 Load the ESSround1-b.csv dataset. These are the same data that you analyzed for the At-Home Exercises, but the processing/recoding that you should have done for those exercises has already been (mostly) implemented. It will be helpful to convert cntry back into a factor. library(dplyr) ess &lt;- read.csv(&quot;ESSround1-b.csv&quot;) %&gt;% mutate(cntry = factor(cntry)) 4.4.2 Kestilä (2006) claimed that running a PCA is a good way to test if the questions in the ESS measure attitudes towards immigration and trust in politics. Based on what you’ve learned from the readings and lectures, do you agree with this position? Click for explanation Hopefully not. PCA is not a method for estimating latent measurement structure; PCA is a dimension reduction technique that tries to summarize a set of data with a smaller set of component scores. If we really want to estimate the factor structure underlying a set of observed variables, we should use EFA. 4.4.3 Suppose you had to construct the trust in politics and attitude towards immigration scales described by Kestilä (2006) based on the theory and background information presented in that article. What type of analysis would you choose? What key factors would influence your decision? Click for explanation We are trying to estimate meaningful latent factors, so EFA would be an appropriate method. The theory presented by Kestilä (2006) did not hypothesize a particular number of factors, so we would need to use appropriate techniques to estimate the best number. In particular, combining information from: Scree plots Parallel analysis Substantive interpretability of the (rotated) factor loadings Since the factors are almost certainly correlated, we should apply an oblique rotation. We will now rerun the two PCAs that you conducted for the At-Home Exercises using EFA. We will estimate the EFA models using the psych::fa() function, but we need to know how many factors to extract. We could simply estimate a range of solutions and compare the results. We can restrict the range of plausible solutions and save some time by first checking/plotting the eigenvalues and running parallel analysis. 4.4.4 Estimate the number of latent factors underlying the Trust items based on the eigenvalues, the scree plot, and parallel analysis. How many factors are suggested by each method? Hint: You can create a scree plot by supplying the vector of eigenvalues to the qplot() function from the ggplot2 package and applying the geom_path() geometry. 1. Eigenvalue estimation Click to show code ## Load the psych package: library(psych) ## Run a trivial EFA on the &#39;trust&#39; items efa_trust0 &lt;- select(ess, trstlgl:impcntr) %&gt;% fa(nfactors = 1, rotate = &quot;none&quot;) Click for explanation (EFA) First, we run a trivial EFA using the psych::fa() function to estimate the eigenvalues. We don’t care about the factors yet, so we can extract a single factor. We also don’t care about interpretable solutions, so we don’t need rotation. ## View the estimated eigenvalues: round(efa_trust0$values, digits = 3) ## [1] 4.555 3.054 0.411 0.134 0.071 -0.119 -0.177 -0.258 -0.280 -0.312 ## [11] -0.344 -0.406 -0.412 -0.423 -0.444 -0.492 Click for explanation (eigenvalue extraction) We can check the eigenvalues to see what proportion of the observed variance is accounted for by each additional factor we may extract. Since only one eigenvalue is greater than one, the so-called “Kaiser Criterion” would suggest extracting a single factor. The Kaiser Criterion is not a valid way to select the number of factors in EFA. So, we don’t want to rely on this information alone. We can still use the eigenvalues to help us with factor enumeration, though. One way to do so is by plotting the eigenvalues in a scree plot. 2. Scree plot Click to show code Given a vector of estimated eigenvalues, we can create a scree plot using ggplot() and the geom_line() or geom_path() geometry. library(ggplot2) library(magrittr) efa_trust0 %$% data.frame(y = values, x = 1:length(values)) %&gt;% ggplot(aes(x, y)) + geom_line() + xlab(&quot;No. of Factors&quot;) + ylab(&quot;Eigenvalues&quot;) We can also use the psych::scree() function to create a scree plot directly from the data. select(ess, trstlgl:impcntr) %&gt;% scree(pc = FALSE) Click for explanation (scree plot) Although the scree plot provides useful information, we need to interpret that information subjectively, and the conclusions are sometimes ambiguous, in this case. In this case, the plot seems to suggest either one or three components, depending on where we consider the “elbow” to lie. As recommended in the lecture, we can also use “parallel analysis” (Horn, 1965) to provide more objective information about the number of factors. We’ll use the psych::fa.parallel() function to implement parallel analysis. Parallel analysis relies on randomly simulated/permuted data, so we should set a seed to make sure our results are reproducible. We can set the fa = \"fa\" option to get only the results for EFA. 3. Parallel Analysis Click to show code ## Set the random number seed: set.seed(235711) ## Run the parallel analysis: pa_trust &lt;- select(ess, trstlgl:impcntr) %&gt;% fa.parallel(fa = &quot;fa&quot;) ## Parallel analysis suggests that the number of factors = 5 and the number of components = NA Click for explanation The results of the parallel analysis suggest 5 factors. If you’ve been paying close attention, you may have noticed that we need to compute the eigenvalues from the original data to run parallel analysis. Hence, we don’t actually need to run a separate EFA to estimate the eigenvalues. ## View the eigenvalues estimated during the parallel analysis: pa_trust$fa.values ## [1] 4.55517136 3.05362593 0.41073627 0.13364902 0.07116952 -0.11909803 ## [7] -0.17729996 -0.25838504 -0.28014401 -0.31230246 -0.34437047 -0.40604399 ## [13] -0.41192101 -0.42303666 -0.44425206 -0.49233019 ## Compare to the version from the EFA: pa_trust$fa.values - efa_trust0$values ## [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## Recreate the scree plot from above: pa_trust %$% data.frame(y = fa.values, x = 1:length(fa.values)) %&gt;% ggplot(aes(x, y)) + geom_line() + xlab(&quot;No. of Factors&quot;) + ylab(&quot;Eigenvalues&quot;) Of course, we also see the same scree plot printed as part of the parallel analysis. So, there’s really no reason to create a separate scree plot, at all, if we’re doing parallel analysis. 4. Conclusion Click for explanation The different criteria disagree on how many factors we should extract, but we have narrowed the range. Based on the scree plot and parallel analysis, we should consider solutions for 3 to 5 factors. We need to examine the factor loadings to see which solution makes the most substantive sense. 4.4.5 Do the same analysis for the attitudes toward immigration items. Click to show code This time, we’ll start by running the parallel analysis and get the eigenvalues and scree plot from psych::fa.parallel(). ## Set the seed: set.seed(235711) ## Run parallel analysis on the &#39;attitudes&#39; items: pa_att &lt;- select(ess, imsmetn:rfgbfml) %&gt;% fa.parallel(fa = &quot;fa&quot;) ## Parallel analysis suggests that the number of factors = 7 and the number of components = NA ## Check the eigenvalues: round(pa_att$fa.values, digits = 3) ## [1] 7.841 1.474 0.748 0.534 0.327 0.152 0.123 0.025 -0.033 -0.064 ## [11] -0.081 -0.098 -0.121 -0.137 -0.145 -0.179 -0.196 -0.204 -0.214 -0.222 ## [21] -0.246 -0.253 -0.331 -0.425 -0.432 Click for explanation For the attitudes toward immigration analysis, the results are even more ambiguous than they were for the trust items. The Kaiser Criterion suggests 2 factors. The scree plot is hopelessly ambiguous. At least 3 factors? No more than 9 factors? Parallel analysis suggests 7 factors Based on the scree plot and parallel analysis, it seems reasonable to consider solutions for 3 to 7 factors. Again, we need to check the substantive interpretation to choose the most reasonable solution. To evaluate the substantive interpretability of the different solutions, we need to estimate the full EFA models for each candidate number of factors. We then compare the factor loadings across solutions to see which set of loadings define the most reasonable set of latent variables. 4.4.6 For the trust items, estimate the EFA models for each plausible number of components that you identified above. Use the psych::fa() function to estimate the models. You will need to specify a few key options. The data (including only the variables you want to analyze) The number of factors that you want to extract The rotation method The estimation method The method of estimating factor scores Hint: You can save yourself a lot of typing/copy-pasting (and the attendant chances of errors) by using a for() loop to iterate through numbers of factors. Click to show code ## Define an empty list to hold all of our fitted EFA objects: efa_trust &lt;- list() ## Loop through the interesting numbers of factors and estimate an EFA for each: for(i in 3:6) efa_trust[[as.character(i)]] &lt;- ess %&gt;% select(trstlgl:impcntr) %&gt;% fa(nfactors = i, # Number of factors = Loop index rotate = &quot;promax&quot;, # Oblique rotation scores = &quot;Bartlett&quot;) # Estimate factor scores with WLS 4.4.7 Repeat the above analysis for the attitudes items. Click to show code efa_att &lt;- list() for(i in 3:7) efa_att[[as.character(i)]] &lt;- ess %&gt;% select(imsmetn:rfgbfml) %&gt;% fa(nfactors = i, rotate = &quot;promax&quot;, scores = &quot;Bartlett&quot;) 4.4.8 Compare the factor loading matrices from the models estimated from the Trust items, and select the best solution. Hints: The factor loadings are stored in the loadings slot of the object returned by psych::fa(). Looping can also be useful here. Click to show code for(x in efa_trust) print(x$loadings) ## ## Loadings: ## MR1 MR3 MR2 ## trstlgl 0.683 ## trstplc 0.600 ## trstplt 0.594 0.198 ## trstep 0.725 ## trstun 0.738 ## stfeco 0.748 ## stfgov 0.109 0.638 ## stfdem 0.253 0.509 ## stfedu 0.644 ## stfhlth 0.628 ## imsmetn 0.811 ## imdfetn 0.875 ## eimrcnt 0.768 ## eimpcnt 0.878 ## imrcntr 0.808 ## impcntr 0.870 ## ## MR1 MR3 MR2 ## SS loadings 4.214 2.339 2.098 ## Proportion Var 0.263 0.146 0.131 ## Cumulative Var 0.263 0.410 0.541 ## ## Loadings: ## MR1 MR3 MR2 MR4 ## trstlgl 0.707 ## trstplc 0.113 0.620 ## trstplt 0.580 0.211 ## trstep 0.709 ## trstun 0.726 ## stfeco 0.758 ## stfgov 0.651 ## stfdem 0.253 0.510 ## stfedu 0.639 ## stfhlth 0.622 ## imsmetn 0.705 0.149 ## imdfetn 0.908 ## eimrcnt 0.213 0.864 ## eimpcnt 0.942 ## imrcntr 0.447 0.515 ## impcntr 0.984 -0.110 ## ## MR1 MR3 MR2 MR4 ## SS loadings 3.458 2.334 2.107 1.061 ## Proportion Var 0.216 0.146 0.132 0.066 ## Cumulative Var 0.216 0.362 0.494 0.560 ## ## Loadings: ## MR1 MR2 MR3 MR4 MR5 ## trstlgl 0.165 0.677 ## trstplc 0.725 ## trstplt 0.202 0.631 ## trstep 0.810 ## trstun 0.653 0.128 ## stfeco 0.736 -0.108 ## stfgov 0.643 0.272 -0.174 ## stfdem 0.511 0.203 ## stfedu 0.668 -0.149 0.134 ## stfhlth 0.637 -0.156 ## imsmetn 0.707 0.144 ## imdfetn 0.912 ## eimrcnt 0.166 0.896 ## eimpcnt 0.952 ## imrcntr 0.421 0.531 ## impcntr 0.995 -0.124 ## ## MR1 MR2 MR3 MR4 MR5 ## SS loadings 3.438 2.123 1.678 1.129 1.071 ## Proportion Var 0.215 0.133 0.105 0.071 0.067 ## Cumulative Var 0.215 0.348 0.452 0.523 0.590 ## ## Loadings: ## MR1 MR2 MR3 MR4 MR5 MR6 ## trstlgl 0.826 ## trstplc 0.851 ## trstplt 0.432 0.353 0.110 ## trstep -0.153 1.092 -0.155 ## trstun 0.470 0.191 ## stfeco 0.704 -0.103 0.155 ## stfgov 0.963 -0.123 ## stfdem 0.545 0.156 ## stfedu 0.653 ## stfhlth 0.666 ## imsmetn 0.708 0.143 ## imdfetn 0.915 ## eimrcnt 0.168 0.890 ## eimpcnt 0.955 ## imrcntr 0.423 0.529 ## impcntr 0.998 -0.122 ## ## MR1 MR2 MR3 MR4 MR5 MR6 ## SS loadings 3.462 1.948 1.563 1.529 1.114 0.921 ## Proportion Var 0.216 0.122 0.098 0.096 0.070 0.058 ## Cumulative Var 0.216 0.338 0.436 0.531 0.601 0.659 Click for explanation Note: Any factor loadings with magnitude lower than 0.1 are suppressed in above output. The factor loadings matrix indicates how strongly each latent factor (columns) associates with the observed items (rows). We can interpret these factor loadings in the same way that we would interpret regression coefficients (indeed, a factor analytic model can be viewed as a multivariate regression model wherein the latent factors are the predictors and the observed items are the outcomes). A higher factor loading indicates a stronger association between the item and factor linked by that loading. Items with high factor loadings are “good” indicators of the respective factors. Items with only very low loadings do not provide much information about any factor. You may want to exclude such items from your analysis. Note that the size of the factor loadings depends on the number of factors. So, you should only consider excluding an observed item after you have chosen the number of latent factors. When we print the loading matrix, we see additional information printed below the factor loadings. Proportion Var: What proportion of the items’ variance is explained by each of the factors. Cumulative Var: How much variance the factors explain, in total. If you estimated as many factors as items, then the Cumulative Var for the final factor would be 1.00 (i.e., 100%). 4.4.9 Compare the factor loading matrices from the models estimated from the Attitudes items, and select the best solution. Click to show code for(x in efa_att) print(x$loadings) ## ## Loadings: ## MR1 MR2 MR3 ## imsmetn 0.801 ## imdfetn 0.756 0.111 ## eimrcnt 0.837 ## eimpcnt 0.813 ## imrcntr 0.854 ## impcntr 0.771 ## qfimchr 0.233 0.852 ## qfimwht 0.135 0.712 ## imwgdwn 0.308 -0.163 ## imhecop 0.380 -0.143 ## imtcjob 0.615 ## imbleco 0.691 ## imbgeco 0.681 ## imueclt 0.558 -0.209 ## imwbcnt 0.731 ## imwbcrm 0.634 ## imrsprc -0.487 -0.119 ## pplstrd 0.259 -0.413 ## vrtrlg -0.261 0.274 ## shrrfg 0.529 -0.105 ## rfgawrk -0.368 ## gvrfgap -0.615 -0.151 ## rfgfrpc 0.449 ## rfggvfn -0.478 ## rfgbfml -0.541 ## ## MR1 MR2 MR3 ## SS loadings 4.811 3.943 1.667 ## Proportion Var 0.192 0.158 0.067 ## Cumulative Var 0.192 0.350 0.417 ## ## Loadings: ## MR2 MR1 MR4 MR3 ## imsmetn 0.788 ## imdfetn 0.734 0.144 0.115 ## eimrcnt 0.854 -0.146 ## eimpcnt 0.788 0.161 ## imrcntr 0.861 ## impcntr 0.744 0.191 ## qfimchr -0.141 0.859 ## qfimwht 0.735 ## imwgdwn 0.601 0.237 ## imhecop 0.656 0.210 ## imtcjob 0.671 0.141 ## imbleco 0.607 -0.157 0.156 ## imbgeco 0.635 -0.123 ## imueclt 0.368 -0.241 -0.187 ## imwbcnt 0.536 -0.262 ## imwbcrm 0.430 -0.257 ## imrsprc 0.605 ## pplstrd 0.219 -0.396 ## vrtrlg 0.220 0.295 ## shrrfg 0.300 -0.277 ## rfgawrk 0.447 ## gvrfgap 0.765 ## rfgfrpc 0.228 -0.263 ## rfggvfn 0.483 ## rfgbfml 0.635 ## ## MR2 MR1 MR4 MR3 ## SS loadings 3.831 2.867 2.460 1.671 ## Proportion Var 0.153 0.115 0.098 0.067 ## Cumulative Var 0.153 0.268 0.366 0.433 ## ## Loadings: ## MR2 MR1 MR5 MR3 MR4 ## imsmetn 0.794 ## imdfetn 0.733 0.156 0.117 ## eimrcnt 0.905 -0.139 -0.229 ## eimpcnt 0.781 0.110 0.197 ## imrcntr 0.908 -0.117 -0.179 ## impcntr 0.734 0.123 0.231 ## qfimchr 0.114 -0.156 0.864 ## qfimwht 0.165 0.735 ## imwgdwn 0.717 ## imhecop 0.695 ## imtcjob 0.532 0.129 0.207 ## imbleco 0.691 0.142 ## imbgeco 0.793 ## imueclt 0.560 -0.211 ## imwbcnt 0.711 ## imwbcrm 0.557 -0.110 ## imrsprc 0.610 ## pplstrd 0.224 -0.406 ## vrtrlg -0.222 0.102 0.308 0.103 ## shrrfg 0.228 -0.266 0.121 ## rfgawrk 0.450 ## gvrfgap 0.778 ## rfgfrpc -0.317 0.165 ## rfggvfn 0.503 ## rfgbfml -0.110 0.562 ## ## MR2 MR1 MR5 MR3 MR4 ## SS loadings 3.974 2.799 2.193 1.693 1.131 ## Proportion Var 0.159 0.112 0.088 0.068 0.045 ## Cumulative Var 0.159 0.271 0.359 0.426 0.472 ## ## Loadings: ## MR2 MR1 MR6 MR3 MR5 MR4 ## imsmetn 0.696 0.175 ## imdfetn 0.834 ## eimrcnt 0.236 0.868 ## eimpcnt 0.943 ## imrcntr 0.447 0.526 ## impcntr 0.956 ## qfimchr 0.140 -0.120 0.858 ## qfimwht 0.174 0.723 ## imwgdwn 0.723 ## imhecop 0.678 ## imtcjob 0.551 0.127 0.202 ## imbleco 0.753 0.150 ## imbgeco 0.813 ## imueclt 0.567 -0.210 ## imwbcnt 0.744 ## imwbcrm 0.601 ## imrsprc 0.158 0.514 -0.103 ## pplstrd 0.222 -0.402 ## vrtrlg -0.224 0.305 0.101 ## shrrfg 0.217 -0.281 -0.102 0.125 ## rfgawrk 0.499 ## gvrfgap 0.786 ## rfgfrpc 0.100 -0.279 0.156 ## rfggvfn 0.530 ## rfgbfml 0.610 ## ## MR2 MR1 MR6 MR3 MR5 MR4 ## SS loadings 3.289 2.992 1.988 1.649 1.091 1.102 ## Proportion Var 0.132 0.120 0.080 0.066 0.044 0.044 ## Cumulative Var 0.132 0.251 0.331 0.397 0.440 0.484 ## ## Loadings: ## MR2 MR1 MR6 MR7 MR5 MR4 MR3 ## imsmetn 0.715 0.170 ## imdfetn 0.854 ## eimrcnt 0.255 0.852 ## eimpcnt 0.965 ## imrcntr 0.467 0.516 ## impcntr 0.978 ## qfimchr -0.231 0.625 ## qfimwht 0.107 0.718 ## imwgdwn 0.735 ## imhecop 0.715 ## imtcjob 0.573 -0.163 0.198 ## imbleco 0.709 ## imbgeco 0.852 -0.108 ## imueclt 0.435 0.288 -0.110 ## imwbcnt 0.576 0.235 ## imwbcrm 0.423 0.225 0.122 ## imrsprc 0.160 0.480 -0.100 ## pplstrd 0.648 -0.109 ## vrtrlg -0.527 ## shrrfg -0.212 0.324 0.149 ## rfgawrk 0.517 ## gvrfgap 0.744 ## rfgfrpc -0.213 0.237 0.182 ## rfggvfn 0.542 ## rfgbfml 0.599 ## ## MR2 MR1 MR6 MR7 MR5 MR4 MR3 ## SS loadings 3.462 2.275 1.830 1.175 1.052 1.184 0.991 ## Proportion Var 0.138 0.091 0.073 0.047 0.042 0.047 0.040 ## Cumulative Var 0.138 0.229 0.303 0.350 0.392 0.439 0.479 It is very possible that you selected a different numbers of factors than Kestilä (2006). We need to keep these exercises consistent, though. So, the remaining questions will all assume you have extract three factors from the Trust items and five factors from the Attitudes items, to parallel the Kestilä (2006) results. ## Select the three-factor solution for &#39;trust&#39;: efa_trust &lt;- efa_trust[[&quot;3&quot;]] ## Select the five-factor solution for &#39;attitudes&#39;: efa_att &lt;- efa_att[[&quot;5&quot;]] 4.4.10 Give the factor scores meaningful names, and add the scores to the ess dataset as new columns. Hint: If you’re not sure of what do to, check 4.3.9. Click to show code ## Rename the factor scores: colnames(efa_trust$scores) &lt;- c(&quot;trust_pol&quot;, &quot;satisfy&quot;, &quot;trust_inst&quot;) colnames(efa_att$scores) &lt;- c(&quot;effects&quot;, &quot;allowance&quot;, &quot;refugees&quot;, &quot;ethnic&quot;, &quot;europe&quot;) ## Add factor scores to the dataset as new columns: ess &lt;- data.frame(ess, efa_trust$scores, efa_att$scores) Kestilä (2006) used the component scores to descriptively evaluate country-level differences in Attitudes toward Immigration and Political Trust. So, now it’s time to replicate those analyses. 4.4.11 Repeat the Kestilä (2006) between-country comparison using the factor scores you created in 4.4.10 and an appropriate statistical test. Click to show code Here, we’ll only demonstrate a possible approach to analyzing one of the Trust dimensions. We can use a linear model to test whether the countries differ in average levels of Trust in Institutions (as quantified by the relevant factor score). ## Estimate the model: out &lt;- lm(trust_inst ~ cntry, data = ess) ## View the regression-style summary: summary(out) ## ## Call: ## lm(formula = trust_inst ~ cntry, data = ess) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.0439 -0.5990 0.0774 0.6546 3.8306 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.05722 0.02380 2.404 0.01624 * ## cntryBelgium 0.24797 0.03461 7.165 8.15e-13 *** ## cntryDenmark 0.89049 0.03709 24.006 &lt; 2e-16 *** ## cntryFinland 0.66876 0.03293 20.309 &lt; 2e-16 *** ## cntryGermany -1.02160 0.03082 -33.147 &lt; 2e-16 *** ## cntryItaly -0.70295 0.03910 -17.980 &lt; 2e-16 *** ## cntryNetherlands -0.10502 0.03233 -3.248 0.00117 ** ## cntryNorway 0.07686 0.03331 2.308 0.02103 * ## cntrySweden -0.06433 0.03464 -1.857 0.06332 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.956 on 14315 degrees of freedom ## (3863 observations deleted due to missingness) ## Multiple R-squared: 0.2656, Adjusted R-squared: 0.2652 ## F-statistic: 647.2 on 8 and 14315 DF, p-value: &lt; 2.2e-16 ## View the results as an ANOVA table: anova(out) ## Post-hoc tests out %&gt;% aov() %&gt;% TukeyHSD() ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = .) ## ## $cntry ## diff lwr upr p adj ## Belgium-Austria 0.24796876 0.14060941 0.355328097 0.0000000 ## Denmark-Austria 0.89049075 0.77541622 1.005565280 0.0000000 ## Finland-Austria 0.66876487 0.56661216 0.770917590 0.0000000 ## Germany-Austria -1.02160451 -1.11721519 -0.925993827 0.0000000 ## Italy-Austria -0.70295083 -0.82423523 -0.581666425 0.0000000 ## Netherlands-Austria -0.10501583 -0.20532400 -0.004707667 0.0319748 ## Norway-Austria 0.07685797 -0.02646120 0.180177134 0.3373046 ## Sweden-Austria -0.06432725 -0.17178456 0.043130061 0.6435559 ## Denmark-Belgium 0.64252199 0.52477886 0.760265130 0.0000000 ## Finland-Belgium 0.42079612 0.31564634 0.525945897 0.0000000 ## Germany-Belgium -1.26957326 -1.36837964 -1.170766883 0.0000000 ## Italy-Belgium -0.95091958 -1.07473883 -0.827100341 0.0000000 ## Netherlands-Belgium -0.35298459 -0.45634331 -0.249625861 0.0000000 ## Norway-Belgium -0.17111079 -0.27739413 -0.064827447 0.0000211 ## Sweden-Belgium -0.31229600 -0.42260635 -0.201985661 0.0000000 ## Finland-Denmark -0.22172588 -0.33474178 -0.108709970 0.0000000 ## Germany-Denmark -1.91209526 -2.01923451 -1.804956003 0.0000000 ## Italy-Denmark -1.59344158 -1.72400698 -1.462876176 0.0000000 ## Netherlands-Denmark -0.99550658 -1.10685803 -0.884155131 0.0000000 ## Norway-Denmark -0.81363278 -0.92770411 -0.699561455 0.0000000 ## Sweden-Denmark -0.95481800 -1.07265047 -0.836985529 0.0000000 ## Germany-Finland -1.69036938 -1.78349215 -1.597246611 0.0000000 ## Italy-Finland -1.37171570 -1.49104866 -1.252382745 0.0000000 ## Netherlands-Finland -0.77378070 -0.87172036 -0.675841051 0.0000000 ## Norway-Finland -0.59190690 -0.69292818 -0.490885631 0.0000000 ## Sweden-Finland -0.73309212 -0.83834193 -0.627842317 0.0000000 ## Italy-Germany 0.31865368 0.20487064 0.432436712 0.0000000 ## Netherlands-Germany 0.91658867 0.82549312 1.007684229 0.0000000 ## Norway-Germany 1.09846248 1.00406162 1.192863333 0.0000000 ## Sweden-Germany 0.95727726 0.85836444 1.056190076 0.0000000 ## Netherlands-Italy 0.59793500 0.48017717 0.715692818 0.0000000 ## Norway-Italy 0.77980880 0.65947582 0.900141779 0.0000000 ## Sweden-Italy 0.63862358 0.51471938 0.762527777 0.0000000 ## Norway-Netherlands 0.18187380 0.08271813 0.281029475 0.0000005 ## Sweden-Netherlands 0.04068858 -0.06277190 0.144149065 0.9523456 ## Sweden-Norway -0.14118522 -0.24756752 -0.034802920 0.0012799 Click for explanation According to the omnibus F-test, average levels of Trust in Institutions significantly differ between countries, but this test cannot tell us between which countries the differences lie. Similarly, the t statistics associated with each dummy code in the regression-style summary only tell us if that country differs significantly from the reference country (i.e., Austria), but we cannot see, for example, if there is a significant difference in average trust levels between Belgium and the Netherlands. One way to test for differences between the individual countries would be a post hoc test of all pairwise comparisons. Since we’ll be doing 45 tests, we need to apply a correction for repeated testing. Above, we use the TukeyHSD() function to conduct all pairwise comparisons while applying Tukey’s HSD correction. The TukeyHSD() function only accepts models estimated with the aov() function, so we first pass our fitted lm object through aov(). The second part of the Kestilä (2006) analysis was to evaluate how socio-demographic characteristics affected attitudes towards immigrants and trust in politics among the Finnish electorate. Before we can replicate this part of the analysis, we need to subset the data to only the Finnish cases. 4.4.12 Create a new data frame that contains only the Finnish cases from ess. Hint: You can use logical indexing based on the cntry variable. Click to show code ess_finland &lt;- filter(ess, cntry == &quot;Finland&quot;) We still have one more step before we can estimate any models. We must prepare our variables for analysis. Our dependent variables will be the factor scores generated above. So, we do not need to apply any further processing. We have not yet used any of the independent variables, though. So, we should inspect those variables to see if they require any processing. In the ess data, the relevant variables have the following names: gndr yrbrn eduyrs polintr lrscale 4.4.13 Inspect the independent variables listed above. Click to show code library(tidySEM) select(ess_finland, gndr, yrbrn, eduyrs, polintr, lrscale) %&gt;% descriptives() Click for explanation It looks like we still need some recoding. 4.4.14 Apply any necessary recoding/transformations. 1. Age Click to show code ess_finland &lt;- mutate(ess_finland, age = 2002 - yrbrn) Click for explanation The data contain the participants’ years of birth instead of their age, but Kestilä analyzed age. Fortunately, we know that the data were collected in 2002, so we can simply subtract each participant’s value of yrbrn from the 2002 to compute their age. 2. Political Interest &amp; Orientation Click to show code First, we’ll transform polintr. ## Store the original variable for checking purposes: tmp &lt;- ess_finland$polintr ## Recode the four character values into two factor levels: ess_finland &lt;- mutate(ess_finland, polintr_bin = recode_factor(polintr, &quot;Not at all interested&quot; = &quot;Low Interest&quot;, &quot;Hardly interested&quot; = &quot;Low Interest&quot;, &quot;Quite interested&quot; = &quot;High Interest&quot;, &quot;Very interested&quot; = &quot;High Interest&quot;) ) ## Check the conversion: table(old = tmp, new = ess_finland$polintr_bin, useNA = &quot;always&quot;) ## new ## old Low Interest High Interest &lt;NA&gt; ## Hardly interested 842 0 0 ## Not at all interested 228 0 0 ## Quite interested 0 785 0 ## Very interested 0 144 0 ## &lt;NA&gt; 0 0 1 Now, we’ll deal with lrscale. ## Save the old version for checking: tmp &lt;- ess_finland$lrscale ## Recode the extreme levels: ess_finland &lt;- mutate(ess_finland, lrscale = recode(lrscale, &quot;Left&quot; = 0, &quot;Right&quot; = 10, .default = as.numeric(lrscale) ) ) ## Check the conversion: table(old = tmp, new = ess_finland$lrscale, useNA = &quot;always&quot;) ## new ## old 0 1 2 3 4 5 6 7 8 9 10 &lt;NA&gt; ## 1 0 25 0 0 0 0 0 0 0 0 0 0 ## 2 0 0 62 0 0 0 0 0 0 0 0 0 ## 3 0 0 0 148 0 0 0 0 0 0 0 0 ## 4 0 0 0 0 183 0 0 0 0 0 0 0 ## 5 0 0 0 0 0 599 0 0 0 0 0 0 ## 6 0 0 0 0 0 0 199 0 0 0 0 0 ## 7 0 0 0 0 0 0 0 296 0 0 0 0 ## 8 0 0 0 0 0 0 0 0 217 0 0 0 ## 9 0 0 0 0 0 0 0 0 0 79 0 0 ## Left 24 0 0 0 0 0 0 0 0 0 0 0 ## Right 0 0 0 0 0 0 0 0 0 0 59 0 ## &lt;NA&gt; 0 0 0 0 0 0 0 0 0 0 0 109 Click for explanation The variables polintr and lrscale are represented as character vectors. If we analyze these variables as they are, R will convert the character vectors to factors and make dummy codes for each distinct value; we definitely don’t want that. We need to convert polintr and lrscale to numeric vectors, but we cannot naively apply the as.numeric() function, because R doesn’t know how to convert a word into a number (or, at least, not how we want the operation to be done). There are many ways that we could go about this conversion, but the recode() function from the dplyr package is particularly useful for arbitrary recoding tasks such as we have here. Kestilä (2006) dichotomized polintr by combining the lowest two and highest two categories. So, we don’t actually want to convert the polint variable into a numeric, Likert-type variable. We want polint to be a binary factor. The recode_factor() function from dplyr() will automatically convert our result into a factor. For political orientation, only the two extreme values of the scale are labeled as text. So, we only need to recode those two levels. Since we’re only replacing two of the 11 values, we’ll need to provide a value for the .default argument in dplyr::recode(). 3. Sex Click to show code ess_finland &lt;- mutate(ess_finland, sex = factor(gndr)) ## Check results: ess_finland %$% table(old = gndr, new = sex, useNA = &quot;always&quot;) ## new ## old Female Male &lt;NA&gt; ## Female 1040 0 0 ## Male 0 960 0 ## &lt;NA&gt; 0 0 0 Click for explanation Although gndr would be automatically converted to a factor by lm(), it’s better to be explicit about our intentions and create the factor ourselves. Now, we’re finally ready to replicate the regression analysis from Kestilä (2006). Creating a single aggregate score by summing the individual component scores is a pretty silly thing to do, though. So, we won’t reproduce that aspect of the analysis. 4.4.15 Run a series of multiple linear regression analyses with the factor scores you created in 4.4.10 as the dependent variables and the same predictors used by Kestilä (2006). Do your results agree with those reported by Kestilä (2006)? Click to show code ## Predicting &#39;Trust in Institutions&#39;: out_trust_inst &lt;- lm(trust_inst ~ sex + age + eduyrs + polintr_bin + lrscale, data = ess_finland) summary(out_trust_inst) ## ## Call: ## lm(formula = trust_inst ~ sex + age + eduyrs + polintr_bin + ## lrscale, data = ess_finland) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.5724 -0.4492 0.1260 0.5941 2.3547 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.3289965 0.1151344 2.857 0.004322 ** ## sexMale 0.1505241 0.0409380 3.677 0.000243 *** ## age -0.0055811 0.0012592 -4.432 9.92e-06 *** ## eduyrs -0.0001833 0.0057951 -0.032 0.974774 ## polintr_binHigh Interest 0.1237345 0.0421741 2.934 0.003392 ** ## lrscale 0.0907595 0.0101966 8.901 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.8355 on 1694 degrees of freedom ## (300 observations deleted due to missingness) ## Multiple R-squared: 0.06695, Adjusted R-squared: 0.0642 ## F-statistic: 24.31 on 5 and 1694 DF, p-value: &lt; 2.2e-16 ## Predicting &#39;Trust in Politicians&#39;: out_trust_pol &lt;- lm(trust_pol ~ sex + age + eduyrs + polintr_bin + lrscale, data = ess_finland) summary(out_trust_pol) ## ## Call: ## lm(formula = trust_pol ~ sex + age + eduyrs + polintr_bin + lrscale, ## data = ess_finland) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.85480 -0.50639 0.06368 0.63001 2.58685 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.097827 0.121803 0.803 0.421995 ## sexMale 0.163314 0.043309 3.771 0.000168 *** ## age 0.013771 0.001332 10.337 &lt; 2e-16 *** ## eduyrs -0.050447 0.006131 -8.229 3.73e-16 *** ## polintr_binHigh Interest -0.258279 0.044617 -5.789 8.43e-09 *** ## lrscale 0.033794 0.010787 3.133 0.001761 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.8839 on 1694 degrees of freedom ## (300 observations deleted due to missingness) ## Multiple R-squared: 0.1645, Adjusted R-squared: 0.1621 ## F-statistic: 66.73 on 5 and 1694 DF, p-value: &lt; 2.2e-16 ## Predicting &#39;Attitudes toward Refugees&#39;: out_refugees &lt;- lm(refugees ~ sex + age + eduyrs + polintr_bin + lrscale, data = ess_finland) summary(out_refugees) ## ## Call: ## lm(formula = refugees ~ sex + age + eduyrs + polintr_bin + lrscale, ## data = ess_finland) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.8921 -0.7112 -0.0618 0.6912 4.1660 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.6771470 0.1489234 -4.547 5.83e-06 *** ## sexMale 0.4853926 0.0524999 9.246 &lt; 2e-16 *** ## age -0.0004773 0.0016248 -0.294 0.768968 ## eduyrs -0.0254016 0.0075576 -3.361 0.000794 *** ## polintr_binHigh Interest -0.2148018 0.0541602 -3.966 7.61e-05 *** ## lrscale 0.0940049 0.0131295 7.160 1.20e-12 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.074 on 1699 degrees of freedom ## (295 observations deleted due to missingness) ## Multiple R-squared: 0.09368, Adjusted R-squared: 0.09102 ## F-statistic: 35.12 on 5 and 1699 DF, p-value: &lt; 2.2e-16 That does it for our replication of the Kesilä (2006) analyses, but we still have one more topic to consider in this practical. One of the most common applications of EFA is scale development. Given a pool of items without a known factor structure, we try to estimate the underlying latent factors that define the (sub)scales represented by our items. In such applications, we use the factor loading matrix for our optimal solution to make “bright-line” assignments of items to putative factors according to the simple structure represented by the estimated factor loading matrix. In other words, we disregard small factor loadings and assign observed items to only the single latent factor upon which they load most strongly. We then hypothesize that those items are true indicators of that latent factor. We can use confirmatory factor analysis (which you will learn about next week) to test rigorously this hypothesis, but we can already get started by estimating the internal consistency (a type of reliability) of the hypothesized subscales. 4.4.16 Estimate the internal consistency of the three Trust subscales and five Attitudes subscales implied by your EFA solutions from above. Use Cronbach’s Alpha to quantify internal consistency. Use the alpha() function from the psych package to conduct the analysis. Run your analysis on the full ess dataset, not the Finnish subset. Are the subscales implied by your EFA reliable, in the sense of good internal consistency? Note that \\(\\alpha &gt; 0.7\\) is generally considered acceptable, and \\(\\alpha &gt; 0.8\\) is usually considered good. Click to show code ## Run the reliability analysis on the subscale data: ( out &lt;- select(ess, starts_with(&quot;stf&quot;)) %&gt;% psych::alpha() ) ## ## Reliability analysis ## Call: psych::alpha(x = .) ## ## raw_alpha std.alpha G6(smc) average_r S/N ase mean sd median_r ## 0.79 0.79 0.77 0.44 3.9 0.0024 6.4 1.7 0.41 ## ## 95% confidence boundaries ## lower alpha upper ## Feldt 0.79 0.79 0.8 ## Duhachek 0.79 0.79 0.8 ## ## Reliability if an item is dropped: ## raw_alpha std.alpha G6(smc) average_r S/N alpha se var.r med.r ## stfeco 0.74 0.74 0.70 0.42 2.9 0.0032 0.0067 0.39 ## stfgov 0.74 0.74 0.69 0.42 2.9 0.0031 0.0031 0.41 ## stfdem 0.75 0.75 0.71 0.43 3.0 0.0030 0.0074 0.41 ## stfedu 0.76 0.76 0.72 0.45 3.2 0.0029 0.0103 0.43 ## stfhlth 0.78 0.78 0.73 0.47 3.5 0.0027 0.0063 0.45 ## ## Item statistics ## n raw.r std.r r.cor r.drop mean sd ## stfeco 17728 0.78 0.77 0.70 0.62 6.1 2.3 ## stfgov 17621 0.77 0.77 0.70 0.61 5.5 2.3 ## stfdem 17624 0.75 0.75 0.66 0.58 6.8 2.2 ## stfedu 17380 0.73 0.73 0.62 0.55 7.0 2.3 ## stfhlth 17981 0.70 0.69 0.57 0.50 6.8 2.3 Click for explanation Here, we estimate the reliability of the Satisfaction subscale from the Trust analysis. According to our EFA, the Satisfaction subscale should be indicated by the following five variables: stfeco stfgov stfdem stfedu stfhlth We select these variables using the tidy-select function starts_with() to extract all variables beginning with the three characters “stf”. To estimate the internal consistency of this subscale, we simply provide a data frame containing only the subscale data to the alpha() function. The raw_alpha value is the estimate of Cronbach’s Alpha. In this case \\(\\alpha = 0.795\\), so the subscale is pretty reliable. The table labeled “Reliability if an item is dropped” shows what Cronbach’s Alpha would be if each item were excluded from the scale. If this value is notably higher than the raw_alpha value, it could indicate a bad item. Note that reliability is only one aspect of scale quality, though. So, you shouldn’t throw out items just because they perform poorly in reliability analysis. End of In-Class Exercises "],["cfa.html", "5 CFA", " 5 CFA This week, we will introduce confirmatory factor analysis (CFA) and discuss how it differs from EFA. Furthermore, we will revisit the idea of model fit and introduce into the R-package lavaan. Homework before the lecture Watch the Lecture Recording for this week. Complete the Reading for this week, and answer the associated reading questions. Homework before the practical Complete the At-Home Exercises. Practical content During the practical you will work on the In-Class Exercises. "],["lecture-4.html", "5.1 Lecture", " 5.1 Lecture Often, we work with scales that have a validated or hypothesized factor structure. In the former case, the scale structure has been validated through previous psychometric studies. In the latter case, we may have conducted an EFA to estimate the factor structure on prior data, or theory/intuition may suggest a plausible structure. Regardless of how we come to expect a given factor structure, such situations represent confirmatory modeling problems, because we are attempting to empirically confirm an a priori expectation. Hence, exploratory methods like EFA are not appropriate, and we should employ confirmatory modeling techniques. This week we consider one such technique: confirmatory factor analysis (CFA). As the name suggests, CFA is related to the EFA methods we discussed last week in that both methods are flavors of factor analysis. However, the two methods address fundamentally different research questions. Rather than attempting to estimate an unknown factor structure (as in EFA), we now want to compare a hypothesized measurement model (i.e., factor structure) to observed data in order to evaluate the model’s plausibility. 5.1.1 Recording Note: When Caspar discusses the complexity of the second-order CFA model, it’s easy to misunderstand his statements. We need to be careful not to over-generalize. In general, a second-order CFA is not more complex than a first-order CFA. Actually, in most practical applications, the opposite is true. A second-order CFA is more complex than a first-order CFA, when the factors in the first-order CFA are uncorrelated. This is the situation Caspar references in the recording when claiming that the second-order model is more complex. We hardly ever want to fit such first-order CFA, though. The default CFA fully saturates the latent covariance structure. If the factors in the first-order CFA are fully correlated (according to standard practice), and we include a single second-order factor, the following statements hold. If the first-order CFA has more than three factors, the first-order model is more complex than the second-order model. If the first-order model has three or fewer factors, the first- and second-order models are equivalent (due to scaling constraints we need to impose to identify the second-order model). The second-order model cannot be more complex than the first-order model (assuming both models are correctly identified and no extra constraints are imposed). The above statements may not hold in more complex situations (e.g., more than one second-order factor, partially saturated first-order correlation structure, etc.). You can always identify the more complex model by calculating the degrees of freedom for both models. The model with fewer degrees of freedom is more complex. 5.1.2 Slides You can download the lecture slides here "],["reading-4.html", "5.2 Reading", " 5.2 Reading Reference Byrne, B. (2005). Factor analytic models: Viewing the structure of an assessment instrument from three perspectives, Journal of Personality Assessment, 85(1), 17–32. Questions What are the main differences between exploratory factor analysis (EFA) and confirmatory factor analysis (CFA)? In which circumstances should a researcher use EFA, and in which should they use CFA? What are the five main limitations of EFA that CFA overcomes? In which circumstances can a second order CFA model be useful? Consider the following four techniques: PCA, EFA, CFA, second order CFA. For each of the following three research situations, which of the above techniques would you use and why? A researcher has developed a new questionnaire that should measure personality and wants to know how many factors underlie the items in their new measure. A researcher is modeling data collected with a seven-item scale that has been used since the 1960s to measure authoritarianism. A researcher has recorded highest completed level of education, years of education, and highest level of education attempted for all respondents in a survey. The researcher wants to include some operationalization of the concept of ‘education’ in their model but is unsure of which observed variable to use. "],["at-home-exercises-4.html", "5.3 At-Home Exercises", " 5.3 At-Home Exercises This week, we will wrap up our re-analysis of the Kestilä (2006) results. During this practical, you will conduct a CFA of the Trust in Politics items and compare the results to those obtained from your previous EFA- and PCA-based replications of Kestilä (2006). 5.3.1 Load the ESS data. The relevant data are contained in the ess_round1.rds file. This file is in R Data Set (RDS) format. The dataset is already stored as a data frame with the processing and cleaning that you should have done for previous practicals completed. Check the documentation for the readRDS() function to see how you can load data stored in an RDS file. Click for explanation ess &lt;- readRDS(&quot;ess_round1.rds&quot;) Although you may have settled on any number of EFA solutions during the Week 4 In-Class Exercises, we are going to base the following CFA on a three-factor model of Trust in Politics similar to the original PCA results from Kestilä (2006). Note: Unless otherwise specified, all following questions refer to the Trust in Politics items. We will not consider the Attitudes toward Immigration items in these exercises. 5.3.2 Define the lavaan model syntax for the CFA implied by the three-factor EFA solution you found in the Week 2 In-Class Exercises. Covary the three latent factors. Do not specify any mean structure. Save this model syntax as an object in your environment. Click for explanation We don’t have to specify the latent covariances in the model syntax, we can tell lavaan to estimate all latent covariances when we fit the model. mod_3f &lt;- &#39; politicians =~ pltcare + pltinvt + trstplt satisfaction =~ stfeco + stfgov + stfdem + stfedu + stfhlth institutions =~ trstlgl + trstplc + trstun + trstprl &#39; 5.3.3 Estimate the CFA model you defined above, and summarize the results. Use the lavaan::cfa() function to estimate the model. Use the default settings for the cfa() function. Request the model fit statistics with the summary by supplying the fit.measures = TRUE argument to summary(). Request the standardized parameter estimates with the summary by supplying the standardized = TRUE argument to summary(). Check the results, and answer the following questions: Does the model fit the data well? How are the latent variances and covariances specified when using the default settings? How is the model identified when using the default settings? Click for explanation ## Load the lavaan package: library(lavaan) ## Estimate the CFA model: fit_3f &lt;- cfa(mod_3f, data = ess) ## Summarize the fitted model: summary(fit_3f, fit.measures = TRUE, standardized = TRUE) ## lavaan 0.6.16 ended normally after 45 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 27 ## ## Used Total ## Number of observations 15448 18187 ## ## Model Test User Model: ## ## Test statistic 9188.922 ## Degrees of freedom 51 ## P-value (Chi-square) 0.000 ## ## Model Test Baseline Model: ## ## Test statistic 75675.049 ## Degrees of freedom 66 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.879 ## Tucker-Lewis Index (TLI) 0.844 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -357923.209 ## Loglikelihood unrestricted model (H1) -353328.748 ## ## Akaike (AIC) 715900.419 ## Bayesian (BIC) 716106.840 ## Sample-size adjusted Bayesian (SABIC) 716021.036 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.108 ## 90 Percent confidence interval - lower 0.106 ## 90 Percent confidence interval - upper 0.110 ## P-value H_0: RMSEA &lt;= 0.050 0.000 ## P-value H_0: RMSEA &gt;= 0.080 1.000 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.058 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## politicians =~ ## pltcare 1.000 0.671 0.639 ## pltinvt 0.981 0.015 65.449 0.000 0.658 0.624 ## trstplt 2.848 0.035 80.855 0.000 1.911 0.876 ## satisfaction =~ ## stfeco 1.000 1.659 0.712 ## stfgov 1.039 0.013 81.895 0.000 1.724 0.752 ## stfdem 0.979 0.012 80.257 0.000 1.624 0.733 ## stfedu 0.780 0.012 64.344 0.000 1.294 0.576 ## stfhlth 0.706 0.012 58.239 0.000 1.171 0.519 ## institutions =~ ## trstlgl 1.000 1.640 0.688 ## trstplc 0.777 0.012 64.538 0.000 1.275 0.582 ## trstun 0.861 0.013 66.949 0.000 1.411 0.605 ## trstprl 1.123 0.013 85.721 0.000 1.842 0.812 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## politicians ~~ ## satisfaction 0.793 0.016 48.672 0.000 0.712 0.712 ## institutions 0.950 0.018 51.888 0.000 0.863 0.863 ## satisfaction ~~ ## institutions 2.046 0.040 51.736 0.000 0.752 0.752 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .pltcare 0.651 0.008 77.811 0.000 0.651 0.591 ## .pltinvt 0.680 0.009 78.658 0.000 0.680 0.611 ## .trstplt 1.103 0.029 38.414 0.000 1.103 0.232 ## .stfeco 2.671 0.038 70.723 0.000 2.671 0.493 ## .stfgov 2.287 0.035 66.172 0.000 2.287 0.435 ## .stfdem 2.266 0.033 68.444 0.000 2.266 0.462 ## .stfedu 3.378 0.042 79.725 0.000 3.378 0.668 ## .stfhlth 3.721 0.045 81.846 0.000 3.721 0.731 ## .trstlgl 2.997 0.040 74.548 0.000 2.997 0.527 ## .trstplc 3.178 0.040 80.410 0.000 3.178 0.662 ## .trstun 3.443 0.043 79.405 0.000 3.443 0.633 ## .trstprl 1.746 0.030 57.842 0.000 1.746 0.340 ## politicians 0.450 0.011 41.572 0.000 1.000 1.000 ## satisfaction 2.751 0.058 47.286 0.000 1.000 1.000 ## institutions 2.690 0.059 45.613 0.000 1.000 1.000 No, the model does not seem to fit the data well. The SRMR looks good, but one good looking fit statistic is not enough. The RMSEA, TLI, and CFI are all in the “unacceptable” range. The \\(\\chi^2\\) is highly significant, but we don’t care. The cfa() function is just a wrapper for the lavaan() function with several options set at the defaults you would want for a standard CFA. By default: All latent variances and covariances are freely estimated (due to the argument auto.cov.lv.x = TRUE) The model is identified by fixing the first factor loading of each factor to 1 (due to the argument auto.fix.first = TRUE) To see a full list of the (many) options you can specify to tweak the behavior of lavaan estimation functions run ?lavOptions. Now, we will consider a couple of alternative factor structures for the Trust in Politics CFA. First, we will go extremely simple by estimating a one-factor model wherein all Trust items are explained by a single latent variable. 5.3.4 Define the lavaan model syntax for a one-factor model of the Trust items. Save this syntax as an object in your environment. Click for explanation mod_1f &lt;- &#39; political_trust =~ pltcare + pltinvt + trstprl + trstplt + stfeco + stfgov + stfdem + stfedu + stfhlth + trstlgl + trstplc + trstun + trstep &#39; 5.3.5 Estimate the one-factor model, and summarize the results. Does this model appear to fit better or worse than the three-factor model? Notes: We can also conduct a formal significance test for the difference between two \\(\\chi^2\\) values, but we won’t introduce those ideas until Week 5. You can use the lavaan::fitMeasures() function to extract only the model fit information from a fitted lavaan object. Click for explanation ## Estimate the one factor model: fit_1f &lt;- cfa(mod_1f, data = ess) ## Summarize the results: summary(fit_1f, fit.measures = TRUE) ## lavaan 0.6.16 ended normally after 38 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 26 ## ## Used Total ## Number of observations 14778 18187 ## ## Model Test User Model: ## ## Test statistic 17667.304 ## Degrees of freedom 65 ## P-value (Chi-square) 0.000 ## ## Model Test Baseline Model: ## ## Test statistic 81699.096 ## Degrees of freedom 78 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.784 ## Tucker-Lewis Index (TLI) 0.741 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -374912.206 ## Loglikelihood unrestricted model (H1) -366078.555 ## ## Akaike (AIC) 749876.413 ## Bayesian (BIC) 750074.036 ## Sample-size adjusted Bayesian (SABIC) 749991.410 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.135 ## 90 Percent confidence interval - lower 0.134 ## 90 Percent confidence interval - upper 0.137 ## P-value H_0: RMSEA &lt;= 0.050 0.000 ## P-value H_0: RMSEA &gt;= 0.080 1.000 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.080 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## political_trust =~ ## pltcare 1.000 ## pltinvt 0.966 0.018 55.075 0.000 ## trstprl 2.986 0.043 70.171 0.000 ## trstplt 2.988 0.042 71.755 0.000 ## stfeco 2.262 0.039 57.544 0.000 ## stfgov 2.489 0.040 62.079 0.000 ## stfdem 2.522 0.039 64.095 0.000 ## stfedu 1.756 0.036 48.642 0.000 ## stfhlth 1.554 0.035 43.930 0.000 ## trstlgl 2.526 0.041 61.195 0.000 ## trstplc 1.956 0.036 54.052 0.000 ## trstun 2.350 0.040 59.017 0.000 ## trstep 2.296 0.038 60.160 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .pltcare 0.743 0.009 81.579 0.000 ## .pltinvt 0.775 0.009 82.043 0.000 ## .trstprl 1.938 0.027 70.877 0.000 ## .trstplt 1.548 0.023 67.052 0.000 ## .stfeco 3.565 0.044 81.289 0.000 ## .stfgov 3.044 0.038 79.326 0.000 ## .stfdem 2.631 0.034 78.072 0.000 ## .stfedu 3.941 0.047 83.419 0.000 ## .stfhlth 4.201 0.050 84.093 0.000 ## .trstlgl 3.370 0.042 79.787 0.000 ## .trstplc 3.410 0.041 82.311 0.000 ## .trstun 3.451 0.043 80.749 0.000 ## .trstep 3.019 0.038 80.272 0.000 ## political_trst 0.360 0.010 36.350 0.000 ## Compare fit statistics: fitMeasures(fit_3f) ## npar fmin chisq ## 27.000 0.297 9188.922 ## df pvalue baseline.chisq ## 51.000 0.000 75675.049 ## baseline.df baseline.pvalue cfi ## 66.000 0.000 0.879 ## tli nnfi rfi ## 0.844 0.844 0.843 ## nfi pnfi ifi ## 0.879 0.679 0.879 ## rni logl unrestricted.logl ## 0.879 -357923.209 -353328.748 ## aic bic ntotal ## 715900.419 716106.840 15448.000 ## bic2 rmsea rmsea.ci.lower ## 716021.036 0.108 0.106 ## rmsea.ci.upper rmsea.ci.level rmsea.pvalue ## 0.110 0.900 0.000 ## rmsea.close.h0 rmsea.notclose.pvalue rmsea.notclose.h0 ## 0.050 1.000 0.080 ## rmr rmr_nomean srmr ## 0.245 0.245 0.058 ## srmr_bentler srmr_bentler_nomean crmr ## 0.058 0.058 0.064 ## crmr_nomean srmr_mplus srmr_mplus_nomean ## 0.064 0.058 0.058 ## cn_05 cn_01 gfi ## 116.444 131.098 0.905 ## agfi pgfi mfi ## 0.854 0.591 0.744 ## ecvi ## 0.598 fitMeasures(fit_1f) ## npar fmin chisq ## 26.000 0.598 17667.304 ## df pvalue baseline.chisq ## 65.000 0.000 81699.096 ## baseline.df baseline.pvalue cfi ## 78.000 0.000 0.784 ## tli nnfi rfi ## 0.741 0.741 0.741 ## nfi pnfi ifi ## 0.784 0.653 0.784 ## rni logl unrestricted.logl ## 0.784 -374912.206 -366078.555 ## aic bic ntotal ## 749876.413 750074.036 14778.000 ## bic2 rmsea rmsea.ci.lower ## 749991.410 0.135 0.134 ## rmsea.ci.upper rmsea.ci.level rmsea.pvalue ## 0.137 0.900 0.000 ## rmsea.close.h0 rmsea.notclose.pvalue rmsea.notclose.h0 ## 0.050 1.000 0.080 ## rmr rmr_nomean srmr ## 0.364 0.364 0.080 ## srmr_bentler srmr_bentler_nomean crmr ## 0.080 0.080 0.087 ## crmr_nomean srmr_mplus srmr_mplus_nomean ## 0.087 0.080 0.080 ## cn_05 cn_01 gfi ## 71.949 79.980 0.825 ## agfi pgfi mfi ## 0.756 0.590 0.551 ## ecvi ## 1.199 The one-factor model definitely seems to fit worse than the three-factor model. A second order CFA model is another way of representing the latent structure underlying a set of items. As you read in Byrne (2005), however, the second order CFA is only appropriate in certain circumstances. 5.3.6 Given the CFA results above, would a second order CFA be appropriate for the Trust data? Why or why not? Click for explanation Yes, a second order CFA model is a theoretically appropriate representation of the Trust items. The first order latent variables in the three-factor model are all significantly correlated. The first order latent variables in the three-factor model seem to tap different aspects of some single underlying construct. 5.3.7 Define the lavaan model syntax for a second-order CFA model of the Trust items. Use the three factors defined in 5.3.2 as the first order factors. Click for explanation To define the second order factor, we use the same syntactic conventions that we employ to define a first order factor. The only differences is that the “indicators” of the second order factor (i.e., the variables listed on the RHS of the =~ operator) are previously defined first order latent variables. mod_2nd &lt;- &#39; politicians =~ pltcare + pltinvt + trstplt satisfaction =~ stfeco + stfgov + stfdem + stfedu + stfhlth institutions =~ trstlgl + trstplc + trstun + trstprl trust =~ politicians + satisfaction + institutions &#39; 5.3.8 Estimate the second order CFA model, and summarize the results. Does this model fit better or worse than the three-factor model? Is this model more or less complex than the three-factor model? What information can you use to quantify this difference in complexity? Click for explanation We don’t have to do anything special here. We can estimate and summarize the second order CFA exactly as we did the first order CFA. fit_2nd &lt;- cfa(mod_2nd, data = ess) summary(fit_2nd, fit.measures = TRUE, standardized = TRUE) ## lavaan 0.6.16 ended normally after 45 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 27 ## ## Used Total ## Number of observations 15448 18187 ## ## Model Test User Model: ## ## Test statistic 9188.922 ## Degrees of freedom 51 ## P-value (Chi-square) 0.000 ## ## Model Test Baseline Model: ## ## Test statistic 75675.049 ## Degrees of freedom 66 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.879 ## Tucker-Lewis Index (TLI) 0.844 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -357923.209 ## Loglikelihood unrestricted model (H1) -353328.748 ## ## Akaike (AIC) 715900.419 ## Bayesian (BIC) 716106.840 ## Sample-size adjusted Bayesian (SABIC) 716021.036 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.108 ## 90 Percent confidence interval - lower 0.106 ## 90 Percent confidence interval - upper 0.110 ## P-value H_0: RMSEA &lt;= 0.050 0.000 ## P-value H_0: RMSEA &gt;= 0.080 1.000 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.058 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## politicians =~ ## pltcare 1.000 0.671 0.639 ## pltinvt 0.981 0.015 65.449 0.000 0.658 0.624 ## trstplt 2.848 0.035 80.855 0.000 1.911 0.876 ## satisfaction =~ ## stfeco 1.000 1.659 0.712 ## stfgov 1.039 0.013 81.895 0.000 1.724 0.752 ## stfdem 0.979 0.012 80.257 0.000 1.624 0.733 ## stfedu 0.780 0.012 64.344 0.000 1.294 0.576 ## stfhlth 0.706 0.012 58.239 0.000 1.171 0.519 ## institutions =~ ## trstlgl 1.000 1.640 0.688 ## trstplc 0.777 0.012 64.539 0.000 1.275 0.582 ## trstun 0.861 0.013 66.949 0.000 1.411 0.605 ## trstprl 1.123 0.013 85.721 0.000 1.842 0.812 ## trust =~ ## politicians 1.000 0.904 0.904 ## satisfaction 2.153 0.037 57.975 0.000 0.788 0.788 ## institutions 2.580 0.044 59.246 0.000 0.955 0.955 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .pltcare 0.651 0.008 77.811 0.000 0.651 0.591 ## .pltinvt 0.680 0.009 78.658 0.000 0.680 0.611 ## .trstplt 1.103 0.029 38.414 0.000 1.103 0.232 ## .stfeco 2.671 0.038 70.723 0.000 2.671 0.493 ## .stfgov 2.287 0.035 66.172 0.000 2.287 0.435 ## .stfdem 2.266 0.033 68.444 0.000 2.266 0.462 ## .stfedu 3.378 0.042 79.725 0.000 3.378 0.668 ## .stfhlth 3.721 0.045 81.846 0.000 3.721 0.731 ## .trstlgl 2.997 0.040 74.549 0.000 2.997 0.527 ## .trstplc 3.178 0.040 80.410 0.000 3.178 0.662 ## .trstun 3.443 0.043 79.405 0.000 3.443 0.633 ## .trstprl 1.746 0.030 57.842 0.000 1.746 0.340 ## .politicians 0.082 0.004 19.635 0.000 0.182 0.182 ## .satisfaction 1.044 0.029 35.902 0.000 0.379 0.379 ## .institutions 0.238 0.024 10.064 0.000 0.089 0.089 ## trust 0.368 0.010 36.776 0.000 1.000 1.000 ## Compare fit between the first and second order models: fitMeasures(fit_3f) ## npar fmin chisq ## 27.000 0.297 9188.922 ## df pvalue baseline.chisq ## 51.000 0.000 75675.049 ## baseline.df baseline.pvalue cfi ## 66.000 0.000 0.879 ## tli nnfi rfi ## 0.844 0.844 0.843 ## nfi pnfi ifi ## 0.879 0.679 0.879 ## rni logl unrestricted.logl ## 0.879 -357923.209 -353328.748 ## aic bic ntotal ## 715900.419 716106.840 15448.000 ## bic2 rmsea rmsea.ci.lower ## 716021.036 0.108 0.106 ## rmsea.ci.upper rmsea.ci.level rmsea.pvalue ## 0.110 0.900 0.000 ## rmsea.close.h0 rmsea.notclose.pvalue rmsea.notclose.h0 ## 0.050 1.000 0.080 ## rmr rmr_nomean srmr ## 0.245 0.245 0.058 ## srmr_bentler srmr_bentler_nomean crmr ## 0.058 0.058 0.064 ## crmr_nomean srmr_mplus srmr_mplus_nomean ## 0.064 0.058 0.058 ## cn_05 cn_01 gfi ## 116.444 131.098 0.905 ## agfi pgfi mfi ## 0.854 0.591 0.744 ## ecvi ## 0.598 fitMeasures(fit_2nd) ## npar fmin chisq ## 27.000 0.297 9188.922 ## df pvalue baseline.chisq ## 51.000 0.000 75675.049 ## baseline.df baseline.pvalue cfi ## 66.000 0.000 0.879 ## tli nnfi rfi ## 0.844 0.844 0.843 ## nfi pnfi ifi ## 0.879 0.679 0.879 ## rni logl unrestricted.logl ## 0.879 -357923.209 -353328.748 ## aic bic ntotal ## 715900.419 716106.840 15448.000 ## bic2 rmsea rmsea.ci.lower ## 716021.036 0.108 0.106 ## rmsea.ci.upper rmsea.ci.level rmsea.pvalue ## 0.110 0.900 0.000 ## rmsea.close.h0 rmsea.notclose.pvalue rmsea.notclose.h0 ## 0.050 1.000 0.080 ## rmr rmr_nomean srmr ## 0.245 0.245 0.058 ## srmr_bentler srmr_bentler_nomean crmr ## 0.058 0.058 0.064 ## crmr_nomean srmr_mplus srmr_mplus_nomean ## 0.064 0.058 0.058 ## cn_05 cn_01 gfi ## 116.444 131.098 0.905 ## agfi pgfi mfi ## 0.854 0.591 0.744 ## ecvi ## 0.598 You should quickly notice something strange about the model fit statistics compared above. If you don’t see it, consider the following: fitMeasures(fit_3f) - fitMeasures(fit_2nd) ## npar fmin chisq ## 0 0 0 ## df pvalue baseline.chisq ## 0 0 0 ## baseline.df baseline.pvalue cfi ## 0 0 0 ## tli nnfi rfi ## 0 0 0 ## nfi pnfi ifi ## 0 0 0 ## rni logl unrestricted.logl ## 0 0 0 ## aic bic ntotal ## 0 0 0 ## bic2 rmsea rmsea.ci.lower ## 0 0 0 ## rmsea.ci.upper rmsea.ci.level rmsea.pvalue ## 0 0 0 ## rmsea.close.h0 rmsea.notclose.pvalue rmsea.notclose.h0 ## 0 0 0 ## rmr rmr_nomean srmr ## 0 0 0 ## srmr_bentler srmr_bentler_nomean crmr ## 0 0 0 ## crmr_nomean srmr_mplus srmr_mplus_nomean ## 0 0 0 ## cn_05 cn_01 gfi ## 0 0 0 ## agfi pgfi mfi ## 0 0 0 ## ecvi ## 0 The two models produce identical fit statistics! We also see that the degrees of freedom are identical between the two models. Hence, the two models have equal complexity. This result taps into a critical idea in statistical modeling, namely, model equivalency. It turns out the two models we’re comparing here are equivalent in the sense that they are statistically indistinguishable representations of the data. Since this is a very important idea, I want to spend some time discussing it in person. So, spend some time between now and the next lecture session thinking about the implications of this model equivalence. Specifically, consider the following questions: What do we mean when we say that these two models are equivalent? How is it possible for these two models to be equivalent when one contains an additional latent variable? Why are the degrees of freedom equal for these two models? Why are the fit statistics equal for these two models? How can we go about picking the “better” of these two models? We’ll take some time to discuss these ideas in the next lecture session. End of At-Home Exercises "],["in-class-exercises-4.html", "5.4 In-Class Exercises", " 5.4 In-Class Exercises Coming soon to a GitBook near you! "],["full-sem.html", "6 Full SEM", " 6 Full SEM This week, we will focus on integrating all of the disparate methods we’ve covered so far into full-fledged structural equation models. Homework before the lecture Watch the Lecture Recording for this week. Complete the Reading for this week, and answer the associated reading questions. Homework before the practical Complete the At-Home Exercises. Practical content During the practical you will work on the In-Class Exercises. "],["lecture-5.html", "6.1 Lecture", " 6.1 Lecture This week, we will begin with our final theme and discuss structural equation modeling (SEM). This powerful technique joins the strengths of CFA and path analysis to produce a highly flexible and theoretically appealing modeling tool. Essentially, SEM allows us to build structural path models using the latent variables defined by a CFA. 6.1.1 Recordings Once it’s ready, the lecture recording will be embedded below. 6.1.2 Slides You can download the lectures slides here "],["reading-5.html", "6.2 Reading", " 6.2 Reading Reference Weston, R. &amp; Gore, P. A. (2006). A brief guide to structural equation modeling. The Counseling Psychologist 34, 719–752. Notes: This article is quite general and provides an overview of things we have discussed so far in this course. This article also also adds an important new idea: combining factor analysis with path modeling to produce a full Structural Equation Model (SEM). Skip the part on GFI (p. 741). The GFI has been shown to be too dependent on sample size and is not recommended any longer. Skip the part on missing data. There is nothing wrong with this section, but missing data analysis is a broad and difficult topic that we cannot adequately cover in this course. If you would like to learn more about missing data and how to treat them, you can take two courses offered by our department: Conducting a Survey Missing Data Theory and Causal Effects Questions The authors state three similarities and two big differences between SEM and other multivariate statistical techniques (e.g., ANCOVA, regression). What are these similarities and differences? Do you agree with the relative strengths and weaknesses of SEM vs. other methods that the authors present? The authors miss at least one additional advantage of SEM over other multivariate methods. What is this missing advantage? Explain what the terms “measurement model” and “structural model” mean in the SEM context. What are the 6 steps of doing an SEM-based analysis given by the authors? The authors claim that testing an SEM using cross-validation is a good idea. When is cross-validation helpful in SEM? Hint: You may have to do some independent (internet, literature) research to learn how cross-validation can be implemented in SEM. "],["at-home-exercises-5.html", "6.3 At-Home Exercises", " 6.3 At-Home Exercises Coming soon to a GitBook near you! "],["in-class-exercises-5.html", "6.4 In-Class Exercises", " 6.4 In-Class Exercises Coming soon to a GitBook near you! "],["multiple-group-models.html", "7 Multiple Group Models", " 7 Multiple Group Models This week, you will cover multiple group modeling and measurement invariance testing in the SEM/CFA context. Homework before the lecture Watch the Lecture Recording for this week. Complete the Reading for this week, and answer the associated reading questions. Homework before the practical Complete the At-Home Exercises. Practical content During the practical you will work on the In-Class Exercises. "],["lecture-6.html", "7.1 Lecture", " 7.1 Lecture In this lecture, we will explore how you can incorporate grouping factors into your CFA and SEM analyses. We’ll cover three general topics: The multiple group modeling framework Measurement invariance testing Using multiple group models to test for moderation 7.1.1 Recordings Once it’s ready, the lecture recording will be embedded below. 7.1.2 Slides You can download the lecture slides here "],["reading-6.html", "7.2 Reading", " 7.2 Reading Coming soon to a GitBook near you! "],["at-home-exercises-6.html", "7.3 At-Home Exercises", " 7.3 At-Home Exercises Coming soon to a GitBook near you! "],["in-class-exercises-6.html", "7.4 In-Class Exercises", " 7.4 In-Class Exercises Coming soon to a GitBook near you! "],["wrap-up.html", "8 Wrap-Up", " 8 Wrap-Up Information This is an open week that we’ll use to tie up any loose ends and wrap up the course content. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
